[{"content":"Dockerfile 实践\rDockerfile 模板\rDockerfile 有很多命令，但是常用的就下边这些\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 # 引用基础镜像 FROM 基础镜像:标签 # 给镜像添加备注 LABEL REMARK=\u0026#34;测试使用\u0026#34; # 给镜像添加环境变量 ENV PATH $PATH:/usr/local/bin APP_HOME=/home/app # 添加主机目录到容器目录 ADD . /home # 执行指令 RUN 命令1 \\ \u0026amp;\u0026amp; 命令2 \\ \u0026amp;\u0026amp; 命令3 \u0026amp;\u0026amp; 命令4 # 设置镜像的主目录 WORKDIR /home/app # 启动容器时执行的命令, 比如 CMD /bin/bash CMD 命令 构建思路\r其实就是相当于手动在 Centos 里安装应用的过程，只不过这个过程由 Dockerfile 命令自动化进行了。\n所以在构建 Dockerfile 之前，需要先了解需要安装的应用，它到底怎么安装，这个安装的过程是怎么样的。\n实践一：以 anolisos 为基础镜像，构建 tomcat 镜像\ranolisos 是阿里开源的一个国产 Linux 系统\n拉取 anolisos 镜像\r1 [root@status docker]# docker pull registry.openanolis.cn/openanolis/anolisos:8 进入 anolisos 镜像\r1 [root@status docker]# docker run -it --name anolisos registry.openanolis.cn/openanolis/anolisos:8 /bin/bash 进入里边发现一个问题，就是 tomcat 包从哪里来？\n使用 Yum 源下载（不推荐，自己的玩具项目可以） 放一个到本地，然后使用 ADD 或者 COPY 指令，添加到容器中（使用这个） 配置 JDK 并安装 tomcat\r1）安装 JDK\n因为基础镜像中一切从简，默认是没有 JDK 的，所以需要安装\n1 yum install -y java-1.8.0-openjdk 2）查看 JDK 的安装目录\n1 2 3 4 5 6 [root@ae813af28fd9 /]# whereis java java: /usr/bin/java /usr/lib/java /etc/java /usr/share/java /usr/share/man/man1/java.1.gz [root@ae813af28fd9 /]# ls -l /usr/bin/java lrwxrwxrwx 1 root root 22 Sep 18 01:49 /usr/bin/java -\u0026gt; /etc/alternatives/java [root@ae813af28fd9 /]# ls -l /etc/alternatives/java lrwxrwxrwx 1 root root 75 Sep 18 01:49 /etc/alternatives/java -\u0026gt; /usr/lib/jvm/java-1.8.0-openjdk-1.8.0.422.b05-2.0.2.an8.x86_64/jre/bin/java JDK 的安装目录就是 /usr/lib/jvm/java-1.8.0-openjdk-1.8.0.422.b05-2.0.2.an8.x86_64/jre/bin/java\n3）配置环境变量\n1 2 3 4 5 6 vi ~/.bash_profile # 加入 export JAVA_HOME=/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.422.b05-2.0.2.an8.x86_64/jre export PATH=$JAVA_HOME/bin:$PATH # 刷新环境变量 source ~/.bash_profile 4）安装 tomcat\n5）启动 tomcat\n根据操作步骤编写 dockerfile\r1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 # 基于基础镜像 FROM registry.openanolis.cn/openanolis/anolisos:8 LABEL Author=\u0026#34;test\u0026#34; LABEL Remark=\u0026#34;测试使用, 基于 anolisos 制作 Tomcat 镜像\u0026#34; # 配置 JDK 环境变量 ENV JAVA_HOME /home/tomcat/jre ENV PATH $JAVA_HOME/bin:$PATH # 创建一个目录存放 JDK 和 tomcat 安装包，注意顺序，得先有这个目录，后续才能放到这个目录 RUN mkdir -p /home/tomcat # 设置 tomcat 主目录 如果后边的命令不需要基于这个主目录去执行，也可不设置 WORKDIR /home/tomcat # 添加 JDK 包和 tomcat 包到容器内部，确保包和 dockerfile 都在一个目录下 # ADD 命令会自动将 tar 包解压 ADD jdk.tar.gz /home/tomcat ADD apache-tomcat-10.1.30.tar.gz /home/tomcat # 暴露端口 EXPOSE 8080 # 启动 tomcat CMD [\u0026#34;/home/tomcat/apache-tomcat-10.1.30/bin/catalina.sh\u0026#34;,\u0026#34;run\u0026#34;] 使用 Dockerfile 构建镜像\r注意：Dockerfile 与 JDK \\ tomcat 的 tar 包要处于同一个目录下\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 [root@status dockerfile]# docker build -t test:v1 . Sending build context to Docker daemon 65.99 MB Step 1/11 : FROM registry.openanolis.cn/openanolis/anolisos:8 ---\u0026gt; ef65d5c9c386 Step 2/11 : LABEL Author \u0026#34;test\u0026#34; ---\u0026gt; Running in 3f756590b7cd ---\u0026gt; 27aab3b7f5b3 Removing intermediate container 3f756590b7cd Step 3/11 : LABEL Remark \u0026#34;测试使用, 基于 龙蜥系统 制作 Tomcat 镜像\u0026#34; ---\u0026gt; Running in b5fc72ee8fac ---\u0026gt; 68a7c28837a0 Removing intermediate container b5fc72ee8fac Step 4/11 : ENV JAVA_HOME /home/tomcat/jre ---\u0026gt; Running in 1136456bdb18 ---\u0026gt; 0ea43384acec Removing intermediate container 1136456bdb18 Step 5/11 : ENV PATH $JAVA_HOME/bin:$PATH ---\u0026gt; Running in 598616ebc31f ---\u0026gt; ddbc3d112a6b Removing intermediate container 598616ebc31f Step 6/11 : RUN mkdir -p /home/tomcat ---\u0026gt; Running in 9fb8f361d189 ---\u0026gt; 621e6817887f Removing intermediate container 9fb8f361d189 Step 7/11 : WORKDIR /home/tomcat ---\u0026gt; 1a893a18a343 Removing intermediate container 009c81d31fc1 Step 8/11 : ADD jdk.tar.gz /home/tomcat ---\u0026gt; 92064443362d Removing intermediate container de35da461b5d Step 9/11 : ADD apache-tomcat-10.1.30.tar.gz /home/tomcat ---\u0026gt; 006acfe8ee17 Removing intermediate container b5d3283e5c4a Step 10/11 : EXPOSE 8080 ---\u0026gt; Running in 5460b8f751fb ---\u0026gt; 9f59ded402c3 Removing intermediate container 5460b8f751fb Step 11/11 : CMD /home/tomcat/apache-tomcat-10.1.30/bin/catalina.sh run ---\u0026gt; Running in 99352d2ca9f8 ---\u0026gt; 56c59b8f7d84 Removing intermediate container 99352d2ca9f8 Successfully built 56c59b8f7d84 成功了，可以看看这个镜像的信息\n1 2 3 [root@status dockerfile]# docker images REPOSITORY TAG IMAGE ID CREATED SIZE test v1 1ae021027b9c About a minute ago 386 MB 1 docker inspect test:v1 启动镜像\r1 2 3 4 5 6 7 8 9 10 [root@status dockerfile]# docker run -it --name tomcat_aliyun -p 8080:8080 test:v1 Using CATALINA_BASE: /home/tomcat/apache-tomcat-10.1.30 Using CATALINA_HOME: /home/tomcat/apache-tomcat-10.1.30 Using CATALINA_TMPDIR: /home/tomcat/apache-tomcat-10.1.30/temp Using JRE_HOME: /home/tomcat/jre Using CLASSPATH: /home/tomcat/apache-tomcat-10.1.30/bin/bootstrap.jar:/home/tomcat/apache-tomcat-10.1.30/bin/tomcat-juli.jar Using CATALINA_OPTS: Unrecognized option: --add-opens=java.base/java.lang=ALL-UNNAMED Error: Could not create the Java Virtual Machine. Error: A fatal exception has occurred. Program will exit. 这里启动 tomcat 报错了\n具体原因：解决ideatomcatUnrecognized option:\u0026ndash;add-opens=java.base/java.lang=ALL-UNNAMEDError:Could not create th_unrecognized option: \u0026ndash;add-opens-CSDN博客\n反正就是 JDK1.8.0 与 tomcat10 不匹配，把 tomcat 版本降一下，换成 tomcat9\n换了 tomcat9 又报错了\n1 Caused by: java.lang.Error: java.io.FileNotFoundException: /home/tomcat/jre/lib/tzdb.dat (No such file or directory) 在 dockerfile 里配置一下 jre_home 环境变量\n重新调整 dockerfile\r1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 # 基于anolisos FROM registry.openanolis.cn/openanolis/anolisos:8 LABEL Author=\u0026#34;test\u0026#34; LABEL Remark=\u0026#34;测试使用, 基于 anolisos 制作 Tomcat 镜像\u0026#34; # 配置 JDK 环境变量 ENV JAVA_HOME /home/tomcat/jdk1.8.0_202 ENV JRE_HOME /home/tomcat/jdk1.8.0_202/jre ENV CLASSPATH $JAVA_HOME/lib:$JRE_HOME/lib ENV PATH $JAVA_HOME/bin:$PATH # 创建一个目录存放 JDK 和 tomcat 安装包，注意顺序，得先有这个目录，后续才能放到这个目录 RUN mkdir -p /home/tomcat # 设置 tomcat 主目录 如果后边的命令不需要基于这个主目录去执行，也可不设置 WORKDIR /home/tomcat # 添加 JDK 包和 tomcat 包到容器内部，确保包和 dockerfile 都在一个目录下 # ADD 命令会自动将 tar 包解压 ADD jdk-8u202-linux-i586.tar.gz /home/tomcat ADD apache-tomcat-9.0.95.tar.gz /home/tomcat # 暴露端口 EXPOSE 8080 # 启动 tomcat CMD [\u0026#34;/home/tomcat/apache-tomcat-9.0.95/bin/catalina.sh\u0026#34;,\u0026#34;run\u0026#34;] 使用这个 dockerfile 构建镜像\n然后启动它\n还是报错了\n1 2 3 4 5 6 7 8 [root@status dockerfile]# docker run -it --name tomcat_aliyun -p 8080:8080 test:v1 Using CATALINA_BASE: /home/tomcat/apache-tomcat-9.0.95 Using CATALINA_HOME: /home/tomcat/apache-tomcat-9.0.95 Using CATALINA_TMPDIR: /home/tomcat/apache-tomcat-9.0.95/temp Using JRE_HOME: /home/tomcat/jdk1.8.0_202/jre Using CLASSPATH: /home/tomcat/apache-tomcat-9.0.95/bin/bootstrap.jar:/home/tomcat/apache-tomcat-9.0.95/bin/tomcat-juli.jar Using CATALINA_OPTS: /home/tomcat/apache-tomcat-9.0.95/bin/catalina.sh: line 421: /home/tomcat/jdk1.8.0_202/jre/bin/java: No such file or directory 感觉是这个 JDK 版本不匹配，重新下一个 x64 版本的 jdk\n最终调整 dockerfile\r1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 # 基于anolisos FROM registry.openanolis.cn/openanolis/anolisos:8 LABEL Author=\u0026#34;test\u0026#34; LABEL Remark=\u0026#34;测试使用, 基于 anolisos 制作 Tomcat 镜像\u0026#34; # 创建一个目录存放 JDK 和 tomcat 安装包，注意顺序，得先有这个目录，后续才能放到这个目录 RUN mkdir -p /home/tomcat # 添加 JDK 包和 tomcat 包到容器内部，确保包和 dockerfile 都在一个目录下 # ADD 命令会自动将 tar 包解压 ADD jdk-8u202-linux-x64.tar.gz /home/tomcat ADD apache-tomcat-9.0.95.tar.gz /home/tomcat # 设置 tomcat 主目录 如果后边的命令不需要基于这个主目录去执行，也可不设置 WORKDIR /home/tomcat # 配置 JDK 环境变量 ENV JAVA_HOME /home/tomcat/jdk1.8.0_202 ENV JRE_HOME /home/tomcat/jdk1.8.0_202/jre ENV CLASSPATH /home/tomcat/jdk1.8.0_202/lib:/home/tomcat/jdk1.8.0_202/jre/lib ENV PATH $JAVA_HOME/bin:$PATH # 验证一下 JDK 是否配置 RUN $JAVA_HOME/bin/java -version # 暴露端口 EXPOSE 8080 # 启动 tomcat CMD [\u0026#34;/home/tomcat/apache-tomcat-9.0.95/bin/catalina.sh\u0026#34;,\u0026#34;run\u0026#34;] 构建过程：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 [root@status dockerfile]# docker build test:v1 . \u0026#34;docker build\u0026#34; requires exactly 1 argument(s). See \u0026#39;docker build --help\u0026#39;. Usage: docker build [OPTIONS] PATH | URL | - Build an image from a Dockerfile [root@status dockerfile]# docker build -t test:v1 . Sending build context to Docker daemon 206.8 MB Step 1/14 : FROM registry.openanolis.cn/openanolis/anolisos:8 ---\u0026gt; ef65d5c9c386 Step 2/14 : LABEL Author \u0026#34;test\u0026#34; ---\u0026gt; Running in ec01334f21ac ---\u0026gt; 88b417c6fcff Removing intermediate container ec01334f21ac Step 3/14 : LABEL Remark \u0026#34;测试使用, 基于 龙蜥系统 制作 Tomcat 镜像\u0026#34; ---\u0026gt; Running in efbab43c84cf ---\u0026gt; f64ab9b3ca4b Removing intermediate container efbab43c84cf Step 4/14 : RUN mkdir -p /home/tomcat ---\u0026gt; Running in 0bd99be045f6 ---\u0026gt; 4535e994046e Removing intermediate container 0bd99be045f6 Step 5/14 : ADD jdk-8u202-linux-x64.tar.gz /home/tomcat ---\u0026gt; 103c0a0d137d Removing intermediate container 778a257c323e Step 6/14 : ADD apache-tomcat-9.0.95.tar.gz /home/tomcat ---\u0026gt; 6e3b3068a3f6 Removing intermediate container 4860b4330b7c Step 7/14 : WORKDIR /home/tomcat ---\u0026gt; 4a6354a3c4ca Removing intermediate container 2f3bf66b733c Step 8/14 : ENV JAVA_HOME /home/tomcat/jdk1.8.0_202 ---\u0026gt; Running in a02da957f0e5 ---\u0026gt; fbb98637fc47 Removing intermediate container a02da957f0e5 Step 9/14 : ENV JRE_HOME /home/tomcat/jdk1.8.0_202/jre ---\u0026gt; Running in 15a12e697856 ---\u0026gt; 576b7678f857 Removing intermediate container 15a12e697856 Step 10/14 : ENV CLASSPATH /home/tomcat/jdk1.8.0_202/lib:/home/tomcat/jdk1.8.0_202/jre/lib ---\u0026gt; Running in 28af34ebfcff ---\u0026gt; d87b8a7680af Removing intermediate container 28af34ebfcff Step 11/14 : ENV PATH $JAVA_HOME/bin:$PATH ---\u0026gt; Running in 440870ff6cbf ---\u0026gt; eb633e75c31b Removing intermediate container 440870ff6cbf Step 12/14 : RUN $JAVA_HOME/bin/java -version ---\u0026gt; Running in b888421b5460 # 注意看这里 ################# java version \u0026#34;1.8.0_202\u0026#34; Java(TM) SE Runtime Environment (build 1.8.0_202-b08) Java HotSpot(TM) 64-Bit Server VM (build 25.202-b08, mixed mode) ############################## ---\u0026gt; 585c6ee10358 Removing intermediate container b888421b5460 Step 13/14 : EXPOSE 8080 ---\u0026gt; Running in fa69ece8e180 ---\u0026gt; c4af6c5056bc Removing intermediate container fa69ece8e180 Step 14/14 : CMD /home/tomcat/apache-tomcat-9.0.95/bin/catalina.sh run ---\u0026gt; Running in 2a007a3fd78f ---\u0026gt; e184d618916b Removing intermediate container 2a007a3fd78f Successfully built e184d618916b 看着应该没问题\n启动镜像看看\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 [root@status dockerfile]# docker run -d --name test_tomcat -p 8080:8080 test:v1 d14c7820921dd0150c1d4c9e9ff786164201f10f86c7dc63db6522ded8b2405a [root@status dockerfile]# docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES d14c7820921d test:v1 \u0026#34;/home/tomcat/apac...\u0026#34; 7 seconds ago Up 6 seconds 0.0.0.0:8080-\u0026gt;8080/tcp test_tomcat ae813af28fd9 registry.openanolis.cn/openanolis/anolisos:8 \u0026#34;/bin/bash\u0026#34; 5 hours ago Up 5 hours anolisos [root@status dockerfile]# docker logs test_tomcat 18-Sep-2024 07:16:34.224 INFO [main] org.apache.catalina.startup.VersionLoggerListener.log Server version name: Apache Tomcat/9.0.95 18-Sep-2024 07:16:34.246 INFO [main] org.apache.catalina.startup.VersionLoggerListener.log Server built: Sep 13 2024 18:07:47 UTC 18-Sep-2024 07:16:34.247 INFO [main] org.apache.catalina.startup.VersionLoggerListener.log Server version number: 9.0.95.0 18-Sep-2024 07:16:34.247 INFO [main] org.apache.catalina.startup.VersionLoggerListener.log OS Name: Linux 18-Sep-2024 07:16:34.248 INFO [main] org.apache.catalina.startup.VersionLoggerListener.log OS Version: 3.10.0-1160.118.1.el7.x86_64 18-Sep-2024 07:16:34.248 INFO [main] org.apache.catalina.startup.VersionLoggerListener.log Architecture: amd64 18-Sep-2024 07:16:34.248 INFO [main] org.apache.catalina.startup.VersionLoggerListener.log Java Home: /home/tomcat/jdk1.8.0_202/jre 18-Sep-2024 07:16:34.248 INFO [main] org.apache.catalina.startup.VersionLoggerListener.log JVM Version: 1.8.0_202-b08 18-Sep-2024 07:16:34.248 INFO [main] org.apache.catalina.startup.VersionLoggerListener.log JVM Vendor: Oracle Corporation 18-Sep-2024 07:16:34.248 INFO [main] org.apache.catalina.startup.VersionLoggerListener.log CATALINA_BASE: /home/tomcat/apache-tomcat-9.0.95 18-Sep-2024 07:16:34.249 INFO [main] org.apache.catalina.startup.VersionLoggerListener.log CATALINA_HOME: /home/tomcat/apache-tomcat-9.0.95 18-Sep-2024 07:16:34.263 INFO [main] org.apache.catalina.startup.VersionLoggerListener.log Command line argument: -Djava.util.logging.config.file=/home/tomcat/apache-tomcat-9.0.95/conf/logging.properties 18-Sep-2024 07:16:34.263 INFO [main] org.apache.catalina.startup.VersionLoggerListener.log Command line argument: -Djava.util.logging.manager=org.apache.juli.ClassLoaderLogManager 18-Sep-2024 07:16:34.263 INFO [main] org.apache.catalina.startup.VersionLoggerListener.log Command line argument: -Djdk.tls.ephemeralDHKeySize=2048 18-Sep-2024 07:16:34.263 INFO [main] org.apache.catalina.startup.VersionLoggerListener.log Command line argument: -Djava.protocol.handler.pkgs=org.apache.catalina.webresources 18-Sep-2024 07:16:34.264 INFO [main] org.apache.catalina.startup.VersionLoggerListener.log Command line argument: -Dorg.apache.catalina.security.SecurityListener.UMASK=0027 18-Sep-2024 07:16:34.264 INFO [main] org.apache.catalina.startup.VersionLoggerListener.log Command line argument: -Dignore.endorsed.dirs= 18-Sep-2024 07:16:34.265 INFO [main] org.apache.catalina.startup.VersionLoggerListener.log Command line argument: -Dcatalina.base=/home/tomcat/apache-tomcat-9.0.95 18-Sep-2024 07:16:34.265 INFO [main] org.apache.catalina.startup.VersionLoggerListener.log Command line argument: -Dcatalina.home=/home/tomcat/apache-tomcat-9.0.95 18-Sep-2024 07:16:34.265 INFO [main] org.apache.catalina.startup.VersionLoggerListener.log Command line argument: -Djava.io.tmpdir=/home/tomcat/apache-tomcat-9.0.95/temp 18-Sep-2024 07:16:34.284 INFO [main] org.apache.catalina.core.AprLifecycleListener.lifecycleEvent The Apache Tomcat Native library which allows using OpenSSL was not found on the java.library.path: [/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib] 18-Sep-2024 07:16:35.498 INFO [main] org.apache.coyote.AbstractProtocol.init Initializing ProtocolHandler [\u0026#34;http-nio-8080\u0026#34;] 18-Sep-2024 07:16:35.604 INFO [main] org.apache.catalina.startup.Catalina.load Server initialization in [2074] milliseconds 18-Sep-2024 07:16:35.719 INFO [main] org.apache.catalina.core.StandardService.startInternal Starting service [Catalina] 18-Sep-2024 07:16:35.720 INFO [main] org.apache.catalina.core.StandardEngine.startInternal Starting Servlet engine: [Apache Tomcat/9.0.95] 18-Sep-2024 07:16:35.749 INFO [main] org.apache.catalina.startup.HostConfig.deployDirectory Deploying web application directory [/home/tomcat/apache-tomcat-9.0.95/webapps/host-manager] 18-Sep-2024 07:16:36.660 INFO [main] org.apache.catalina.startup.HostConfig.deployDirectory Deployment of web application directory [/home/tomcat/apache-tomcat-9.0.95/webapps/host-manager] has finished in [910] ms 18-Sep-2024 07:16:36.661 INFO [main] org.apache.catalina.startup.HostConfig.deployDirectory Deploying web application directory [/home/tomcat/apache-tomcat-9.0.95/webapps/docs] 18-Sep-2024 07:16:36.750 INFO [main] org.apache.catalina.startup.HostConfig.deployDirectory Deployment of web application directory [/home/tomcat/apache-tomcat-9.0.95/webapps/docs] has finished in [89] ms 18-Sep-2024 07:16:36.751 INFO [main] org.apache.catalina.startup.HostConfig.deployDirectory Deploying web application directory [/home/tomcat/apache-tomcat-9.0.95/webapps/examples] 18-Sep-2024 07:16:37.540 INFO [main] org.apache.catalina.startup.HostConfig.deployDirectory Deployment of web application directory [/home/tomcat/apache-tomcat-9.0.95/webapps/examples] has finished in [789] ms 18-Sep-2024 07:16:37.540 INFO [main] org.apache.catalina.startup.HostConfig.deployDirectory Deploying web application directory [/home/tomcat/apache-tomcat-9.0.95/webapps/ROOT] 18-Sep-2024 07:16:37.641 INFO [main] org.apache.catalina.startup.HostConfig.deployDirectory Deployment of web application directory [/home/tomcat/apache-tomcat-9.0.95/webapps/ROOT] has finished in [100] ms 18-Sep-2024 07:16:37.642 INFO [main] org.apache.catalina.startup.HostConfig.deployDirectory Deploying web application directory [/home/tomcat/apache-tomcat-9.0.95/webapps/manager] 18-Sep-2024 07:16:37.730 INFO [main] org.apache.catalina.startup.HostConfig.deployDirectory Deployment of web application directory [/home/tomcat/apache-tomcat-9.0.95/webapps/manager] has finished in [87] ms 18-Sep-2024 07:16:37.767 INFO [main] org.apache.coyote.AbstractProtocol.start Starting ProtocolHandler [\u0026#34;http-nio-8080\u0026#34;] 18-Sep-2024 07:16:37.799 INFO [main] org.apache.catalina.startup.Catalina.start Server startup in [2194] milliseconds 看着启动起来了\n访问 tomcat 前台看看，没问题了\n总结\r编写 dockerfile 的思路，其实就是实际手动配置的思路。\n就以构建 tomcat 镜像来说，如果是手工操作：\n需要准备 JDK、tomcat 包 需要解压 JDK、tomcat 包 需要配置 JDK 的环境变量 需要开通 tomcat 的 8080 端口 在编写 dockerfile 的时候，也是同理：\n准备好的 JDK、tomcat 包放到镜像的什么地方？ ADD 指令会自动解压 JDK、tomcat 包，代替了手动执行 tar 命令 配置 JDK 的环境变量 暴露 tomcat 的 8080 端口 最后，使用 CMD 指令，执行启动 tomcat 的命令 还有就是，一定得注意 tomcat 版本应该与 JDK 版本相匹配。\n实践二：以 anolisos 为基础镜像，构建 nginx 镜像\r还是以 anolisos 为基础镜像，并在里边运行一个 nginx 服务。\n安装 nginx\r根据此文\nLinux 安装 Nginx 并配置为系统服务（超详细）-阿里云开发者社区 (aliyun.com)\n1）下载 nginx 并解压\n1 2 wget http://nginx.org/download/nginx-1.25.1.tar.gz tar -xzvf nginx-1.25.1.tar.gz /home/dockerfile_nginx 2）配置 nginx\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 ./configure # 出现下边表示成功 Configuration summary + using system PCRE library + OpenSSL library is not used + md5: using system crypto library + sha1: using system crypto library + using system zlib library nginx path prefix: \u0026#34;/usr/local/nginx\u0026#34; nginx binary file: \u0026#34;/usr/local/nginx/sbin/nginx\u0026#34; nginx configuration prefix: \u0026#34;/usr/local/nginx/conf\u0026#34; nginx configuration file: \u0026#34;/usr/local/nginx/conf/nginx.conf\u0026#34; nginx pid file: \u0026#34;/usr/local/nginx/logs/nginx.pid\u0026#34; nginx error log file: \u0026#34;/usr/local/nginx/logs/error.log\u0026#34; nginx http access log file: \u0026#34;/usr/local/nginx/logs/access.log\u0026#34; nginx http client request body temporary files: \u0026#34;client_body_temp\u0026#34; nginx http proxy temporary files: \u0026#34;proxy_temp\u0026#34; nginx http fastcgi temporary files: \u0026#34;fastcgi_temp\u0026#34; nginx http uwsgi temporary files: \u0026#34;uwsgi_temp\u0026#34; nginx http scgi temporary files: \u0026#34;scgi_temp\u0026#34; 一般来讲，还是需要安装 gcc 之类的依赖的，因为我这个是阿里云服务器，里边的内容都比较完整，可以直接配置。\n3）编译安装\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 make \u0026amp;\u0026amp; make install # 出现下边这个 make -f objs/Makefile install make[1]: Entering directory `/home/dockerfile_nginx/nginx-1.9.9\u0026#39; test -d \u0026#39;/usr/local/nginx\u0026#39; || mkdir -p \u0026#39;/usr/local/nginx\u0026#39; test -d \u0026#39;/usr/local/nginx/sbin\u0026#39; || mkdir -p \u0026#39;/usr/local/nginx/sbin\u0026#39; test ! -f \u0026#39;/usr/local/nginx/sbin/nginx\u0026#39; || mv \u0026#39;/usr/local/nginx/sbin/nginx\u0026#39; \u0026#39;/usr/local/nginx/sbin/nginx.old\u0026#39; cp objs/nginx \u0026#39;/usr/local/nginx/sbin/nginx\u0026#39; test -d \u0026#39;/usr/local/nginx/conf\u0026#39; || mkdir -p \u0026#39;/usr/local/nginx/conf\u0026#39; cp conf/koi-win \u0026#39;/usr/local/nginx/conf\u0026#39; cp conf/koi-utf \u0026#39;/usr/local/nginx/conf\u0026#39; cp conf/win-utf \u0026#39;/usr/local/nginx/conf\u0026#39; test -f \u0026#39;/usr/local/nginx/conf/mime.types\u0026#39; || cp conf/mime.types \u0026#39;/usr/local/nginx/conf\u0026#39; cp conf/mime.types \u0026#39;/usr/local/nginx/conf/mime.types.default\u0026#39; test -f \u0026#39;/usr/local/nginx/conf/fastcgi_params\u0026#39; || cp conf/fastcgi_params \u0026#39;/usr/local/nginx/conf\u0026#39; cp conf/fastcgi_params \u0026#39;/usr/local/nginx/conf/fastcgi_params.default\u0026#39; test -f \u0026#39;/usr/local/nginx/conf/fastcgi.conf\u0026#39; || cp conf/fastcgi.conf \u0026#39;/usr/local/nginx/conf\u0026#39; cp conf/fastcgi.conf \u0026#39;/usr/local/nginx/conf/fastcgi.conf.default\u0026#39; test -f \u0026#39;/usr/local/nginx/conf/uwsgi_params\u0026#39; || cp conf/uwsgi_params \u0026#39;/usr/local/nginx/conf\u0026#39; cp conf/uwsgi_params \u0026#39;/usr/local/nginx/conf/uwsgi_params.default\u0026#39; test -f \u0026#39;/usr/local/nginx/conf/scgi_params\u0026#39; || cp conf/scgi_params \u0026#39;/usr/local/nginx/conf\u0026#39; cp conf/scgi_params \u0026#39;/usr/local/nginx/conf/scgi_params.default\u0026#39; test -f \u0026#39;/usr/local/nginx/conf/nginx.conf\u0026#39; || cp conf/nginx.conf \u0026#39;/usr/local/nginx/conf/nginx.conf\u0026#39; cp conf/nginx.conf \u0026#39;/usr/local/nginx/conf/nginx.conf.default\u0026#39; test -d \u0026#39;/usr/local/nginx/logs\u0026#39; || mkdir -p \u0026#39;/usr/local/nginx/logs\u0026#39; test -d \u0026#39;/usr/local/nginx/logs\u0026#39; || mkdir -p \u0026#39;/usr/local/nginx/logs\u0026#39; test -d \u0026#39;/usr/local/nginx/html\u0026#39; || cp -R html \u0026#39;/usr/local/nginx\u0026#39; test -d \u0026#39;/usr/local/nginx/logs\u0026#39; || mkdir -p \u0026#39;/usr/local/nginx/logs\u0026#39; make[1]: Leaving directory `/home/dockerfile_nginx/nginx-1.9.9\u0026#39; 它创建了 /usr/local/nginx 目录，这个就是 nginx 的安装目录了，日志、启动文件都在这里。\n4）启动并访问\n1 2 3 4 5 6 7 [root@status sbin]# pwd /usr/local/nginx/sbin [root@status sbin]# ./nginx [root@status sbin]# ps -ef | grep nginx root 11694 1 0 15:53 ? 00:00:00 nginx: master process ./nginx nobody 11695 11694 0 15:53 ? 00:00:00 nginx: worker process root 11700 8800 0 15:53 pts/10 00:00:00 grep --color=auto nginx 根据操作步骤编写 dockerfile\r1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 # 基于anolisos FROM registry.openanolis.cn/openanolis/anolisos:8 LABEL Author=\u0026#34;test\u0026#34; LABEL Remark=\u0026#34;测试使用, 基于 anolisos 制作 Nginx 镜像\u0026#34; # 解压包到工作目录 ADD nginx-1.25.1.tar.gz /usr/local # 安装编译Nginx所需的依赖 RUN yum install -y gcc make openssl-devel pcre-devel zlib-devel # 设置主目录 WORKDIR /usr/local/nginx-1.25.1 # 配置、编译和安装Nginx RUN ./configure \\ --prefix=/usr/local/nginx \\ --sbin-path=/usr/sbin/nginx \\ --conf-path=/etc/nginx/nginx.conf \\ --error-log-path=/var/log/nginx/error.log \\ --http-log-path=/var/log/nginx/access.log \\ --pid-path=/var/run/nginx.pid \\ --lock-path=/var/run/nginx.lock \\ --http-client-body-temp-path=/var/cache/nginx/client_temp \\ --http-proxy-temp-path=/var/cache/nginx/proxy_temp \\ --http-fastcgi-temp-path=/var/cache/nginx/fastcgi_temp \\ --http-uwsgi-temp-path=/var/cache/nginx/uwsgi_temp \\ --http-scgi-temp-path=/var/cache/nginx/scgi_temp \\ --user=nginx \\ --group=nginx \\ --with-http_ssl_module \\ --with-http_realip_module \\ --with-http_addition_module \\ --with-http_sub_module \\ --with-http_dav_module \\ --with-http_flv_module \\ --with-http_mp4_module \\ --with-http_gunzip_module \\ --with-http_gzip_static_module \\ --with-http_random_index_module \\ --with-http_secure_link_module \\ --with-http_stub_status_module \\ --with-mail \\ --with-mail_ssl_module \\ --with-file-aio \\ --with-ipv6 \\ --with-http_v2_module \\ --with-cc-opt=\u0026#34;-Wno-error\u0026#34; \\ \u0026amp;\u0026amp; make \\ \u0026amp;\u0026amp; make install # 创建日志和缓存目录 RUN mkdir -p /var/log/nginx \u0026amp;\u0026amp; \\ mkdir -p /var/cache/nginx # 拷贝Nginx配置文件 COPY nginx.conf /etc/nginx/nginx.conf # 暴露80端口，供外部访问 EXPOSE 80 # 启动 nginx CMD [\u0026#34;nginx\u0026#34;, \u0026#34;-g\u0026#34;, \u0026#34;daemon off;\u0026#34;] nginx 配置\r把 nginx.conf 文件放到 dockerfile 目录下\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 user root; # 镜像里没有创建 nginx 用户，指定 root 用户来启动服务，不然会报错 worker_processes auto; events { worker_connections 512; use epoll; } http { include mime.types; default_type application/octet-stream; access_log off; sendfile on; keepalive_timeout 75; server { listen 80; server_name 139.196.97.87; location / { proxy_pass http://139.196.97.87:8080; } } } 构建镜像\r1 2 3 4 5 6 7 8 [root@status dockerfile_nginx]# docker build -t nginx:v1 . ... Step 11/11 : CMD nginx -g daemon off; ---\u0026gt; Running in 145e8f62d60c ---\u0026gt; dcfd18bb9209 Removing intermediate container 145e8f62d60c Successfully built dcfd18bb9209 启动镜像\r1 2 3 4 [root@status dockerfile_nginx]# docker run -d --name nginx -p 80:80 nginx:v1 a4f70aab39a1665802135a47d7a5bc2edf6c15093e0fef27fa4db82d0690f917 [root@status dockerfile_nginx]# docker logs nginx nginx: [emerg] getpwnam(\u0026#34;nginx\u0026#34;) failed 这里报错了，没有找到 nginx 用户。\n1）在容器里创建一个 nginx 用户 2）指定 root 用户为启动 Nginx 的用户 如果是使用 1 方案的话，应该得在 dockerfile 里 RUN 一条创建 nginx 用户的命令\n1 useradd -r -s /sbin/nologin nginx 我使用了 2 方案，指定 root 用户启动。在 nginx.conf 添加一行\n1 user root; 添加后重新构建镜像，然后启动。\n1 2 3 4 5 6 7 8 [root@status dockerfile_nginx]# docker run -d --name nginx -p 80:80 nginx:v1 ef443ef68ec75631a11ee52eeb2d8831610582a257154350cadb5af5ac72a97e [root@status dockerfile_nginx]# docker logs nginx [root@status dockerfile_nginx]# docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES ef443ef68ec7 nginx:v1 \u0026#34;nginx -g \u0026#39;daemon ...\u0026#34; 50 seconds ago Up 48 seconds 0.0.0.0:80-\u0026gt;80/tcp nginx d14c7820921d test:v1 \u0026#34;/home/tomcat/apac...\u0026#34; 18 hours ago Up 18 hours 0.0.0.0:8080-\u0026gt;8080/tcp test_tomcat ae813af28fd9 registry.openanolis.cn/openanolis/anolisos:8 \u0026#34;/bin/bash\u0026#34; 24 hours ago Up 24 hours anolisos 一切正常，访问 IP:80 端口，成功跳转到 tomcat:8080 页面。\n构建 Dockerfile 过程的问题\r如何将本地的某个包放到容器内部？\r需要将 rpm 包放到 centos 容器内\n1.复制文件命令 cp\n1 [root@status home]# docker container cp wget-1.14-18.el7_6.1.x86_64.rpm centos7:/home/ 1 2 3 [root@9fb9bacc6189 home]# ll total 548 -rw-r--r-- 1 root root 560272 Sep 13 07:45 wget-1.14-18.el7_6.1.x86_64.rpm 2.加载数据卷，但是容器内对数据卷里的内容做修改也会导致主机的内容被修改，这个不适用于现在的情况\n3.构建 Docker 镜像时，使用 ADD 命令或者 COPY 命令，将文件添加进去\n1 COPY /home/wget-1.14-18.el7_6.1.x86_64.rpm /home 如何将容器里打包好的文件传回主机？\r直接复制到主机 挂载数据卷容器 通过 docker 的管道 - 传回主机 复制\r从容器复制到主机\n1 2 3 4 [root@status dockerfile]# docker container cp anolisos:/home/jdk.tar.gz /home/dockerfile/ [root@status dockerfile]# ll total 51100 -rw-r--r-- 1 root root 52325939 Sep 18 10:57 jdk.tar.gz Network 实践\r实践一：nginx 容器与 tomcat 容器互联\r前提\r从上边的实践一和实践二，可以成功的构建了 tomcat 镜像与 nginx 镜像\n因为我的阿里云服务器网络策略，是把 tomcat 8080 端口和 nginx 80 端口都打开了，上边的两个镜像，成功的通过 nginx 跳转到 tomcat 页面。\n[!IMPORTANT]\n实际项目中，如果对外使用了 nginx 做反向代理或者负载均衡，则 tomcat（应用） 的 IP和端口是不对外开放的，统一通过 nginx 跳转应用。\n所以我把阿里云服务器网络策略中 tomcat 8080 端口关掉，这样 tomcat 就无法访问，同时 nginx 就跳转不到 tomcat 上了。\n[!IMPORTANT]\n在主机 8080 端口关闭的前提下，为了能够让 nginx 成功跳转到 tomcat ，从容器内部出发。使用 docker 的 network 机制，将 nginx 容器和 tomcat 容器都加入到同一个网络中，让它们能够互相访问。\n这样，外部只需要访问 nginx ，然后 nginx 通过 docker network 访问 tomcat 。\n这个实践是基于上边的实践一、实践二来操作的。 配置 network 容器互联\r创建网络，将 nginx 和 tomcat 容器都拉进来\n1 2 3 4 [root@status dockerfile_nginx]# docker network create ng_web_network ddc7f8925ad5df07beabacb8c0f556f152fef9f937cf48c97fdd8078a3f49e14 [root@status dockerfile_nginx]# docker network connect ng_web_network nginx [root@status dockerfile_nginx]# docker network connect ng_web_network test_tomcat 查看网络详情，里边有两个容器了。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 [root@status dockerfile_nginx]# docker network inspect ng_web_network [ { \u0026#34;Name\u0026#34;: \u0026#34;ng_web_network\u0026#34;, \u0026#34;Id\u0026#34;: \u0026#34;ddc7f8925ad5df07beabacb8c0f556f152fef9f937cf48c97fdd8078a3f49e14\u0026#34;, \u0026#34;Created\u0026#34;: \u0026#34;2024-09-19T09:55:24.921745354+08:00\u0026#34;, \u0026#34;Scope\u0026#34;: \u0026#34;local\u0026#34;, \u0026#34;Driver\u0026#34;: \u0026#34;bridge\u0026#34;, \u0026#34;EnableIPv6\u0026#34;: false, \u0026#34;IPAM\u0026#34;: { \u0026#34;Driver\u0026#34;: \u0026#34;default\u0026#34;, \u0026#34;Options\u0026#34;: {}, \u0026#34;Config\u0026#34;: [ { \u0026#34;Subnet\u0026#34;: \u0026#34;172.19.0.0/16\u0026#34;, \u0026#34;Gateway\u0026#34;: \u0026#34;172.19.0.1\u0026#34; } ] }, \u0026#34;Internal\u0026#34;: false, \u0026#34;Attachable\u0026#34;: false, \u0026#34;Containers\u0026#34;: { \u0026#34;d14c7820921dd0150c1d4c9e9ff786164201f10f86c7dc63db6522ded8b2405a\u0026#34;: { \u0026#34;Name\u0026#34;: \u0026#34;test_tomcat\u0026#34;, \u0026#34;EndpointID\u0026#34;: \u0026#34;da006a7767d6937f310880a114c7d24a085c87573c84a9b47b91c99f79211473\u0026#34;, \u0026#34;MacAddress\u0026#34;: \u0026#34;02:42:ac:13:00:03\u0026#34;, \u0026#34;IPv4Address\u0026#34;: \u0026#34;172.19.0.3/16\u0026#34;, \u0026#34;IPv6Address\u0026#34;: \u0026#34;\u0026#34; }, \u0026#34;ef443ef68ec75631a11ee52eeb2d8831610582a257154350cadb5af5ac72a97e\u0026#34;: { \u0026#34;Name\u0026#34;: \u0026#34;nginx\u0026#34;, \u0026#34;EndpointID\u0026#34;: \u0026#34;19569264099f4fdd3723309ff9512a2dbe9b6eea3b51e7318b2e8c1dba1a4074\u0026#34;, \u0026#34;MacAddress\u0026#34;: \u0026#34;02:42:ac:13:00:02\u0026#34;, \u0026#34;IPv4Address\u0026#34;: \u0026#34;172.19.0.2/16\u0026#34;, \u0026#34;IPv6Address\u0026#34;: \u0026#34;\u0026#34; } }, \u0026#34;Options\u0026#34;: {}, \u0026#34;Labels\u0026#34;: {} } ] nginx 跳转 tomcat 失败\r[!IMPORTANT]\nnginx 还是跳转不到 tomcat，问了 AI ：\n因为我在【dockerfile 实践一】里，对 tomcat 容器的端口进行映射，将 tomcat 8080 端口映射到了主机 8080 端口。不知道为啥不能这样，先试试。\n所以我用镜像再生成一个没有映射端口的 tomcat 容器，看看效果。\n1）重新执行镜像，并加入到 network 中\n1 2 [root@status ~]# docker run -d --name tomcat --network ng_web_network test:v1 fe5b1183ab41931e8e4c33c8c6cd4b03b4c098cd6212c91986a78b006c9a2533 2）把有端口映射的容器从这个 network 中移除\n1 docker network disconnect ng_web_network test_tomcat 3）打开代理地址看看能否跳转\n一般出现了连接超时，肯定是网络没通\n查看网络，没反应，说明没通\n1 [root@status ~]# docker exec -it nginx curl http://139.196.97.87:808 网络没通的原因\r[!IMPORTANT]\nDocker 网络内部使用 DNS 服务来解析容器名称到其 IP 地址的映射。\n当在一个自定义网络中启动容器时，Docker 会为每个容器分配一个唯一的 IP 地址，并注册其容器名称到 Docker 内部 DNS 服务器。因此，在同一网络中的其他容器可以使用容器名称来访问它。\n看一下这个 network 里边容器的 IP\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 [root@status ~]# docker network inspect ng_web_network ... \u0026#34;Containers\u0026#34;: { \u0026#34;ef443ef68ec75631a11ee52eeb2d8831610582a257154350cadb5af5ac72a97e\u0026#34;: { \u0026#34;Name\u0026#34;: \u0026#34;nginx\u0026#34;, \u0026#34;EndpointID\u0026#34;: \u0026#34;19569264099f4fdd3723309ff9512a2dbe9b6eea3b51e7318b2e8c1dba1a4074\u0026#34;, \u0026#34;MacAddress\u0026#34;: \u0026#34;02:42:ac:13:00:02\u0026#34;, \u0026#34;IPv4Address\u0026#34;: \u0026#34;172.19.0.2/16\u0026#34;, \u0026#34;IPv6Address\u0026#34;: \u0026#34;\u0026#34; }, \u0026#34;fe5b1183ab41931e8e4c33c8c6cd4b03b4c098cd6212c91986a78b006c9a2533\u0026#34;: { \u0026#34;Name\u0026#34;: \u0026#34;tomcat\u0026#34;, \u0026#34;EndpointID\u0026#34;: \u0026#34;0c304895c8bdb0c149cb8ded2511d79d851be71059174e35551fbe80ce2e14e1\u0026#34;, \u0026#34;MacAddress\u0026#34;: \u0026#34;02:42:ac:13:00:04\u0026#34;, \u0026#34;IPv4Address\u0026#34;: \u0026#34;172.19.0.4/16\u0026#34;, \u0026#34;IPv6Address\u0026#34;: \u0026#34;\u0026#34; } ... 在【Dockerfile 实践 - 实践二 - 3 nginx 配置】中，配置的跳转的 IP 是我主机的 IP，而这个 tomcat 是运行在容器里的，实际的 tomcat 地址应该是 172.19.0.4:8080 ，我通过 nginx 的地址 139.196.97.87:80 跳转到 172.19.0.4:8080 才对。因为 docker network 是使用容器名来解析容器的 IP，所以这里我就需要跳转到 tomcat:8080 。\n解决问题\r好了，明白原因，改一下 nginx.conf 配置，然后更新到 nginx 容器内部 /etc/nginx/nginx.conf\n1）nginx.conf 配置改为这样\n1 2 3 4 5 6 server { listen 80; server_name 139.196.97.87; location / { proxy_pass http://tomcat:8080; } 2）使用 cp 命令传进去，然后重启 nginx 服务\n1 2 3 4 # 传进去 docker container cp nginx.conf nginx:/etc/nginx/nginx.conf # 重启 docker exec nginx nginx -s reload nginx -s reload 是重启 nginx 命令\n然后访问 139.196.97.87:80 ，成功跳转\n总结\r应用如果是通过 nginx 跳转，则应用容器不需要映射端口 应用通过 nginx 跳转，将应用和 nginx 容器都加入到同一个 network 中即可实现互相访问 在同一个 network 中，使用容器名解析容器的IP，所以相关配置应该填写容器名 疑问\r1.如果先映射了端口，后续想用 nginx 做代理的话，如何清除原来的端口映射？如果重新生成容器，原来的数据怎么办？\n2.日志怎么处理？应用的日志、nginx 的日志怎么快速的查看？怎么做归集到专门的日志目录里？\n","date":"2024-09-13T13:56:41+08:00","permalink":"http://localhost:1313/posts/2024/09/docker-dockerfile%E4%B8%8Enetwork%E5%AE%9E%E8%B7%B5/","title":"Docker-dockerfile构建镜像与network实践"},{"content":" 根据《docker 技术入门与实践（第 3 版）》进行学习\n对命令有疑问，可使用：\n1）docker 命令 \u0026ndash;help\n2）man docker 命令\n查看帮助，其中 man docker 命令 里边有详细的解释，包括示例\nDocker 安装的目录：\n1 2 3 4 5 6 7 8 9 10 11 12 [root@status volumes]# cd /var/lib/docker/ [root@status docker]# ll total 36 drwx------ 4 root root 4096 Aug 30 13:23 containers\t# 容器 drwx------ 3 root root 4096 Jul 22 14:58 image\t# 镜像 drwxr-x--- 3 root root 4096 Jul 22 14:58 network\t# 网络 drwx------ 10 root root 4096 Aug 30 13:28 overlay2 drwx------ 4 root root 4096 Jul 22 14:58 plugins drwx------ 2 root root 4096 Jul 22 14:58 swarm drwx------ 2 root root 4096 Aug 29 14:52 tmp drwx------ 2 root root 4096 Jul 22 14:58 trust drwx------ 3 root root 4096 Aug 30 16:27 volumes\t# 数据卷 Docker 核心概念\r三大核心概念：\n镜像 image 容器 container 仓库 repository Docker 大部分的操作都是围绕这三个核心进行\n镜像\r镜像是创建容器的基础：运行镜像 \u0026raquo; 生成容器 镜像本身是只读的。 [!IMPORTANT]\n启动镜像生成容器的时候，容器会在镜像的最上层创建一个可写层。 可以把镜像看作一块光盘，里边有黑神话，直接插入光盘，游戏就可以运行，省去不同平台下载安装的麻烦。\n容器\r容器就是一个盒子，里边打包放了很多东西：操作系统、进程、网络、用户等。\n仓库\r仓库注册服务器是存放仓库的地方，仓库就是存放镜像的地方，各个镜像文件通过不同的标签进行区分。\n仓库有公开仓库和私有仓库\nDocker 基础\rDocker 镜像\r搜索镜像\r使用 search 命令在 Docker 仓库中搜索镜像\n1 2 3 4 5 docker search 镜像名 # 例子 docker search nginx docker search centos 获取镜像\r1 docker pull 镜像名[:标签] 这里的标签就是这个镜像的版本号，可忽略，不指定的话会默认下载仓库中最新版本（latest）的镜像。一般从稳定性考虑，最好还是输入标签，让各个环境的版本一致。\n但是一开始如何知道 pull 了什么版本的镜像呢？\n当我们 pull 镜像到本机，可以使用 docker inspect 查看镜像的详细信息。然后里边会有相关的信息版本，比如这里的 nginx_version=1.21.5\n1 2 3 4 5 6 \u0026#34;Env\u0026#34;: [ \u0026#34;PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\u0026#34;, \u0026#34;NGINX_VERSION=1.21.5\u0026#34;, \u0026#34;NJS_VERSION=0.7.1\u0026#34;, \u0026#34;PKG_RELEASE=1~bullseye\u0026#34; ] 然后可以给这个镜像打上版本的 tag\n1 docker tag nginx:latest naginx:1.21.5 查看镜像信息\rDocker 镜像的信息可以通过相关命令查看\n使用 images 命令列出镜像\r1 2 3 # 2 种查看命令 docker images docker image ls 列出本地主机上已有镜像的基本信息\n1 2 3 4 5 6 [root@status ~]# docker images REPOSITORY TAG IMAGE ID CREATED SIZE docker.io/centos latest 5d0da3dc9764 2 years ago 231 MB [root@status ~]# docker image ls REPOSITORY TAG IMAGE ID CREATED SIZE docker.io/centos latest 5d0da3dc9764 2 years ago 231 MB 基本信息解释如下：\nREPOSITORY - 来源哪个库\nTAG - 镜像标签（版本）\nIMAGE_ID - 镜像ID\nCREATED - 创建时间\nSIZE - 镜像大小\n使用 tag 命令添加镜像标签\r可以使用 docker tag 命令为本地镜像添加新的标签\n1 docker tag 镜像名:标签 新镜像名:新标签 相等于这个镜像的别名，因为添加新的标签，它俩的镜像ID是一样的，本质上都是一个镜像。跟 Linux 里的 链接 类似。\n这个例子，给 centos:latest 镜像添加新的标签 test:10086\n1 2 3 4 5 [root@status ~]# docker tag centos:latest test:10086 [root@status ~]# docker images REPOSITORY TAG IMAGE ID CREATED SIZE docker.io/centos latest 5d0da3dc9764 2 years ago 231 MB test 10086 5d0da3dc9764 2 years ago 231 MB 使用 inspect 命令查看详细信息\r使用 docker inspect 命令获取镜像的详细信息：制作者、适用框架、各层数字摘要等\n1 2 docker inspect 镜像名[:标签] docker inspect 镜像ID 使用 history 命令查看镜像历史\r镜像文件由多个层组成，查看各个层的内容具体是什么，使用 history 命令\n1 2 3 4 5 [root@status test]# docker history centos IMAGE CREATED CREATED BY SIZE COMMENT 5d0da3dc9764 2 years ago /bin/sh -c #(nop) CMD [\u0026#34;/bin/bash\u0026#34;] 0 B \u0026lt;missing\u0026gt; 2 years ago /bin/sh -c #(nop) LABEL org.label-schema.... 0 B \u0026lt;missing\u0026gt; 2 years ago /bin/sh -c #(nop) ADD file:805cb5e15fb6e0b... 231 MB 删除镜像\rdocker rmi 或者 docker image rm 命令可以删除镜像\n使用名称+标签删除镜像\r1 2 3 4 5 docker rmi 镜像名[:标签] docker image rm 镜像名[:标签] docker rmi [options] 镜像名[:标签] docker image rm [options] 镜像名[:标签] 该命令支持的选项：\n-force 强制删除镜像，有容器依赖这个镜像，也会删除 -no-prune 不要清理未带标签的父镜像 1 docker rmi -force -no-prune 镜像名[:标签] 例子：删除【1.3.2】步骤中的 test:10086 镜像标签\n1 2 3 4 5 6 [root@status test]# docker rmi test:10086 Untagged: test:10086 Untagged: docker.io/centos@sha256:a27fd8080b517143cbbbab9dfb7c8571c40d67d534bbdee55bd6c473f432b177 [root@status test]# docker images REPOSITORY TAG IMAGE ID CREATED SIZE docker.io/centos latest 5d0da3dc9764 2 years ago 231 MB 例子：彻底删除镜像，当该镜像没有任何标签的时候，删除镜像，就真的没有了\n1 [root@status test]# docker rmi centos:latest 使用镜像ID删除镜像\r使用镜像ID进行删除，会将该镜像+它的标签，一起删除\n1 docker rmi 镜像ID 镜像已经运行，生成容器了，那这个镜像是无法被删除的。可以通过 -force 强制删除。 1 docker rmi -force 镜像ID 不推荐直接删除镜像的，应该先删除该镜像相关的容器，再删除镜像 1 2 docker rm 容器ID docker rmi 镜像ID 清理镜像\r在 Docker 使用一段时间后，可能会遗留一些临时的镜像文件，以及一些没有使用的镜像，可以通过 docker image prune 命令清理掉。\n1 docker image prune 该命令支持的选项：\n-a 删除所有无用镜像（临时 + 没有被使用的） -f 强制删除 -filter 只清理复核给定过滤器的镜像 例子：自动清理临时的镜像文件层\n1 2 [root@status test]# docker image prune -f Total reclaimed space: 0 B 创建镜像\r创建镜像的方法：\n基于已有容器创建（前提是这个容器的镜像还在） 基于本地模板导入 基于 Dockerfile 创建 基于已有容器创建\r使用 docker commit 命令\n1 docker commit 容器ID 镜像名[:标签] 支持的选项：\n-a 作者信息 -m 给这个镜像添加备注（可以使用 docker inspect 镜像名[:标签] 查看，具体见【1.3.3】步骤） -p 提交时暂停容器的运行（一般不用的吧？） 例子\r1）先启动一个镜像，并到容器里执行一个命令\n1 2 3 4 [root@status go]# docker run -it centos:latest /bin/bash [root@720ef900dddc /]# touch test [root@720ef900dddc /]# exit exit 这个容器ID = 720ef900dddc\n这个容器，因为已经在里边进行增删改操作，容器内容与它的镜像内容已经不一样了。这个时候可以基于这个容器进行创建一个新的镜像出来。\n2）基于这个容器创建新的镜像\n1 2 [root@status go]# docker commit -m \u0026#34;Add a new file\u0026#34; -a \u0026#34;weiqi\u0026#34; 720ef900dddc test:20240829_V1 sha256:9e0017db11d154d7c08c964a14745afd25a667a7b82b68a8a61381bd7a5de205 详解：\n-m 给这个镜像加备注\n-a 作者信息\n720ef900dddc 容器ID\ntest:20240829_V1 镜像名:标签\n3）查看镜像列表\n1 2 3 4 [root@status go]# docker images REPOSITORY TAG IMAGE ID CREATED SIZE test 20240829_V1 9e0017db11d1 50 seconds ago 231 MB docker.io/centos latest 5d0da3dc9764 2 years ago 231 MB 这里生成了一个新的镜像 test\n可以使用 docker inspect 9e0017db11d1 查看它的详细信息，里边就有作者信息、镜像的备注\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 [root@status go]# docker inspect 9e0017db11d1 [ { \u0026#34;Id\u0026#34;: \u0026#34;sha256:9e0017db11d154d7c08c964a14745afd25a667a7b82b68a8a61381bd7a5de205\u0026#34;, \u0026#34;RepoTags\u0026#34;: [ \u0026#34;test:20240829_V1\u0026#34; ], \u0026#34;RepoDigests\u0026#34;: [], \u0026#34;Parent\u0026#34;: \u0026#34;sha256:5d0da3dc976460b72c77d94c8a1ad043720b0416bfc16c52c45d4847e53fadb6\u0026#34;, \u0026#34;Comment\u0026#34;: \u0026#34;Add a new file\u0026#34;, \u0026#34;Created\u0026#34;: \u0026#34;2024-08-29T06:26:49.211537969Z\u0026#34;, \u0026#34;Container\u0026#34;: \u0026#34;720ef900dddc4666e553ed9c26458b6fd4df541fa0939930b4479925d2ca2f0e\u0026#34;, \u0026#34;ContainerConfig\u0026#34;: { \u0026#34;Hostname\u0026#34;: \u0026#34;720ef900dddc\u0026#34;, \u0026#34;Domainname\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;User\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;AttachStdin\u0026#34;: true, \u0026#34;AttachStdout\u0026#34;: true, \u0026#34;AttachStderr\u0026#34;: true, \u0026#34;Tty\u0026#34;: true, \u0026#34;OpenStdin\u0026#34;: true, \u0026#34;StdinOnce\u0026#34;: true, \u0026#34;Env\u0026#34;: [ \u0026#34;PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\u0026#34; ], \u0026#34;Cmd\u0026#34;: [ \u0026#34;/bin/bash\u0026#34; ], \u0026#34;Image\u0026#34;: \u0026#34;centos:latest\u0026#34;, \u0026#34;Volumes\u0026#34;: null, \u0026#34;WorkingDir\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;Entrypoint\u0026#34;: null, \u0026#34;OnBuild\u0026#34;: null, \u0026#34;Labels\u0026#34;: { \u0026#34;org.label-schema.build-date\u0026#34;: \u0026#34;20210915\u0026#34;, \u0026#34;org.label-schema.license\u0026#34;: \u0026#34;GPLv2\u0026#34;, \u0026#34;org.label-schema.name\u0026#34;: \u0026#34;CentOS Base Image\u0026#34;, \u0026#34;org.label-schema.schema-version\u0026#34;: \u0026#34;1.0\u0026#34;, \u0026#34;org.label-schema.vendor\u0026#34;: \u0026#34;CentOS\u0026#34; } }, \u0026#34;DockerVersion\u0026#34;: \u0026#34;1.13.1\u0026#34;, \u0026#34;Author\u0026#34;: \u0026#34;weiqi\u0026#34;, \u0026#34;Config\u0026#34;: { \u0026#34;Hostname\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;Domainname\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;User\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;AttachStdin\u0026#34;: false, \u0026#34;AttachStdout\u0026#34;: false, \u0026#34;AttachStderr\u0026#34;: false, \u0026#34;Tty\u0026#34;: false, \u0026#34;OpenStdin\u0026#34;: false, \u0026#34;StdinOnce\u0026#34;: false, \u0026#34;Env\u0026#34;: [ \u0026#34;PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\u0026#34; ], \u0026#34;Cmd\u0026#34;: [ \u0026#34;/bin/bash\u0026#34; ], \u0026#34;Image\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;Volumes\u0026#34;: null, \u0026#34;WorkingDir\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;Entrypoint\u0026#34;: null, \u0026#34;OnBuild\u0026#34;: null, \u0026#34;Labels\u0026#34;: { \u0026#34;org.label-schema.build-date\u0026#34;: \u0026#34;20210915\u0026#34;, \u0026#34;org.label-schema.license\u0026#34;: \u0026#34;GPLv2\u0026#34;, \u0026#34;org.label-schema.name\u0026#34;: \u0026#34;CentOS Base Image\u0026#34;, \u0026#34;org.label-schema.schema-version\u0026#34;: \u0026#34;1.0\u0026#34;, \u0026#34;org.label-schema.vendor\u0026#34;: \u0026#34;CentOS\u0026#34; } }, \u0026#34;Architecture\u0026#34;: \u0026#34;amd64\u0026#34;, \u0026#34;Os\u0026#34;: \u0026#34;linux\u0026#34;, \u0026#34;Size\u0026#34;: 231268873, \u0026#34;VirtualSize\u0026#34;: 231268873, \u0026#34;GraphDriver\u0026#34;: { \u0026#34;Name\u0026#34;: \u0026#34;overlay2\u0026#34;, \u0026#34;Data\u0026#34;: { \u0026#34;LowerDir\u0026#34;: \u0026#34;/var/lib/docker/overlay2/c36ca0390a29eaefd180fcb6f80d57f127acfa92b9bedbd09a6d84c3a2e6e9f2/diff\u0026#34;, \u0026#34;MergedDir\u0026#34;: \u0026#34;/var/lib/docker/overlay2/8548138b25638a23cdff292a6548e6e8698d59d98afde1866ea91684cfd2600b/merged\u0026#34;, \u0026#34;UpperDir\u0026#34;: \u0026#34;/var/lib/docker/overlay2/8548138b25638a23cdff292a6548e6e8698d59d98afde1866ea91684cfd2600b/diff\u0026#34;, \u0026#34;WorkDir\u0026#34;: \u0026#34;/var/lib/docker/overlay2/8548138b25638a23cdff292a6548e6e8698d59d98afde1866ea91684cfd2600b/work\u0026#34; } }, \u0026#34;RootFS\u0026#34;: { \u0026#34;Type\u0026#34;: \u0026#34;layers\u0026#34;, \u0026#34;Layers\u0026#34;: [ \u0026#34;sha256:74ddd0ec08fa43d09f32636ba91a0a3053b02cb4627c35051aff89f853606b59\u0026#34;, \u0026#34;sha256:b43592c44888d32269515c418d4f4d02b9517cc0642ef2960bbe9c4efbd0924c\u0026#34; ] } } ] 基于本地模板导入镜像\r使用 docker import 命令\n1 docker import fileName - 镜像名:标签 这个就不试了，没有本地模板\n基于 Dockerfile 创建镜像\r实际工作中，这个方式最常见\nDockerfile 是一个文件，利用给定的指令描述基于某个父镜像创建新的镜像。它里边相当于描述了创建的过程。\n例子\r没有例子，先了解，后边再补充\n存出和载入镜像\r存出和载入镜像如何理解？就是导出和导入的意思。\n存出镜像：就是将镜像保存到本地，方便给别的机器使用 载入镜像：在新机器把镜像文件给加载出来使用 存出镜像\r使用 docker save 命令\n1 2 docker save -o 存出的文件名 镜像名:标签 docker save -o 存出的文件名 镜像ID -o 就是 output 的意思\n例子\n1 2 3 4 5 6 [root@status go]# docker save -o centos.tar.gz centos:latest [root@status go]# docker save -o test.tar.gz 9e0017db11d1 [root@status go]# ll total 466000 -rw------- 1 root root 238581248 Aug 29 14:50 centos.tar.gz -rw------- 1 root root 238587904 Aug 29 14:52 test.tar.gz 这两个就是镜像文件了，把这个拿给别人，直接加载使用就可以\n载入镜像\r使用 docker load 命令\n1 2 docker load -i centos.tar.gz docker load -i test.tar.gz 然后再使用 docker images 查看镜像列表，看看加载成功没，就可以了。\n上传镜像\r使用 docker push 命令推送镜像到镜像仓库，默认是推送到 Docker Hub 的。\n1 docker push 镜像名:标签 | 仓库IP:仓库端口/镜像名:标签 例子\r用户 WeiQ 想要推送本地的镜像 centos:latest 到仓库中，怎么推？\n先给要推送的镜像添加新的标签，再推送这个标签的镜像，方便区分是 WeiQ 推送的\n1 2 docker tag centos:latest WeiQ/centos:latest docker push WeiQ/centos:latest 运行镜像\r使用 docker run 命令，它是运行镜像，生成对应的容器，所以这个命令也可以归为运行容器。\n与启动容器命令是一样的\nDocker 容器\r容器，是运行镜像生成的，并且是有可写文件层的 容器，是集合了 应用 + 操作环境 的一个盒子 创建容器\r创建容器涉及到\ncreate 创建 start 启动容器 run 创建并启动 wait logs 新建容器\r创建容器的命令是 docker create ，创建的容器是非运行状态；可通过 docker ps -a 查看新创建的容器\n1 docker create -it 镜像名:标签 它支持的选项很多，一般常用就 -it --name -d -p -e\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 --name：为容器指定一个名称。 -it：这是两个选项的组合，-i 允许你通过 STDIN 与容器交互，-t 分配一个伪终端。 -d：以守护态（后台）运行容器。 -p：映射容器的端口到宿主机的端口。 -P：随机映射所有暴露的端口到宿主机的端口。 -v：挂载宿主机的一个卷到容器内。 -e：设置环境变量。 --env-file：从一个文件中读取环境变量。 --network：将容器连接到指定的网络。 --restart：设置容器的重启策略。 --cpus：限制容器可以使用的 CPU 数量。 --memory：限制容器可以使用的内存量。 --memory-swap：限制容器可以使用的内存加上交换空间的总和。 --entrypoint：覆盖镜像的默认入口点。 --cmd：覆盖镜像的默认命令。 --label：设置容器的元数据标签。 --user：指定运行容器的用户。 --workdir：指定容器的工作目录。 --hostname：设置容器的主机名。 --mac-address：设置容器的 MAC 地址。 --ip：设置容器的 IPv4 地址（当使用自定义网络时）。 --add-host：添加自定义的 host-to-IP 映射（host:IP）。 --volume-driver：指定容器的卷驱动。 --stop-signal：设置停止容器的信号。 例子，创建一个别名为 centos7 的容器\n1 2 3 4 5 [root@status ~]# docker create --name centos7 -it centos:latest 77c3b94004ddb337d7a1fd66aa4b7a4c45347918a1664020618e82eb1438655a [root@status ~]# docker ps -a CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 77c3b94004dd centos:latest \u0026#34;/bin/bash\u0026#34; 2 seconds ago Created centos7 启动容器\r使用 docker start 命令\n1 2 docker start 容器名 docker start 容器ID 然后可以使用 docker ps 查看正在运行的容器\n1 2 3 4 5 [root@status ~]# docker start centos7 centos7 [root@status ~]# docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 77c3b94004dd centos:latest \u0026#34;/bin/bash\u0026#34; 23 minutes ago Up 6 seconds centos7 新建并启动容器\r使用 docker run 命令\n1 2 3 docker run -it 镜像名:标签 docker run -it 镜像ID docker run -it --name 容器名称 镜像ID -i\t让容器的标准输入保存打开，就是打开容器的执行窗口\n-t\t让 Docker 分配一个伪终端并绑定到容器的标准输入上\n1 2 3 4 5 [root@status ~]# docker run -d --name centos7 -it centos:latest c0121f9cb884f0783b86c077cb027025cc472515fe2d9267d4073e7000a9bd7c [root@status ~]# docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES c0121f9cb884 centos:latest \u0026#34;/bin/bash\u0026#34; 30 minutes ago Up 30 minutes centos7 执行 docker run 的原理\r执行时，docker 在后台的操作：\n1）检查本地是否存在镜像，不存在则从共有仓库拉取\n2）利用镜像创建一个容器，并启动容器\n3）分配一个文件系统给容器，并在只读的镜像层外挂载一层可读写层\n4）从宿主主机配置的网桥接口接一个虚拟接口到容器中\n5）从网桥的地址池配置一个 IP 地址给容器\n6）执行用户指定的应用程序\nexit 退出销毁容器 *\rdocker run 是会生成容器的，那这里的创建容器是为了什么？因为创建新容器，它里边不就什么都没有？\n[!IMPORTANT]\nrun 命令其实是 create 与 start 命令的合集，它等于创建容器、启动容器\n验证：\n1）运行镜像，进入容器进行增删改操作\n1 2 3 4 5 [root@status ~]# docker run -it centos:latest [root@b0d385386935 /]# cd /home/ [root@b0d385386935 home]# touch test.txt [root@b0d385386935 home]# ls test.txt 2）然后退出容器，看看容器是否存在\n1 2 3 4 [root@b0d385386935 home]# exit exit [root@status ~]# docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 3）不存在容器，重新运行镜像，进入容器，查看刚刚创建的 test.txt 文件\n1 2 3 4 [root@status ~]# docker run -it centos:latest [root@6e198af7152d /]# cd /home/ [root@6e198af7152d home]# ls [root@6e198af7152d home]# 已经没有了，且这个容器ID也改变了。\n[!IMPORTANT]\n结论，运行镜像生成容器，在容器内使用 exit 命令退出的时候，容器也会销毁。重新运行镜像则是会生成一个全新的容器。\n20241009：这里其实是退出容器，并且这个容器因为执行完命令了，处于退出的状态，并没有销毁，可使用 docker ps -a 查看它。\n退出不销毁容器 *\r在容器内部，我退出的时候，不销毁容器，让容器继续运行，应该如何操作？\n1）使用 ctrl + p 再使用 ctrl + q\n1 2 3 4 5 6 [root@status ~]# docker run -it centos:latest # ctrl + p # ctrl + q [root@status ~]# docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 7f64fc558ccb centos:latest \u0026#34;/bin/bash\u0026#34; 14 seconds ago Up 13 seconds loving_swanson 2）可以重新进入这个容器\n1 2 [root@status ~]# docker exec -it 7f64fc558ccb /bin/bash [root@7f64fc558ccb /]# 退出容器 *\r如果是退出并销毁容器，使用 exit 命令；\n如果是退出但保留容器在后台运行，使用 ctrl + p 再使用 ctrl + q\n后台运行容器\r让容器在后台运行，使用 -d 选项\n1 docker run -d 镜像名:标签 查看容器输出\r1 docker logs [选项] 容器ID 选项可以有：\n\u0026ndash;detail\t打印详细信息\n-f\t持续保持输出\n\u0026ndash;tail string\t输出从某个时间开始的日志\n列出容器\r使用 docker ps 命令，列出容器列表\n[!IMPORTANT]\ndocker ps 列出当前运行的容器\n支持的参数：\n-a 列出所有的容器（运行 + 已停止）\n-q\t只列出容器 ID\n-aq\t列出所有容器ID\n-l\t显示最近创建的容器信息\n-n 5\t显示最后创建的 5 个容器信息\n停止容器\r有暂停容器、有终止容器，如何理解？\n[!IMPORTANT]\n可以把容器看作一个应用进程，暂停容器，就是把进程先暂停，后续还可以直接恢复运行状态。\n终止容器，就是把这个应用进程给 KILL 掉了，也就是这个容器被彻底关掉了。\npause unpause stop prune 暂停容器\r使用 docker pause 命令暂停容器的运行（只是暂停运行，非销毁\\删除），使用 docker ps 命令还能查到\n1 2 docker pause 容器名 docker pause 容器ID 1 2 3 4 5 6 7 8 [root@status ~]# docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES c0121f9cb884 centos:latest \u0026#34;/bin/bash\u0026#34; 30 minutes ago Up 30 minutes centos7 [root@status ~]# docker pause centos7 centos7 [root@status ~]# docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES c0121f9cb884 centos:latest \u0026#34;/bin/bash\u0026#34; 32 minutes ago Up 32 minutes (Paused) centos7 停止之后，STUTAS 变为了 Paused\n恢复运行\r使用 docker unpause 命令恢复容器的运行\n1 2 docker unpause 容器名 docker unpause 容器ID 终止容器\r使用 docker stop 命令。把容器给 KILL 掉，使用 docker ps 查看不到了。（这个不是删除容器！）\n1 2 docker stop 容器名 docker stop 容器ID 1 2 3 4 [root@status ~]# docker stop centos7 centos7 [root@status ~]# docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 使用 docker ps -a 还是可以看到这个容器\n重启容器\r其实就是【2.1.2 启动容器】步骤\n1 2 3 4 5 6 docker start 容器名 docker start 容器ID # 重启 docker restart 容器名 docker restart 容器ID 1 2 3 4 5 [root@status ~]# docker start centos7 centos7 [root@status ~]# docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES c0121f9cb884 centos:latest \u0026#34;/bin/bash\u0026#34; 46 minutes ago Up 5 seconds centos7 进入容器\r在【2.1.3 新建并启动容器】步骤中，通过 -d 让容器后台运行\n1 docker run --name centos7 -itd centos:latest 容器后台运行，是不会进入到容器内部的\n需要进入容器，使用 docker exec 命令\n1 2 docker exec -it 容器名 /bin/bash docker exec -it 容器ID /bin/bash 1 2 [root@status ~]# docker exec -it centos7 /bin/bash [root@c0121f9cb884 /]# 这里不使用 /bin/bash ，会进不去\n删除容器\rdocker rm 命令是删除容器\ndocker rmi 命令是删除镜像\n注意区别\n删除容器，通常是只能删除非运行状态的容器，使用 pause 暂停的容器也删除不了。必须是 docker ps 命令查不到的容器 强行删除，加入 -f 参数，或者先使用 stop 终止容器 1 2 docker rm -f 容器名 docker rm -f 容器ID 1 2 docker stop 容器名\u0026amp;容器ID docker rm 容器名\u0026amp;容器ID 1 2 3 4 5 6 7 8 9 10 11 12 [root@status ~]# docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES c0121f9cb884 centos:latest \u0026#34;/bin/bash\u0026#34; 2 hours ago Up 2 hours centos7 [root@status ~]# docker stop centos7 centos7 [root@status ~]# docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES [root@status ~]# docker rm centos7 centos7 [root@status ~]# docker ps -a CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES [root@status ~]# 导入和导出容器\r这个就跟 【1.7 存出和载入镜像】类似，将整体容器导出到文件，然后导入到其他机器中，就可以使用了。\n导出容器\r使用 docker export 命令\n1 docker export -o 文件名.tar.gz 容器名或者容器ID 1 2 3 4 5 6 7 8 9 10 11 [root@status ~]# docker run --name centos7 -itd centos:latest 9fb9bacc6189204e54463401d3e91326a1256a8bec59d4737e600bc76d789d11 [root@status ~]# docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 9fb9bacc6189 centos:latest \u0026#34;/bin/bash\u0026#34; 3 seconds ago Up 2 seconds centos7 8a848522fedf centos:latest \u0026#34;/bin/bash\u0026#34; 29 seconds ago Up 28 seconds stupefied_swartz [root@status ~]# docker export -o container_centos7.tar.gz centos7 [root@status ~]# ll total 233008 -rw------- 1 root root 238592512 Aug 30 13:24 container_centos7.tar.gz 导入容器\r使用 docker import 命令，导入容器，将变为镜像文件\n1 docker import 包名 名称:标签 例子\r1 2 3 4 5 6 7 [root@status ~]# docker import container_centos7.tar.gz test_import/centos:20240830_V1 sha256:592397d362e5fb6e89f5718e13c19a9f8a74562a7f97c10108aa4b30c9e3c0f2 [root@status ~]# docker images REPOSITORY TAG IMAGE ID CREATED SIZE test_import/centos 20240830_V1 592397d362e5 7 seconds ago 231 MB test 20240829_V1 9e0017db11d1 23 hours ago 231 MB docker.io/centos latest 5d0da3dc9764 2 years ago 231 MB 将 container_centos7.tar.gz 导入，生成一个 test_import/centos 的镜像文件，标签是 20240830_V1\n迁移环境有 2 种方式\r1 打包镜像\r1）打包镜像，【1.6.1 基于已有容器创建】章节，以现在容器创建一个镜像文件\n2）将这个镜像文件，放到其他机器里，载入镜像文件，【1.7.2 载入镜像】章节。\n2 打包容器\r1）打包容器，【2.6.1 导出容器】，生成一个容器文件\n2）将这个容器文件，放到其他机器里，导入容器文件，【2.6.2 导入容器】\n3 区别\r其实没啥区别，除了执行的命令有区别，本质上都是将这个容器打包成文件，然后在其他机器上加载生成新镜像，然后运行这个镜像就可以得到一模一样的容器了。\n查看容器\r在【1.3 查看镜像信息】章节，可以使用 inspect 查看镜像的详细信息\n其实 inspect 还可以查看容器的详细信息\n查看镜像信息是 docker inspect 查看容器信息是 docker container inspect 查看容器详情\r1 2 3 docker container inspect 容器名\\容器ID docker container [options] inspect 容器名\\容器ID 支持的选项：\n使用 docker container inspect --help 查看，或者\n使用 man docker container inspect 查看\n1 [root@status ~]# docker container inspect centos7 会有容器ID、创建时间、路径、状态、镜像、配置等\n查看容器内进程\r1 2 3 docker container top 容器名\\容器ID docker top 容器名\\容器ID 使用 docker container top 方便区分是容器的操作命令\n1 2 3 [root@status ~]# docker container top centos7 UID PID PPID C STIME TTY TIME CMD root 31467 31450 0 13:23 pts/2 00:00:00 /bin/bash 查看统计信息\r1 2 3 docker container stats 容器名\\容器ID docker container stats [options] 容器名\\容器ID 支持的选项：\n-a\t输出所有容器统计信息，不加就是显示运行状态的容器信息\n\u0026ndash;format string\t格式化输出信息\n\u0026ndash;no-stream\t不持续输出，默认是自动更新实时结果的\n其他容器命令\rcp diff port update 复制文件 cp\rcp 命令支持在容器与主机之间复制文件\n1 docker container cp 主机内容 容器:/容器路径/ 也可以从容器传到主机\n1 docker container cp 容器:/路径/文件 /主机路径 例子\n将本地的 sh 文件复制到 centos7 容器的 tmp 目录下\n1 2 3 4 5 6 7 8 9 10 11 [root@status shell]# docker container cp /home/shell/serviceCheckDay.sh centos7:/tmp [root@status shell]# docker exec -it centos7 /bin/bash [root@9fb9bacc6189 /]# cd tmp/ [root@9fb9bacc6189 tmp]# ls ks-script-4luisyla ks-script-o23i7rc2 ks-script-x6ei4wuu serviceCheckDay.sh [root@9fb9bacc6189 tmp]# ls -l total 16 -rwx------ 1 root root 701 Sep 15 2021 ks-script-4luisyla -rwx------ 1 root root 671 Sep 15 2021 ks-script-o23i7rc2 -rwx------ 1 root root 291 Sep 15 2021 ks-script-x6ei4wuu -rwxr-xr-x 1 root root 2467 Jul 23 03:13 serviceCheckDay.sh 查看变更 diff\rdiff 命令\n1 docker container diff 容器名\\容器ID 1 2 3 4 5 [root@status shell]# docker container diff centos7 C /run D /run/secrets C /tmp A /tmp/serviceCheckDay.sh 有变更的目录和文件都显示出来\n查看端口映射 port\rport 命令\n1 docker container port 容器名\\容器ID 更新配置 update\rupdate 命令\n1 docker container update 容器名\\容器ID --需要更新的参数 参数：用到再看\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 [root@status shell]# docker container update --help Usage: docker container update [OPTIONS] CONTAINER [CONTAINER...] Update configuration of one or more containers Options: --blkio-weight uint16 Block IO (relative weight), between 10 and 1000, or 0 to disable (default 0) --cpu-period int Limit CPU CFS (Completely Fair Scheduler) period --cpu-quota int Limit CPU CFS (Completely Fair Scheduler) quota --cpu-rt-period int Limit the CPU real-time period in microseconds --cpu-rt-runtime int Limit the CPU real-time runtime in microseconds -c, --cpu-shares int CPU shares (relative weight) --cpuset-cpus string CPUs in which to allow execution (0-3, 0,1) --cpuset-mems string MEMs in which to allow execution (0-3, 0,1) --help Print usage --kernel-memory string Kernel memory limit -m, --memory string Memory limit --memory-reservation string Memory soft limit --memory-swap string Swap limit equal to memory plus swap: \u0026#39;-1\u0026#39; to enable unlimited swap --restart string Restart policy to apply when a container exits 仓库\r官方仓库 Docker Hub ，现在已经被墙了\n使用国内的仓库源就可以\n具体配置了一个阿里云的镜像仓库，看《Docker 安装与配置》，配置文件为 /etc/docker/daemon.json\n搭建本地私有仓库 *\r先不看\nDocker 进阶\rDocker 数据管理\r在生成环境种使用 Docker ，特别是数据库放在 Docker 里，或者应用中上传的文件、资料等，需要对数据进行持久化，否则在进行应用版本升级或者容器挂掉后，重新利用镜像生成容器，数据全没了。\n之前做某银行的审计内控项目，使用的 Docker 部署应用，每当应用需要修改或者优化的时候，都需要重新上传应用包到某个地方，然后部署。他们应该使用 devops 一键部署的，我上传包到对应的地方，然后执行一个 yaml 命令，每次都是重新生成容器，原先的东西就全没了。\n数据管理有 2 种方式：\n数据卷 Data Volumns：容器内数据直接映射到本地主机环境 数据卷容器 Data Volume Containers：使用特定容器维护数据卷 如何在容器内创建数据卷？\n如何把本地目录或者文件挂到容器内的数据卷？\n如何在容器和主机之间共享数据？\n如何实现容器数据的备份和恢复？\n数据卷\r数据卷是将主机的目录映射进容器，类似 linux 的 mount 挂载共享盘。\n数据卷，在各个容器之间都可以共享数据 对数据卷内的数据进行修改，容器和本机的数据也会修改。并且容器可以修改数据卷里的内容，本机也可以 数据卷内的数据修改，不会影响到镜像 创建数据卷\r使用 docker volume 命令\n1 docker volume create -d local 数据卷名称 -d\t表示字符串指定卷驱动程序名称（默认为“local”）\n例子\n1）在本地创建一个 vol_test 数据卷\n1 2 [root@status /]# docker volume create -d local vol_test vol_test 2）可以在 Docker 安装目录下查看数据卷\n1 2 3 4 5 [root@status /]# cd /var/lib/docker/volumes [root@status volumes]# ll total 28 -rw------- 1 root root 32768 Aug 30 16:27 metadata.db drwxr-xr-x 3 root root 4096 Aug 30 16:27 vol_test 查看数据卷详细信息\r使用 docker volume inspect 命令\n1 2 3 4 5 6 7 8 9 10 11 [root@status /]# docker volume inspect vol_test [ { \u0026#34;Driver\u0026#34;: \u0026#34;local\u0026#34;, \u0026#34;Labels\u0026#34;: {}, \u0026#34;Mountpoint\u0026#34;: \u0026#34;/var/lib/docker/volumes/vol_test/_data\u0026#34;, \u0026#34;Name\u0026#34;: \u0026#34;vol_test\u0026#34;, \u0026#34;Options\u0026#34;: {}, \u0026#34;Scope\u0026#34;: \u0026#34;local\u0026#34; } ] 列出所有数据卷\r使用 docker volume ls 命令\n1 2 3 [root@status /]# docker volume ls DRIVER VOLUME NAME local vol_test 清理无用数据卷\r使用 docker volume prune 命令\n1 2 3 4 5 6 7 8 9 [root@status /]# docker volume prune WARNING! This will remove all volumes not used by at least one container. Are you sure you want to continue? [y/N] y Deleted Volumes: vol_test Total reclaimed space: 0 B [root@status /]# docker volume ls DRIVER VOLUME NAME 删除数据卷\r使用 docker volume rm 命令\n1 docker volume rm 数据卷名称 1 2 3 4 5 6 7 8 9 [root@status /]# docker volume create -d local data_test data_test [root@status /]# docker volume ls DRIVER VOLUME NAME local data_test [root@status /]# docker volume rm data_test data_test [root@status /]# docker volume ls DRIVER VOLUME NAME 绑定数据卷\r创建容器的时候，可以直接将本地的任意路径挂载到容器内作为数据卷，这种形式本质上也是创建一个数据卷，只不过它是在创建容器的时候直接绑定了，所以叫绑定数据卷。\n使用 -mount 命令进行绑定，它有 3 种类型的数据卷：\nvolume 普通数据卷，映射到主机 /var/lib/docker/volume 路径下 bind 绑定数据卷，映射到主机指定路径下 tmpfs 临时数据卷，只存在内存中 例子：\n将本地的 /home/go 目录挂载到容器 /opt/web 内，作为容器卷\n1 docker run -d -P --name web -v /home/go:/opt/web centos:latest -P 是映射所有端口 这里直接绑定数据卷的容器，使用 docker ps -a 命令查看，它的状态是：Exited\n1 2 3 [root@status ~]# docker ps -a CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 3577d310d7b1 centos:latest \u0026#34;/bin/bash\u0026#34; 4 minutes ago Exited (0) 4 minutes ago web 不清楚啥原因，先把它删了：\n1 docker rm 3577d310d7b1 再重新创建容器并绑定数据卷，这次在命令后边接执行命令\n1 docker run -d -P --name web -v /home/go:/opt/web centos:latest /bin/bash 啊，不行，先跳过，这个不知道为啥\n数据卷容器\r如果需要在多个容器之间共享一些持续更新的数据，使用数据卷容器是最简单的方式。\n数据卷容器也是一个容器，只不过它提供数据卷，给其他容器挂载。\n例子\r1）创建一个数据卷容器，并在其中创建数据卷挂载到容器里，将本地的 /dbdata 挂载到容器 dbdata 里\n1 2 3 4 [root@status ~]# docker run -it -v /dbdata --name dbdata centos:latest [root@bab3308ef270 /]# ls bin dbdata dev etc home lib lib64 lost+found media mnt opt proc root run sbin srv sys tmp usr var [root@bab3308ef270 /]# [root@status ~]# 使用 ctrl+p 再 ctrl+q 让容器在后台运行\n2）在其他容器中使用 --volumes-from 来挂载容器中的数据卷\n可以创建新的容器，并挂载这个数据卷容器\n1 2 3 [root@status ~]# docker run -it --volumes-from dbdata --name db1 centos:latest [root@64e8cf50b3be /]# ls bin dbdata dev etc home lib lib64 lost+found media mnt opt proc root run sbin srv sys tmp usr var 这里 db1 容器里，已经有了这个 dbdata 数据卷容器了\n3）在容器内，往数据卷容器创建新文件，看看数据卷容器是否也被创建\n进入数据卷容器，可以看到，是可以同步的\n1 2 3 4 [root@status ~]# docker exec -it dbdata /bin/bash [root@bab3308ef270 /]# cd /dbdata/ [root@bab3308ef270 dbdata]# ls test.go 4）再创建一个容器并挂载数据卷容器\n1 2 3 4 5 6 [root@status ~]# docker run -it --volumes-from dbdata --name db2 centos:latest [root@0bcca546d72d /]# ls bin dbdata dev etc home lib lib64 lost+found media mnt opt proc root run sbin srv sys tmp usr var [root@0bcca546d72d /]# cd dbdata/ [root@0bcca546d72d dbdata]# ls test.go 5）在数据卷容器里操作，其他容器也同时生效，因为里边的数据是共享的\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 [root@status ~]# docker exec -it dbdata /bin/bash [root@bab3308ef270 /]# ls bin dbdata dev etc home lib lib64 lost+found media mnt opt proc root run sbin srv sys tmp usr var [root@bab3308ef270 /]# cd dbdata/ [root@bab3308ef270 dbdata]# ls test.go [root@bab3308ef270 dbdata]# mkdir test1 test2 test3 [root@bab3308ef270 dbdata]# ls test.go test1 test2 test3 [root@bab3308ef270 dbdata]# rm -rf test.go [root@bab3308ef270 dbdata]# [root@status ~]# [root@status ~]# docker exec -it db2 /bin/bash [root@0bcca546d72d /]# cd dbdata/ [root@0bcca546d72d dbdata]# ls test1 test2 test3 [!IMPORTANT]\n总结\n正常的，数据卷容器只要存在，就可以相当于 NFS 或者 NAS 一样，作为一个挂载盘在容器之间共享。只要这个容器不被销毁。\n注意\r数据卷容器，本质上是一个容器，只不过它是挂载了数据卷，然后又将这个容器挂载到其他容器中。\n使用 docker volume ls 查看的是数据卷 使用 docker ps 查看的是数据卷容器 利用数据卷容器进行数据迁移\r因为数据卷容器，它就是个容器，将这个容器导出来，放到其他机器上，可以实现数据的迁移、备份。\n使用数据卷容器备份数据\r理论上是可以的，验证一下看看：\n1）导出容器\n1 2 3 4 [root@status ~]# docker export -o bak.tar.gz dbdata [root@status ~]# ll total 233008 -rw------- 1 root root 238593024 Sep 3 16:13 bak.tar.gz 2）导入容器\n1 2 3 4 5 [root@status ~]# docker import bak.tar.gz bak_test:20240903V1 sha256:01b390296306643a0ea36d203a846b306d185069937ab3f618fbb864fc1a47a5 [root@status ~]# docker images REPOSITORY TAG IMAGE ID CREATED SIZE bak_test 20240903V1 01b390296306 4 minutes ago 231 MB 3）进入容器，看看是否 dbdata 目录是否还有文件？\n1 2 3 4 5 6 7 8 9 10 11 12 13 [root@status ~]# docker run -d -it bak_test:20240903V1 /bin/bash 17a3da2583a3a37c153b6d34afb19c65f8b9f202377ab04af9e315a2edb1db7b [root@status ~]# ls bak.tar.gz [root@status ~]# docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 17a3da2583a3 bak_test:20240903V1 \u0026#34;/bin/bash\u0026#34; 18 seconds ago Up 17 seconds heuristic_jang [root@status ~]# docker exec -it heuristic_jang /bin/bash [root@17a3da2583a3 /]# ls bin dbdata dev etc home lib lib64 lost+found media mnt opt proc root run sbin srv sys tmp usr var [root@17a3da2583a3 /]# cd dbdata/ [root@17a3da2583a3 dbdata]# ls [root@17a3da2583a3 dbdata]# dbdata 里边没有数据，很奇怪\n4）查看数据卷容器\n1 2 3 4 5 6 [root@status ~]# docker exec -it dbdata /bin/bash [root@bab3308ef270 /]# ls bin dbdata dev etc home lib lib64 lost+found media mnt opt proc root run sbin srv sys tmp usr var [root@bab3308ef270 /]# cd dbdata/ [root@bab3308ef270 dbdata]# ls test1 test2 test3 数据卷容器的文件还是有的，但是导出的时候好像并没有导出来？\ndocker 容器是基于镜像生成的，镜像是一个静态的文件系统，它不会自动包含导入时附带的数据卷的。\n如果需要导入时包含数据卷里的数据，可以绑定数据卷，将这个 bak.tar.gz 映射到容器内，然后解压它。\n结论：\n不能使用数据卷容器备份数据\n使用数据卷容器备份数据卷\r不能使用数据卷容器做备份，但是可以备份它里边的数据卷，使用 docker run 命令\n1 docker run --volumes-from 数据卷容器 -v $(pwd):/bakup --name 新容器名 镜像名:标签 执行的命令 例子\n1 docker run --volumes-from dbdata -v $(pwd):/bakup --name worker centos:latest tar -cvf /bakup/bakup.tar.gz /dbdata 命令详解：\n--volumes-from 是让容器 worker 挂载 dbdata 数据卷容器 -v $(pwd):/bakup 是将当前目录，都映射到 worker 容器里的 /bakup 目录 tar 命令，就是运行容器之后，立马执行的命令 注意\r这个命令生成的容器，因为 tar 命令是前台命令，命令执行完成后，容器会停止。如果需要在后台继续运行该容器，则可以这样\n1 docker run -it --volumes-from dbdata -v $(pwd):/bakup --name worker centos:latest /bin/bash -c \u0026#34;tar -cvf /bakup/bakup.tar.gz /dbdata\u0026#34; 使用数据卷容器恢复数据 *\r这个百度或者问问 AI\n涉及到数据备份和恢复的，都是挺重要的章节，看看怎么单独实践一张。\n端口映射、容器互联\r生产上，通常各个容器会互相协作，特别是微服务架构的应用，每个服务一个容器。还有数据库与应用之间的互联，应用需要访问到数据库的端口。\n映射容器内应用的服务端口到本地主机 互联机制实现多个容器间通过容器名来快速访问 容器的端口映射\r如果在启动容器的时候，没有指定对应的端口参数，容器外部是无法通过网络访问容器内的应用服务的。\n通过 -p 或者 -P 参数进行端口映射\n-p 可以指定具体的端口 -P 是随机映射一个 49000 ~ 49900 的端口 首先，要知道，容器一旦运行起来是不能修改其端口映射的，必须重新运行一个容器并在启动时就进行映射。\n1 dokcer run -d --name 容器名 -p 外部映射端口:容器应用端口 镜像名:标签 从外部访问容器应用\r1）启动 nginx 容器，并进行端口映射\n1 2 3 4 5 [root@status ~]# docker run -d --name nginx -p 8088:80 nginx:1.21.5 1bb6ac4fee9793393c1fa9066f61105201a5f94e3cb5bc1fb4fe463f96bbe647 [root@status ~]# docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 1bb6ac4fee97 nginx:1.21.5 \u0026#34;/docker-entrypoin...\u0026#34; 6 seconds ago Up 5 seconds 0.0.0.0:8088-\u0026gt;80/tcp nginx 可以看到 0.0.0.0:8088 -\u0026gt; 80/tcp ，说明外部的 8088 端口映射到了容器内部的 80 端口，这个时候，在外部就可以使用 8088 端口访问到容器内部的 80 端口了\n2）通过宿主机 IP:PORT 的形式访问 nginx\n因为使用的阿里云服务器，所以使用阿里云服务器的 IP:8088 去访问 nginx，前提是阿里云服务器上开通 8088 端口\n把 阿里云的安全组的访问规则开通一下 8088 端口，然后就可以访问了\n3）查看 docker nginx 日志\n1 2 3 4 5 [root@status ~]# docker logs nginx ...... 140.207.163.4 - - [06/Sep/2024:02:31:56 +0000] \u0026#34;GET / HTTP/1.1\u0026#34; 200 615 \u0026#34;-\u0026#34; \u0026#34;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/128.0.0.0 Safari/537.36 Edg/128.0.0.0\u0026#34; \u0026#34;-\u0026#34; 2024/09/06 02:31:56 [error] 30#30: *1 open() \u0026#34;/usr/share/nginx/html/favicon.ico\u0026#34; failed (2: No such file or directory), client: 140.207.163.4, server: localhost, request: \u0026#34;GET /favicon.ico HTTP/1.1\u0026#34;, host: \u0026#34;139.196.97.87:8088\u0026#34;, referrer: \u0026#34;http://139.196.97.87:8088/\u0026#34; 140.207.163.4 - - [06/Sep/2024:02:31:56 +0000] \u0026#34;GET /favicon.ico HTTP/1.1\u0026#34; 404 555 \u0026#34;http://139.196.97.87:8088/\u0026#34; \u0026#34;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/128.0.0.0 Safari/537.36 Edg/128.0.0.0\u0026#34; \u0026#34;-\u0026#34; 可以看到里边记录着谁访问了这个地址\n映射所有接口地址\r使用 -p port:容器port 的形式，就是默认映射所有地址的，就上边【2.1.1】步骤，这个就是所有地址都可以访问到 8088 端口\n1 dokcer run -d --name 容器名 -p 外部映射端口:容器应用端口 镜像名:标签 映射到指定地址的指定端口\r使用 -p 指定地址:指定端口:容器端口 可以指定映射的地址和端口\n1 docker run -d --name 容器名 -p 指定外部地址:指定外部映射端口:容器应用端口 镜像名:标签 映射到指定地址的任意端口\r使用 -p 指定地址::容器端口 可以映射到指定地址的所有端口\n1 docker run -d --name 容器名 -p 指定外部地址::容器应用端口 镜像名:标签 查看映射端口的配置\r使用 docker port 容器名 命令查看容器当前映射的端口配置\n1 2 [root@status ~]# docker port nginx 80/tcp -\u0026gt; 0.0.0.0:8088 查看容器的 IP\r可以使用 docker container inspect 查看容器的详细信息，包含 IP\n1 docker container inspect 容器名 容器互联\r容器互联，可以让多个容器之间的应用进行互相访问，最常见的就是应用容器得访问到数据库容器，应用才能正常运行。\n容器的互相连接，采用容器名的方式连接\n使用 --link 参数，可以让容器互联 [!CAUTION]\nAI回答：\n\u0026ndash;link 是旧版 docker 的用法，新版（docker 1.9）已经不推荐使用了，因为它需要停止容器后，重新 run 容器才能设置互联。\n新版使用 network （docker 的网络功能）连接容器，创建一个网络，然后将需要互联的容器都放到同一个网络中，就可以实现容器互联。\n所以，更推荐 network 用法\nnetwork 用法\r模板\n1 docker network 命令选项 网络名 create 创建 connection 将容器连接到网络 disconnection 将容器从网络中移除 inspect 展示网络的详细信息 ls 展示网络列表 prune 删除所有不在使用的网络 rm 删除网络 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 # 1.创建 docker network create 网络名称 # 2.将容器加入网络中 docker network connect 网络名称 \u0026lt;容器1的ID或名字\u0026gt; docker network connect 网络名称 \u0026lt;容器2的ID或名字\u0026gt; # 3.将容器从网络中移除 docker network disconnect 网络名称 \u0026lt;容器1的ID或名字\u0026gt; # 4.展示网络详细信息 docker network inspect 网络名称 # 5.网络列表 docker network ls # 6.删除所有不在使用的网络 docker network prune # 7.删除网络 docker network rm 网络名称 例子\r将现有的 nginx 容器与 tomcat 容器进行互联（这里使用 network 进行容器互联）\n1）启动一个 tomcat 容器，不设置映射端口（一般通过 nginx 进行访问 tomcat，所以有 nginx 能在外部访问到就行）\n1 2 [root@status ~]# docker run -d --name tomcat tomcat:10.0.14 59c519066587ee0ad708f99b91a8d04f0a66c2e087a9327dfdf003832140503c 2）创建一个 docker 网络\n1 2 3 4 5 6 7 8 [root@status ~]# docker network create web_network 5b1463443f2a443e2f7fa8277ac96eafcc0c9f0866302b910ce507394d667714 [root@status ~]# docker network ls NETWORK ID NAME DRIVER SCOPE 833b114c72d5 bridge bridge local ea34ff8ed89e host host local c142124b84e6 none null local 5b1463443f2a web_network bridge local 3）将 tomcat 容器和 nginx 容器都拉进来\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 [root@status ~]# docker network connect web_network tomcat [root@status ~]# docker network connect web_network nginx [root@status ~]# docker network inspect web_network [ { \u0026#34;Name\u0026#34;: \u0026#34;web_network\u0026#34;, \u0026#34;Id\u0026#34;: \u0026#34;5b1463443f2a443e2f7fa8277ac96eafcc0c9f0866302b910ce507394d667714\u0026#34;, \u0026#34;Created\u0026#34;: \u0026#34;2024-09-06T11:21:49.319643032+08:00\u0026#34;, \u0026#34;Scope\u0026#34;: \u0026#34;local\u0026#34;, \u0026#34;Driver\u0026#34;: \u0026#34;bridge\u0026#34;, \u0026#34;EnableIPv6\u0026#34;: false, \u0026#34;IPAM\u0026#34;: { \u0026#34;Driver\u0026#34;: \u0026#34;default\u0026#34;, \u0026#34;Options\u0026#34;: {}, \u0026#34;Config\u0026#34;: [ { \u0026#34;Subnet\u0026#34;: \u0026#34;172.18.0.0/16\u0026#34;, \u0026#34;Gateway\u0026#34;: \u0026#34;172.18.0.1\u0026#34; } ] }, \u0026#34;Internal\u0026#34;: false, \u0026#34;Attachable\u0026#34;: false, \u0026#34;Containers\u0026#34;: { \u0026#34;1bb6ac4fee9793393c1fa9066f61105201a5f94e3cb5bc1fb4fe463f96bbe647\u0026#34;: { \u0026#34;Name\u0026#34;: \u0026#34;nginx\u0026#34;, \u0026#34;EndpointID\u0026#34;: \u0026#34;405bee2c3142c87ac6e9d007e021dd4ea4a95e9191ae72dd394343e7fead50e3\u0026#34;, \u0026#34;MacAddress\u0026#34;: \u0026#34;02:42:ac:12:00:03\u0026#34;, \u0026#34;IPv4Address\u0026#34;: \u0026#34;172.18.0.3/16\u0026#34;, \u0026#34;IPv6Address\u0026#34;: \u0026#34;\u0026#34; }, \u0026#34;59c519066587ee0ad708f99b91a8d04f0a66c2e087a9327dfdf003832140503c\u0026#34;: { \u0026#34;Name\u0026#34;: \u0026#34;tomcat\u0026#34;, \u0026#34;EndpointID\u0026#34;: \u0026#34;2296bfc0dbf18154fac66e0100b770cf342b2e8556cde98432bc694839b06ba9\u0026#34;, \u0026#34;MacAddress\u0026#34;: \u0026#34;02:42:ac:12:00:02\u0026#34;, \u0026#34;IPv4Address\u0026#34;: \u0026#34;172.18.0.2/16\u0026#34;, \u0026#34;IPv6Address\u0026#34;: \u0026#34;\u0026#34; } }, \u0026#34;Options\u0026#34;: {}, \u0026#34;Labels\u0026#34;: {} } ] Dockerfile 构建镜像\rDockerfile 里各个指令填写的文件目录，一般是上下文路径，不需要加路径。只有放入镜像内部的路径才填写绝对路径。\nDockerfile 是一个文件，主要内容：\n基础镜像信息 FROM 维护者信息 LABEL 镜像操作指令 RUN 容器启动时执行指令 CMD 设置容器的环境变量 ENV 使用 FROM 指令指明基于哪个基础镜像创建\n使用 LABEL 指令说明作者信息\n使用 RUN 指令在镜像中执行命令\n使用 CMD 指令来指定容器启动的时候执行哪些命令\nDockerfile 主要指令\rDockerfile 指令 说明 FROM 指定基础镜像，用于后续的指令构建。 MAINTAINER 指定Dockerfile的作者/维护者。（已弃用，推荐使用LABEL指令） LABEL 添加镜像的元数据，使用键值对的形式。 RUN 在构建过程中在镜像中执行命令。 CMD 指定容器创建时的默认命令。（可以被覆盖） ENTRYPOINT 设置容器创建时的主要命令。（不可被覆盖） EXPOSE 声明容器运行时监听的特定网络端口。 ENV 在容器内部设置环境变量。 ADD 将文件、目录或远程URL复制到镜像中。 COPY 将文件或目录复制到镜像中。 VOLUME 为容器创建挂载点或声明卷。 WORKDIR 设置后续指令的工作目录。 USER 指定后续指令的用户上下文。 ARG 定义在构建过程中传递给构建器的变量，可使用 \u0026ldquo;docker build\u0026rdquo; 命令设置。 ONBUILD 当该镜像被用作另一个构建过程的基础时，添加触发器。 STOPSIGNAL 设置发送给容器以退出的系统调用信号。 HEALTHCHECK 定义周期性检查容器健康状态的命令。 SHELL 覆盖Docker中默认的shell，用于RUN、CMD和ENTRYPOINT指令。 配置指令\rFROM\rDockerfile中第一条指令必须是 FROM 指令\n1 FROM 镜像名[:标签] [AS 别名] 为了保证镜像精简，可以使用包小的镜像，比如 Alpine \\ Debian 作为基础镜像\n1 2 3 4 5 6 7 8 9 10 好像是可以有几个 FROM 的？ FROM RUN ... FROM RUN .... FROM RUN ..。 LABEL\rLABEL指令是给镜像添加元数据标签信息的，包含镜像的基本信息，键值对的形式。可以有多个 LABEL 。\n1 2 3 4 LABEL 键1=值1 LABEL 键2=值2 LABEL 键3=值3 ... 1 2 3 4 LABEL version=\u0026#34;V1.0\u0026#34; LABEL author=\u0026#34;Weii\u0026#34; LABEL description=\u0026#34;这里一个例子\\ 可以换行\u0026#34; EXPOSE\r声明镜像内服务监听的端口。仅仅是声明，不会自动完成端口映射，映射还得是启动容器时的 -p 参数【2.1】步骤。\n1 EXPOSE 端口 ENV\r指定镜像的环境变量，环境变量在启动容器时也会存在。键值对的形式，也可以有多个 ENV。\n1 2 3 4 ENV 键1=值1 ENV 键2=值2 ENV 键3=值3 ... 1 2 3 4 ENV JAVA_HOME=/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.272.b10-7.ky10.aarch64 ENV JRE_HOME=/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.272.b10-7.ky10.aarch64/jre ENV CLASSPATH=.:$JAVA_HOME/lib:$JRE_HOME/lib ENV PATH=$JAVA_HOME/bin:$PATH VOLUME\r数据卷，给镜像创建一个数据卷挂载点\n1 VOLUME [\u0026#34;/path\u0026#34;] 可以在 Dockerfile 直接用 VOLUME 创建，也可以不用。到时候启动容器的时候使用参数挂载数据卷。\nUSER\r指定运行容器时的用户名（指服务器用户名）\n1 USER 用户名 WORKDIR\r配置容器的主工作目录，给后续的 RUN \\ CMD 等指令配置工作目录，RUN \\ CMD 执行的命令，就是在这个目录下执行的\n1 WORKDIR /path/to/dir SHELL\r指定使用 shell 时的默认 shell 类型\n操作指令\rRUN\r运行指令\n1 2 3 4 5 6 7 RUN 命令1 RUN 命令2 RUN 命令3 RUN 命令4 \u0026amp;\u0026amp; 命令5 \u0026amp;\u0026amp; 命令6 RUN 命令7 \\ \u0026amp;\u0026amp; 命令8 \\ \u0026amp;\u0026amp; 命令9 注意：\n每条 RUN 指令都会生成一层镜像层，都是在上一层的基础上生成新的一层。 可以使用 \\ 来换行 合理的利用 RUN 分层，可以提供构建效率 CMD\r指定启动容器时执行的命令\n1 CMD 命令 注意：\n每个 Dockerfile 只能有一条 CMD 指令，如果有多条，则会被最后一条覆盖，只有最后一条会执行。 如果启动容器时指定了执行参数，则会覆盖掉 CMD 指令 docker run -d \u0026ndash;name 容器名 镜像名:标签 执行的命令\n这里执行的命令，会覆盖掉 Dockerfile 里的 CMD 指令\nADD\r添加内容到镜像，一般填写镜像里的绝对路径；\n复制的路径，则是 dockerfile 所在的目录，所有包都需要在同一个目录，不能加路径。\n1 ADD 需要复制的路径 容器里的绝对路径 比如：复制当前目录内容到容器内的 /home 目录\n1 ADD . /home 比如\n1 2 ADD jdk.tar.gz /home/install ADD apache-tomcat-10.1.30.tar.gz /home/install 它会直接解压这个 tar 包到 /home/install 里，所以 RUN 命令不用跟着 tar -xzvf 命令了。\nCOPY\r复制内容到镜像，跟 ADD 差不多，用 ADD。\n创建镜像\r在编写完 Dockerfile 后，使用 docker image build 命令创建镜像\n1 docker image build -t 镜像名称:标签 Dockerfile的路径 该命令的逐条执行 Dockerfile 里的 RUN 指令，如果 RUN 指令过多，会导致创建镜像缓慢。因为每一条 RUN 指令，都会生成一层新镜像，最后才合并到一起。\n同样的，docker image build 支持很多选项，具体可需要时百度\n选择父镜像\r生成新的镜像都是基于 Dockerfile 的 FROM 指令中指定的父镜像，父镜像是生成镜像的基础，会影响到生成镜像的大小和功能。\n使用 .dockerignore 文件\r不看\n多步骤创建\r总结\r[!IMPORTANT]\ndocker 主要是4个大部分的命令：\n镜像命令 容器命令 数据卷命令 网络命令 inspect 都是查看详细信息\nls 都是列出列表\n","date":"2024-09-01T13:56:41+08:00","permalink":"http://localhost:1313/posts/2024/09/docker-%E5%9F%BA%E7%A1%80/","title":"Docker-基础"},{"content":"某证券的异常交易项目的测试环境已经早没了，只有生产环境。因为都是稳定运行的项目，一般开发完直接上生产，具体遇到问题在生产上排查。但是由于流程逐渐严格，所有发包必须走流程，经测试部验证后才能上产线，所以需要搭个测试环境。但是这个项目已经很早了，关于项目的数据库用户，有框架用户、产品用户，还有客户给自己创建的用户，总共 100 + 。当时看着客户提供过来的需创建的用户，头大。所以就有了批量创建的想法。\n首先需要知道，创建表空间、创建用户的语句\n1 2 3 4 5 6 7 8 -- 创建表空间 CREATE TABLESPACE \u0026#34;TS_TEST\u0026#34; DATAFILE \u0026#39;/home/dmdba/data/TS_TEST.DBF\u0026#39; SIZE 500 AUTOEXTEND ON NEXT 40 MAXSIZE UNLIMITED; -- 创建用户 CREATE USER \u0026#34;TEST\u0026#34; IDENTIFIED BY \u0026#34;123456789\u0026#34; DEFAULT TABLESPACE TS_TEST; -- *** 上方使用双引号是为了区分大小写，不用双引号都默认大写 *** 1 2 3 -- 创建表空间 CREATE TABLESPACE TABLESPACE_NAME DATAFILE \u0026#39;/home/ORACLE/data/TS_TEST.DBF\u0026#39; SIZE 500 AUTOEXTEND ON NOLOGGING EXTENT MANAGEMENT LOCAL; 实现方式一\r1.需要创建的表空间和用户使用 excel 整理好，一一对应\n2.创建表，存放表空间和用户数据\n1 CREATE TABLE TEST.T_TABLESPACE_USER(TABLESPACE_NAME VARCHAR2(200), USER_NAME VARCHAR2(200)); 3.开锁，把整理好的数据插入表中\n1 SELECT TABLESPACE_NAME, USER_NAME, ROWID FROM TEST.T_TABLESPACE_USER; 4.编写存储过程，循环创建\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 CREATE OR REPLACE PROCEDURE TEST.P_CREATE_TABLESPACE(I_BUSI_DATE IN VARCHAR2, O_RETURN_MSG OUT VARCHAR2, O_RETURN_CODE OUT INTEGER) IS --===================================================== -- AUTHOR: WQ -- MARK: 批量创建表空间\\用户程序 --===================================================== -- 变量 V_DATAFILE_PATH VARCHAR2(1000) DEFAULT \u0026#39;/home/oracle/data/testdb/\u0026#39;; -- 表空间路径 V_SIZE VARCHAR2(20) DEFAULT \u0026#39;100M\u0026#39;;\t-- 表空间默认大小 --===================================================== -- 业务处理过程 BEGIN DBMS_OUTPUT.PUT_LINE(\u0026#39;表空间创建：开始\u0026#39;); -- 遍历表空间名称 FOR TABLESPACE_REC IN (SELECT TABLESPACE_NAME FROM TEST.T_TABLESPACE_USER) LOOP EXECUTE IMMEDIATE \u0026#39;CREATE BIGFILE TABLESPACE \u0026#39; || TABLESPACE_REC.TABLESPACE_NAME || \u0026#39; DATAFILE \u0026#39;\u0026#39;\u0026#39; || V_DATAFILE_PATH || TABLESPACE_REC.TABLESPACE_NAME || \u0026#39;.DBF\u0026#39;\u0026#39;\u0026#39; || \u0026#39; SIZE \u0026#39; || V_SIZE || \u0026#39; AUTOEXTEND ON NOLOGGING EXTENT MANAGEMENT LOCAL\u0026#39;; -- 输出，方便查看创建结果 DBMS_OUTPUT.PUT_LINE(\u0026#39;表空间 \u0026#39; || TABLESPACE_REC.TABLESPACE_NAME || \u0026#39; 创建成功。\u0026#39;); END LOOP; DBMS_OUTPUT.PUT_LINE(\u0026#39;表空间创建：结束\u0026#39;); -- 设置返回值 O_RETURN_CODE := 1; O_RETURN_MSG := \u0026#39;执行成功\u0026#39;; EXCEPTION WHEN OTHERS THEN O_RETURN_CODE := SQLCODE; O_RETURN_MSG := SQLERRM; ROLLBACK; END; 奇怪，达梦里边报 语法分析错误，不太理解。\n\u0026hellip; 没设置兼容 ORACLE 语法，把 dm.ini 的 COMPATIBLE_MODE 改为 2 即可\n改正后\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 CREATE OR REPLACE PROCEDURE TEST.P_CREATE_TABLESPACE(I_BUSI_DATE IN VARCHAR2, O_RETURN_MSG OUT VARCHAR2, O_RETURN_CODE OUT INTEGER) IS --===================================================== -- AUTHOR: WQ -- MARK: 批量创建表空间\\用户程序 --===================================================== -- 变量 V_DATAFILE_PATH VARCHAR2(1000) DEFAULT \u0026#39;/home/dmdba/data/DAMENG/\u0026#39;; -- 表空间路径 V_SIZE VARCHAR2(20) DEFAULT \u0026#39;100M\u0026#39;;\t-- 表空间默认大小 --===================================================== -- 业务处理过程 BEGIN DBMS_OUTPUT.PUT_LINE(\u0026#39;表空间创建：开始\u0026#39;); -- 遍历表空间名称 FOR TABLESPACE_REC IN (SELECT TABLESPACE_NAME FROM TEST.T_TABLESPACE_USER) LOOP BEGIN EXECUTE IMMEDIATE \u0026#39;CREATE TABLESPACE \u0026#39; || TABLESPACE_REC.TABLESPACE_NAME || \u0026#39; DATAFILE \u0026#39;\u0026#39;\u0026#39; || V_DATAFILE_PATH || TABLESPACE_REC.TABLESPACE_NAME || \u0026#39;.DBF\u0026#39;\u0026#39;\u0026#39; || \u0026#39; SIZE \u0026#39; || V_SIZE || \u0026#39; AUTOEXTEND ON NEXT 40 MAXSIZE UNLIMITED\u0026#39;; -- 输出，方便查看创建结果 DBMS_OUTPUT.PUT_LINE(\u0026#39;表空间 \u0026#39; || TABLESPACE_REC.TABLESPACE_NAME || \u0026#39; 创建成功。\u0026#39;); EXCEPTION WHEN OTHERS THEN DBMS_OUTPUT.PUT_LINE(\u0026#39;表空间 \u0026#39; || TABLESPACE_REC.TABLESPACE_NAME || \u0026#39; 创建失败。错误信息：\u0026#39; || SQLERRM); END; END LOOP; DBMS_OUTPUT.PUT_LINE(\u0026#39;表空间创建：结束\u0026#39;); DBMS_OUTPUT.PUT_LINE(\u0026#39;用户创建：开始\u0026#39;); -- 遍历用户名称 FOR USER_REC IN (SELECT TABLESPACE_NAME, USER_NAME FROM TEST.T_TABLESPACE_USER) LOOP BEGIN EXECUTE IMMEDIATE \u0026#39;CREATE USER \u0026#39; || USER_REC.USER_NAME || \u0026#39; IDENTIFIED BY \u0026#39;\u0026#39;123456789\u0026#39;\u0026#39; \u0026#39; || \u0026#39;DEFAULT TABLESPACE \u0026#39; || USER_REC.TABLESPACE_NAME; -- 输出，方便查看创建结果 DBMS_OUTPUT.PUT_LINE(\u0026#39;用户 \u0026#39; || USER_REC.USER_NAME || \u0026#39; 创建成功。\u0026#39;); EXCEPTION WHEN OTHERS THEN DBMS_OUTPUT.PUT_LINE(\u0026#39;用户 \u0026#39; || USER_REC.USER_NAME || \u0026#39; 创建失败。错误信息：\u0026#39; || SQLERRM); END; END LOOP; DBMS_OUTPUT.PUT_LINE(\u0026#39;用户创建：结束\u0026#39;); -- 设置返回值 O_RETURN_CODE := 1; O_RETURN_MSG := \u0026#39;执行成功\u0026#39;; EXCEPTION WHEN OTHERS THEN O_RETURN_CODE := SQLCODE; O_RETURN_MSG := SQLERRM; -- ROLLBACK; END; 5.授权创建表空间\n1 grant create tablespace to TEST; 6.执行 SP 即可\n实现方式二\r其实也不用写存储过程\n1 2 3 4 5 6 7 8 9 10 11 -- 表空间语句 SELECT \u0026#39;CREATE TABLESPACE \u0026#39; || A.TABLESPACE_NAME || \u0026#39; DATAFILE \u0026#39;\u0026#39;\u0026#39; || \u0026#39;/home/dmdba/data/testdb/\u0026#39; || A.TABLESPACE_NAME || \u0026#39;.DBF\u0026#39;\u0026#39;\u0026#39; || \u0026#39; SIZE 500M AUTOEXTEND ON NEXT 40 MAXSIZE UNLIMITED;\u0026#39; FROM TEST.T_TABLESPACE_USER A; -- 用户语句 SELECT \u0026#39;CREATE USER \u0026#39; || A.USER_NAME || \u0026#39; IDENTIFIED BY \u0026#34;123456789\u0026#34; DEFAULT TABLESPACE \u0026#39; || A.TABLESPACE_NAME || \u0026#39;;\u0026#39; FROM TEST.T_TABLESPACE_USER A; ","date":"2024-08-28T21:02:51+08:00","permalink":"http://localhost:1313/posts/2024/08/sp-%E6%89%B9%E9%87%8F%E5%88%9B%E5%BB%BA%E8%A1%A8%E7%A9%BA%E9%97%B4%E5%92%8C%E7%94%A8%E6%88%B7/","title":"SP-批量创建表空间和用户"},{"content":" 参考官方文档：物理备份还原 | 达梦技术文档 (dameng.com)\n备份还原过程中的问题解决方案参考：备份还原 | 达梦技术文档 (dameng.com)\n备份还原其实也挺简单，就是备份，一般整库备份，一般开启联机备份。就是把全库导出来，然后重新刷进去的过程\n备份：就是从数据库文件拷贝出有效的数据页保存到备份集中\n还原：就是备份的逆过程，将备份集中的数据内容（数据文件、数据页、归档文件）重新写入到目标数据文件的过程。\n恢复：通过重做归档日志，将数据库恢复到备份结束时的状态，或者恢复到指定的时间点和LSN。\n备份还原基础\r相关术语\r联机备份还原：数据库处于运行状态时，进行的备份还原操作 脱机备份还原：数据库服务关闭的情况下，进行的备份还原操作 备份集：存放备份数据 备份的前提\r对数据库实例开启归档模式，并处于打开的状态（如果是集群的话，就不需要再打开了，因为集群搭建时就会打开归档。如果是单机版，有可能没有打开归档模式，需要先打开）\n1 2 3 4 ALTER DATABASE MOUNT; ALTER DATABASE ARCHIVELOG; ALTER DATABASE ADD ARCHIVELOG \u0026#39;DEST=/home/dmdba/dmdbms/DMDB/arch, TYPE=LOCAL, FILE_SIZE=1024, SPACE_LIMIT=10240\u0026#39;; ALTER DATABASE OPEN; 然后重新启动一下 达梦管理工具 ，不然达梦管理工具没刷新生效。建议直接到数据库服务器上使用 ./disql 操作\n联机与脱机备份还原的区别\r备份还原\r备份\r联机备份，就是数据库运行时进行备份。支持的备份有：\n数据库备份 用户表空间备份 用户表备份 归档备份 脱机备份，只支持：\n数据库备份 归档备份 表空间备份、表备份，只能联机备份！\n数据库备份命令\r1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 # 全备 BACKUP DATABASE FULL BACKUPSET \u0026#39;/opt/dmdbms/BAK/db_full_bak_01\u0026#39;; # 增备 BACKUP DATABASE INCREMENT BACKUPSET \u0026#39;/opt/dmdbms/BAK/db_full_bak_01\u0026#39;; # 设置备份压缩等级 COMPRESSED LEVEL BACKUP DATABASE FULL BACKUPSET \u0026#39;/home/dm_bak/db_bak_3_06\u0026#39; COMPRESSED LEVEL 5; # 设置并行备份 PARALLEL BACKUP DATABASE FULL BACKUPSET \u0026#39;/home/dm_bak/db_bak_3_07\u0026#39; PARALLEL 8; # 设置切片大小 MAXPIECESIZE BACKUP DATABASE FULL BACKUPSET \u0026#39;/home/dm_bak/db_bak_3_05\u0026#39; MAXPIECESIZE 300; # 设置备份文件的名称 TO BAK_NAME BACKUP DATABASE TO WEEKLY_FULL_BAK BACKUPSET \u0026#39;/home/dm_bak/db_bak_3_02\u0026#39;; # 添加备份备注 BACKUPINFO BACKUP DATABASE BACKUPSET \u0026#39;/home/dm_bak/db_bak_3_04\u0026#39; BACKUPINFO \u0026#39;完全备份\u0026#39;; 结合起来就是这样的：\n1 backup database full to \u0026#34;DB_DAMENG_FULL_2024_09_11_16_12_29\u0026#34; backupset \u0026#39;/home/dmdba/data/DAMENG/bak/DB_DAMENG_FULL_2024_09_11_16_12_29\u0026#39; backupinfo \u0026#39;全量备份\u0026#39; compressed level 1 parallel 8; 归档备份命令\r1 BACKUP ARCHIVE LOG ALL BACKUPSET \u0026#39;arch_bak_01\u0026#39;; 这个应该是全备？参数也跟【数据库备份命令】一样\n还原\r达梦的联机还原，只支持表的还原。库、表空间等均不支持。\n不推荐联机还原，当数据库需要还原时，肯定发生了一些大操作，使用脱机更好。\n还原可以还原到指定的备份集（不管是联机备份数据库备份集，还是脱机备份的数据库备份集），也可以还原到指定的归档文件。\n还原操作统一有一个工具 ./dmrman\nDMRMAN（DM RECOVERY MANAGER）是脱机备份还原命令行工具，无需额外安装，由它来统一负责库级脱机备份、脱机还原、脱机恢复等相关操作，该工具支持命令行指定参数方式和控制台交互方式执行，降低用户的操作难度。\n1 2 3 4 5 6 ##启动DMRMAN ./dmrman ##退出DMRMAN ##启动后控制台中输入 exit 命令 RMAN\u0026gt;exit; 备份还原实践（单机版）\r本次验证达梦单机版上的备份与还原，以防以后遇到后临时抱佛脚。\n注意：\n请确保开启了归档模式！不然无法备份的。 联机备份库、脱机还原库 所有操作没有特定说明，均使用 dmdba 用户进行操作 本次为 全量备份 + 增量备份 还原数据库的实践\n注意：\n当有全量备份 + 增量备份时，只需要使用最新的增量备份进行还原即可。但是全量备份文件不可删除，必须存在。 也可以只使用全量，但是会造成期间数据的丢失。 场景一：删表还原（全备 + 增备还原）\r使用全备 + 增备，通过最新的增备文件进行还原 备份\r因为我的测试库已经有一个 TEST 用户并且具有 DBA 权限，所以此处直接开始造数据，省略了建立表空间、用户、授权的前置步骤。\n在数据库中插入测试数据\r1 2 3 4 5 6 7 8 9 10 CREATE TABLE TEST.T_BAKUP_TEST( ID INT, BUSI_DATE DATE, DESCRIPTION VARCHAR2(200) ); INSERT INTO TEST.T_BAKUP_TEST VALUES(1, SYSDATE(), \u0026#39;这是一条测试数据，用于备份还原的验证\u0026#39;); INSERT INTO TEST.T_BAKUP_TEST VALUES(2, SYSDATE(), \u0026#39;aoedtl\u0026#39;); SELECT * FROM TEST.T_BAKUP_TEST; 数据如下：\n1 2 1\t2024-09-11 15:07:55\t这是一条测试数据，用于备份还原的验证 2\t2024-09-11 15:08:44\taoedtl 当然也有其他的测试表、数据、SP、表空间、用户等，顺便准备就行。\n执行全备\r1 BACKUP DATABASE FULL TO DB_DM_FULL_20240911_154700 BACKUPSET \u0026#39;/home/dmdba/data/DAMENG/bak\u0026#39; COMPRESSED LEVEL 5 ; 这个为啥备份了，名字没有按照命令设置？\n1 2 3 4 5 [root@status bak]# ll total 369736 -rw-r--r-- 1 dmdba dm 11264 Sep 11 16:01 bak_1.bak -rw-r--r-- 1 dmdba dm 378478080 Sep 11 16:01 bak.bak -rw-r--r-- 1 dmdba dm 116224 Sep 11 16:01 bak.meta 得这样：\n1 BACKUP DATABASE FULL TO \u0026#34;DB_DM_FULL_20240911_1618\u0026#34; BACKUPSET \u0026#39;/home/dmdba/data/DAMENG/bak/DB_DM_FULL_20240911_1618\u0026#39; COMPRESSED LEVEL 1; 执行增备\r第一次增备\r往数据库里添加点新数据\n1 2 INSERT INTO TEST.T_BAKUP_TEST VALUES(3, SYSDATE(), \u0026#39;第2条\u0026#39;); INSERT INTO TEST.T_BAKUP_TEST VALUES(4, SYSDATE(), \u0026#39;第3条\u0026#39;); 然后执行增备\n1 BACKUP DATABASE INCREMENT TO \u0026#34;DB_DM_INCREMENT_20240911_1623\u0026#34; BACKUPSET \u0026#39;/home/dmdba/data/DAMENG/bak/DB_DM_INCREMENT_20240911_1623\u0026#39; COMPRESSED LEVEL 1; 第二次增备\r1 2 3 4 INSERT INTO TEST.T_BAKUP_TEST VALUES(5, SYSDATE(), \u0026#39;第4条\u0026#39;); INSERT INTO TEST.T_BAKUP_TEST VALUES(6, SYSDATE(), \u0026#39;第5条\u0026#39;); BACKUP DATABASE INCREMENT TO \u0026#34;DB_DM_INCREMENT_20240911_1625\u0026#34; BACKUPSET \u0026#39;/home/dmdba/data/DAMENG/bak/DB_DM_INCREMENT_20240911_1625\u0026#39; COMPRESSED LEVEL 1; 查看备份集\r到服务器里看看，备份集\n1 2 3 4 5 [root@status bak]# ll total 12 drwxr-xr-x 2 dmdba dm 4096 Sep 11 16:19 DB_DM_FULL_20240911_1618 drwxr-xr-x 2 dmdba dm 4096 Sep 11 16:24 DB_DM_INCREMENT_20240911_1623 drwxr-xr-x 2 dmdba dm 4096 Sep 11 16:25 DB_DM_INCREMENT_20240911_1625 还原\r全备 + 增备后还原，看看表数据是否恢复正常\n删除表\r上边已经备份完成了，直接把上边创建的表删了，然后进行还原操作，看看是否恢复。\n1 DROP TABLE TEST.T_BAKUP_TEST; 还原操作\r1）关闭数据库服务\n1 2 3 [root@status bak]# cd /home/dmdba/dmdbms/bin [root@status bin]# ./DmServiceDASERVER stop Stopping DmServiceDASERVER: [ OK ] 2）启动 ./dmrman 服务进行校验备份集\n1 2 3 4 5 6 7 8 9 [root@status bin]# ./dmrman dmrman V8 # 校验最新的增量备份集 RMAN\u0026gt; CHECK BACKUPSET \u0026#39;/home/dmdba/data/DAMENG/bak/DB_DM_INCREMENT_20240911_1625\u0026#39;; CHECK BACKUPSET \u0026#39;/home/dmdba/data/DAMENG/bak/DB_DM_INCREMENT_20240911_1625\u0026#39;; [Percent:100.00%][Speed:0.00M/s][Cost:00:00:00][Remaining:00:00:00] check backupset successfully. time used: 166.999(ms) 3）还原\n1 2 3 4 5 6 7 8 9 RMAN\u0026gt; RESTORE DATABASE \u0026#39;/home/dmdba/data/DAMENG/dm.ini\u0026#39; FROM BACKUPSET \u0026#39;/home/dmdba/data/DAMENG/bak/DB_DM_INCREMENT_20240911_1625\u0026#39;; RESTORE DATABASE \u0026#39;/home/dmdba/data/DAMENG/dm.ini\u0026#39; FROM BACKUPSET \u0026#39;/home/dmdba/data/DAMENG/bak/DB_DM_INCREMENT_20240911_1625\u0026#39;; Normal of FAST Normal of DEFAULT Normal of RECYCLE Normal of KEEP Normal of ROLL [Percent:0.00%][Speed:0.00M/s][Cost:00:00:03][Remaining:00:00:00] [-8024]:数据文件读写出错 这里还原时，报错了 [-8024]\n查看官方文档：备份还原 | 达梦技术文档 (dameng.com)\n因为用户忘了切换，使用了 root 用户进行操作。需要使用 dmdba 用户进行操作才行，也要注意备份的文件 dmdba 用户是否有权限读写。\n切换dmdba 重新来\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 RMAN\u0026gt; RESTORE DATABASE \u0026#39;/home/dmdba/data/DAMENG/dm.ini\u0026#39; FROM BACKUPSET \u0026#39;/home/dmdba/data/DAMENG/bak/DB_DM_INCREMENT_20240911_1625\u0026#39;; RESTORE DATABASE \u0026#39;/home/dmdba/data/DAMENG/dm.ini\u0026#39; FROM BACKUPSET \u0026#39;/home/dmdba/data/DAMENG/bak/DB_DM_INCREMENT_20240911_1625\u0026#39;; file dm.key not found, use default license! os_file_open_low_real error! desc: Permission denied, path: /home/dmdba/data/DAMENG/SYSTEM.DBF, code: 13 os_file_open_normal_rw error! path: \u0026#39;/home/dmdba/data/DAMENG/ctl_bak/dm_20240911165939_295566.ctl\u0026#39;, code: 13, desc: Permission denied os_file_open_normal_rw error! path: \u0026#39;/home/dmdba/data/DAMENG/ctl_bak/dm_20240911165845_735048.ctl\u0026#39;, code: 13, desc: Permission denied os_file_open_low_real error! desc: Permission denied, path: /home/dmdba/data/DAMENG/DAMENG01.log, code: 13 os_file_open_low_real error! desc: Permission denied, path: /home/dmdba/data/DAMENG/DAMENG02.log, code: 13 Normal of FAST Normal of DEFAULT Normal of RECYCLE Normal of KEEP Normal of ROLL [Percent:100.00%][Speed:0.00M/s][Cost:00:00:19][Remaining:00:00:00]os_file_open_normal_rw error! path: \u0026#39;/home/dmdba/data/DAMENG/ctl_bak/dm_20240911165939_295566.ctl\u0026#39;, code: 13, desc: Permission denied os_file_open_normal_rw error! path: \u0026#39;/home/dmdba/data/DAMENG/ctl_bak/dm_20240911165845_735048.ctl\u0026#39;, code: 13, desc: Permission denied [Percent:100.00%][Speed:0.00M/s][Cost:00:00:19][Remaining:00:00:00] restore successfully. time used: 00:00:19.990 error 报错都是 Permission denied ，挨个看看目录、文件的用户主组是否都是 dmdba\n先不管，往下执行看看最后能不能成功？\n也能成功，使用 dmdba 用户执行的话，是不会有权限拒绝的情况的\n恢复操作\r据库恢复是指重做 REDO 日志，有两种方式：从备份集恢复，即重做备份集中的 REDO 日志；或从归档恢复，即重做归档中的 REDO 日志。\n1 2 3 4 5 6 7 8 9 10 11 12 RMAN\u0026gt; RECOVER DATABASE \u0026#39;/home/dmdba/data/DAMENG/dm.ini\u0026#39; FROM BACKUPSET \u0026#39;/home/dmdba/data/DAMENG/bak/DB_DM_INCREMENT_20240911_1625\u0026#39;; RECOVER DATABASE \u0026#39;/home/dmdba/data/DAMENG/dm.ini\u0026#39; FROM BACKUPSET \u0026#39;/home/dmdba/data/DAMENG/bak/DB_DM_INCREMENT_20240911_1625\u0026#39;; Database mode = 2, oguid = 0 Normal of FAST Normal of DEFAULT Normal of RECYCLE Normal of KEEP Normal of ROLL EP[0]\u0026#39;s cur_lsn[3756051], file_lsn[3756051] [Percent:100.00%][Speed:0.00PKG/s][Cost:00:00:00][Remaining:00:00:00] recover successfully! time used: 00:00:02.726 恢复成功\n更新操作\r数据库更新是指更新数据库的 DB_MAGIC，并将数据库调整为可正常工作状态，与数据库恢复一样使用 RECOVER 命令完成。数据库更新发生在重做 REDO 日志恢复数据库后。\n1 2 3 4 5 6 7 8 9 10 11 12 13 RMAN\u0026gt; RECOVER DATABASE \u0026#39;/home/dmdba/data/DAMENG/dm.ini\u0026#39; UPDATE DB_MAGIC; RECOVER DATABASE \u0026#39;/home/dmdba/data/DAMENG/dm.ini\u0026#39; UPDATE DB_MAGIC; Database mode = 2, oguid = 0 Normal of FAST Normal of DEFAULT Normal of RECYCLE Normal of KEEP Normal of ROLL EP[0]\u0026#39;s cur_lsn[3756064], file_lsn[3756064] os_file_open_normal_rw error! path: \u0026#39;/home/dmdba/data/DAMENG/ctl_bak/dm_20240911165939_295566.ctl\u0026#39;, code: 13, desc: Permission denied os_file_open_normal_rw error! path: \u0026#39;/home/dmdba/data/DAMENG/ctl_bak/dm_20240911165845_735048.ctl\u0026#39;, code: 13, desc: Permission denied recover successfully! time used: 00:00:01.182 这个 DB_MAGIC 就是魔数，魔数，就是每个数据文件、REDO \\ UNRO 日志开头的一个标识\n重启数据库验证还原情况\r执行更新操作后，数据库就算还原成功了。这个时候启动数据库实例，进去看看有没有还原【2.1.1】步骤中删除的表。\n1 2 SELECT * FROM SYS.ALL_OBJECTS A WHERE A.OWNER = \u0026#39;TEST\u0026#39; AND A.OBJECT_NAME = \u0026#39;T_BAKUP_TEST\u0026#39;; SELECT * FROM TEST.T_BAKUP_TEST; 都正常\n场景二：删表空间与用户\r新建表空间与用户，并在里边添加点数据，然后进行全量备份，使用全量备份集还原。 用 SYSDBA 将 TEST BAKUSER 都删掉，然后恢复。具体：删除 TEST 用户，删除 BAKUSER 用户与对应表空间。 验证表空间、用户、权限是否都恢复。 准备工作\r新建表空间、用户、授权\r使用 SYSDBA 创建测试的表空间、用户，并给 4 个权限\n1 2 3 4 5 6 7 8 -- 创建表空间 CREATE TABLESPACE \u0026#34;TS_BACKUP_TEST\u0026#34; DATAFILE \u0026#39;/home/dmdba/data/DAMENG/TS_BACKUP_TEST.DBF\u0026#39; SIZE 128 AUTOEXTEND ON NEXT 40 MAXSIZE 1024; -- 创建用户 CREATE USER BAKUSER IDENTIFIED BY \u0026#34;test123456\u0026#34; DEFAULT TABLESPACE TS_BACKUP_TEST; GRANT CREATE SESSION TO BAKUSER; GRANT CREATE TABLE TO BAKUSER; GRANT INSERT ANY TABLE TO BAKUSER; GRANT INSERT TABLE TO BAKUSER; 查看它的权限\n1 2 3 4 5 6 SELECT * FROM DBA_SYS_PRIVS A WHERE A.GRANTEE = \u0026#39;BAKUSER\u0026#39;; ----------------------------- BAKUSER\tCREATE TABLE\tNO BAKUSER\tINSERT TABLE\tNO BAKUSER\tINSERT ANY TABLE\tNO BAKUSER\tCREATE SESSION\tNO 添加测试数据\r使用创建好的用户 BAKUSER 造点数据\n1 2 3 4 5 6 CREATE TABLE BAKUSER.T_TEST( ID INT, MARK VARCHAR2(200) ); INSERT INTO BAKUSER.T_TEST VALUES (1, \u0026#39;用来验证还原操作的数据\u0026#39;); 备份\r直接全备，不用增备了\n1 BACKUP DATABASE FULL TO \u0026#34;DB_DM_FULL_20240912_093400\u0026#34; BACKUPSET \u0026#39;/home/dmdba/data/DAMENG/bak/DB_DM_FULL_20240912_093400\u0026#39; COMPRESSED LEVEL 1; 还原\r删除表空间、用户\r删除 TEST 用户 删除 BAKUSER 用户、删除它的表空间 1 2 3 4 -- 使用级联删除 DROP USER BAKUSER CASCADE; DROP TABLESPACE TS_BACKUP_TEST; DROP USER TEST CASCADE; 还原操作\r1）关闭数据库\n1 2 3 [dmdba@status /]$ cd /home/dmdba/dmdbms/bin [dmdba@status bin]$ ./DmServiceDASERVER stop Stopping DmServiceDASERVER: [ OK ] 2）检验备份集\n1 2 3 4 5 6 7 [dmdba@status bin]$ ./dmrman dmrman V8 RMAN\u0026gt; CHECK BACKUPSET \u0026#39;/home/dmdba/data/DAMENG/bak/DB_DM_FULL_20240912_093400\u0026#39;; CHECK BACKUPSET \u0026#39;/home/dmdba/data/DAMENG/bak/DB_DM_FULL_20240912_093400\u0026#39;; [Percent:100.00%][Speed:0.00M/s][Cost:00:00:01][Remaining:00:00:00] check backupset successfully. time used: 00:00:01.752 3）还原操作\n1 2 3 4 5 6 7 8 9 10 11 RMAN\u0026gt; RESTORE DATABASE \u0026#39;/home/dmdba/data/DAMENG/dm.ini\u0026#39; FROM BACKUPSET \u0026#39;/home/dmdba/data/DAMENG/bak/DB_DM_FULL_20240912_093400\u0026#39;; RESTORE DATABASE \u0026#39;/home/dmdba/data/DAMENG/dm.ini\u0026#39; FROM BACKUPSET \u0026#39;/home/dmdba/data/DAMENG/bak/DB_DM_FULL_20240912_093400\u0026#39;; file dm.key not found, use default license! Normal of FAST Normal of DEFAULT Normal of RECYCLE Normal of KEEP Normal of ROLL [Percent:100.00%][Speed:0.00M/s][Cost:00:00:18][Remaining:00:00:00] restore successfully. time used: 00:00:18.930 恢复操作\r1 2 3 4 5 6 7 8 9 10 11 12 RMAN\u0026gt; RECOVER DATABASE \u0026#39;/home/dmdba/data/DAMENG/dm.ini\u0026#39; FROM BACKUPSET \u0026#39;/home/dmdba/data/DAMENG/bak/DB_DM_FULL_20240912_093400\u0026#39;; RECOVER DATABASE \u0026#39;/home/dmdba/data/DAMENG/dm.ini\u0026#39; FROM BACKUPSET \u0026#39;/home/dmdba/data/DAMENG/bak/DB_DM_FULL_20240912_093400\u0026#39;; Database mode = 2, oguid = 0 Normal of FAST Normal of DEFAULT Normal of RECYCLE Normal of KEEP Normal of ROLL EP[0]\u0026#39;s cur_lsn[3756229], file_lsn[3756229] [Percent:100.00%][Speed:0.00PKG/s][Cost:00:00:00][Remaining:00:00:00] recover successfully! time used: 00:00:02.774 更新操作\r1 2 3 4 5 6 7 8 9 10 11 RMAN\u0026gt; RECOVER DATABASE \u0026#39;/home/dmdba/data/DAMENG/dm.ini\u0026#39; UPDATE DB_MAGIC; RECOVER DATABASE \u0026#39;/home/dmdba/data/DAMENG/dm.ini\u0026#39; UPDATE DB_MAGIC; Database mode = 2, oguid = 0 Normal of FAST Normal of DEFAULT Normal of RECYCLE Normal of KEEP Normal of ROLL EP[0]\u0026#39;s cur_lsn[3756333], file_lsn[3756333] recover successfully! time used: 00:00:01.182 重启数据库验证还原情况\r1 2 [dmdba@status bin]$ ./DmServiceDASERVER start Starting DmServiceDASERVER: [ OK ] 1 2 3 4 5 6 7 8 9 -- 查看用户 SELECT * FROM SYS.ALL_USERS; --------------------------------------------------- SYS\t50331648\t2024-06-24 16:33:25.403980 SYSDBA\t50331649\t2024-06-24 16:33:25.403980 SYSAUDITOR\t50331650\t2024-06-24 16:33:25.403980 SYSSSO\t50331651\t2024-06-24 16:33:25.403980 TEST\t50331748\t2024-06-24 17:02:49.225244 BAKUSER\t50331749\t2024-09-12 09:04:08.170548 1 2 3 4 5 6 7 8 9 -- 查看表空间 SELECT * FROM V$TABLESPACE; --------------------------------------------------- 0\tSYSTEM\t1\t0\t0\t9472\t1\t3008\t0\t0\t64\t404\t1 1\tROLL\t1\t0\t0\t16384\t1\t336\t0\t0\t64\t1003\t38 3\tTEMP\t2\t0\t0\t1280\t1\t48\t0\t0\t64\t77\t34 4\tMAIN\t1\t0\t0\t16384\t1\t256\t0\t0\t64\t1008\t1 5\tTS_TEST\t1\t0\t0\t197120\t1\t195904\t0\t0\t64\t76\t1 6\tTS_BACKUP_TEST\t1\t0\t0\t16384\t1\t32\t0\t0\t64\t1022\t1 1 2 3 4 5 6 7 -- 查看用户权限 SELECT * FROM DBA_SYS_PRIVS A WHERE A.GRANTEE = \u0026#39;BAKUSER\u0026#39;; --------------------------------------------------- BAKUSER\tCREATE TABLE\tNO BAKUSER\tINSERT TABLE\tNO BAKUSER\tINSERT ANY TABLE\tNO BAKUSER\tCREATE SESSION\tNO 1 2 3 4 -- 查看测试表数据 SELECT * FROM BAKUSER.T_TEST; --------------------------------------------------- 1\t用来验证还原操作的数据 都还原成功了。\n实际项目的备份方案\r每周六全量备份 + 每天晚上 9 点进行增量备份（定时备份） 保留两周的备份文件，定期删除两周以前的备份文件（定期删除） 管理工具备份\r管理控制台全量备份\r进入达梦管理工具 - 右键代理 - 新建代理环境 - 作业 - 新建作业\n1）填写作业名\n2）设置步骤名称、备份路径、备份方式、压缩级别\n备份路径：填写数据库服务器的路径 3）设置频率、持续实践\n全量为每周六，中午12点（可以自己定） 增量可以每天晚上9点 4）执行后，在服务里可以看到已经备份了\n1 2 3 4 5 6 7 8 9 10 11 [root@YD-FXQDB01-3-161 bak]# pwd /u01/amop/AMOP/bak [root@YD-FXQDB01-3-161 bak]# ll 总用量 0 drwxr-xr-x 2 dmdba dinstall 141 9月 12 11:21 DB_AMOP_FULL_2024_09_12_11_21_56 [root@YD-FXQDB01-3-161 bak]# cd DB_AMOP_FULL_2024_09_12_11_21_56/ [root@YD-FXQDB01-3-161 DB_AMOP_FULL_2024_09_12_11_21_56]# ll 总用量 14004 -rw-r--r-- 1 dmdba dinstall 1312768 9月 12 11:21 DB_AMOP_FULL_2024_09_12_11_21_56_1.bak -rw-r--r-- 1 dmdba dinstall 12913152 9月 12 11:21 DB_AMOP_FULL_2024_09_12_11_21_56.bak -rw-r--r-- 1 dmdba dinstall 108032 9月 12 11:21 DB_AMOP_FULL_2024_09_12_11_21_56.meta 全量备份的名称是 DB_实例名_FULL_日期 管理控制台增量备份\r步骤都差不多，区别就是增量备份需要基于一个全量备份集。\nSQL 备份\rSQL 全量备份\r1 2 3 4 5 6 7 8 9 10 11 call SP_CREATE_JOB(\u0026#39;全量备份_周六\u0026#39;,1,0,\u0026#39;\u0026#39;,0,0,\u0026#39;\u0026#39;,0,\u0026#39;每周六定时全量备份数据库\u0026#39;); call SP_JOB_CONFIG_START(\u0026#39;全量备份_周六\u0026#39;); call SP_ADD_JOB_STEP(\u0026#39;全量备份_周六\u0026#39;, \u0026#39;DB_DM_FULL_BACKUP\u0026#39;, 6, \u0026#39;01000000/u01/amop/AMOP/bak\u0026#39;, 0, 0, 0, 0, NULL, 0); call SP_ADD_JOB_SCHEDULE(\u0026#39;全量备份_周六\u0026#39;, \u0026#39;DB_DM_FULL_BACKUP\u0026#39;, 1, 2, 1, 64, 0, \u0026#39;12:00:00\u0026#39;, NULL, \u0026#39;2024-09-12 11:15:41\u0026#39;, NULL, \u0026#39;\u0026#39;); call SP_JOB_CONFIG_COMMIT(\u0026#39;全量备份_周六\u0026#39;); call SP_JOB_SET_SCHEMA(\u0026#39;全量备份_周六\u0026#39;, \u0026#39;SYSDBA\u0026#39;); SP 详解\rSP_CREATE_JOB\r1 2 3 4 5 6 7 8 9 10 11 SP_CREATE_JOB( JOB_NAME,\t-- 作业名称 ENABLED,\t-- 作业是否启用 1-启用，0-不启用 ENABLE_EMAIL,\t-- 是否开启邮件系统 1-启用，0-不启用 EMAIL_OPTR_NAME,\t-- 操作员名称，没有为 \u0026#39;\u0026#39; 空 EMAIL_TYPE,\t-- 什么情况下发邮件 0-成功后发 1-失败发 2-结束就发 ENABLED_ENTSEND,\t-- 是否开启网络作业 1-开 0-不开 NETSEND_OPTR_NAME,\t-- 操作员，没有为 \u0026#39;\u0026#39; 空 ENTSEND_TYPE,\t-- 什么情况下发消息，0-成功发 1-失败发 2-结束就发 DESCRIBE\t-- 作业描述，可以为 \u0026#39;\u0026#39; 空 ) SP_JOB_CONFIG_START\r1 2 3 SP_JOB_CONFIG_START( JOB_NAME\t-- 开始配置某个作业，传作业名称 ) 额，具体详见《DM8作业系统使用手册.pdf》，不再看了，用达梦管理工具就行了。\nSQL 增量备份\r1 2 3 4 5 6 7 8 9 10 11 call SP_CREATE_JOB(\u0026#39;增量备份_每日\u0026#39;,1,0,\u0026#39;\u0026#39;,0,0,\u0026#39;\u0026#39;,0,\u0026#39;\u0026#39;); call SP_JOB_CONFIG_START(\u0026#39;增量备份_每日\u0026#39;); call SP_ADD_JOB_STEP(\u0026#39;增量备份_每日\u0026#39;, \u0026#39;DayBackup\u0026#39;, 6, \u0026#39;11000000/u01/amop/AMOP/bak/|/u01/amop/AMOP/bak\u0026#39;, 0, 0, 0, 0, NULL, 0); call SP_ADD_JOB_SCHEDULE(\u0026#39;增量备份_每日\u0026#39;, \u0026#39;DayBackup\u0026#39;, 1, 1, 1, 0, 0, \u0026#39;21:00:00\u0026#39;, NULL, \u0026#39;2024-09-12 13:09:05\u0026#39;, NULL, \u0026#39;\u0026#39;); call SP_JOB_CONFIG_COMMIT(\u0026#39;增量备份_每日\u0026#39;); call SP_JOB_SET_SCHEMA(\u0026#39;增量备份_每日\u0026#39;, \u0026#39;SYSDBA\u0026#39;); 定期删除旧备份文件\r删除旧备份，确保不会把所有的备份都删除，要确保一个最新的增量备份以及它的基备份存在（反正就是留着最新的全量 + 增量备份集）\n加一个删除备份的作业步骤 在上一个作业步骤设置，执行成功后继续执行下一步：删除备份的作业 删除备份的SP如下：\n1 2 3 4 -- 添加备份目录 SF_BAKSET_BACKUP_DIR_ADD(\u0026#39;DISK\u0026#39;,\u0026#39;/u01/amop/AMOP/bak\u0026#39;); -- 删 30 天前的备份文件 CALL SP_DB_BAKSET_REMOVE_BATCH(\u0026#39;DISK\u0026#39;,SYSDATE-30); 总结\r还原就是使用 全量 + 增量 备份集进行还原 还原操作 RESTORE DATABASE 后，数据库还不能操作，需要使用 RECOVER 恢复数据库工作，最后更新数据库的 DB_MAGIC 魔数 实际项目上的方案：每周全量 + 每天增量 + 保留 14 天备份集 ","date":"2024-08-28T13:56:41+08:00","permalink":"http://localhost:1313/posts/2024/08/%E4%B8%BB%E5%A4%87%E9%9B%86%E7%BE%A4-%E8%BE%BE%E6%A2%A6%E6%95%B0%E6%8D%AE%E5%BA%93%E5%A4%87%E4%BB%BD%E8%BF%98%E5%8E%9F%E5%AE%9E%E8%B7%B5%E5%9B%9B/","title":"主备集群-达梦数据库备份还原实践（四）"},{"content":"问题\r生产环境中，有些项目的用户是不给 DBA 权限的，导致了执行了这个SQL，但是耗时很久形成阻塞，想 KILL 它，怎么办？\n思路\r1.使用 DBA 用户创建存储过程，里边写 KILL 掉自己会话的代码\n写法一\r1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 CREATE OR REPLACE PROCEDURE DBAUSER.CLOSE_USER_SESSION(SESSION_ID BIGINT) AS CURR_NAME VARCHAR(32); SESS_NAME VARCHAR(32); BEGIN --校验用户，只能杀自己执行的 SELECT USER INTO CURR_NAME; SELECT USER_NAME INTO SESS_NAME FROM V$SESSIONS WHERE SESS_ID=SESSION_ID; IF CURR_NAME = SESS_NAME THEN SP_CLOSE_SESSION(SESSION_ID); ELSE PRINT \u0026#39; \u0026#39;; PRINT \u0026#39;执行失败,只能关闭当前用户连接的会话!!!\u0026#39; ; END IF; EXCEPTION WHEN NO_DATA_FOUND THEN PRINT \u0026#39; \u0026#39;; PRINT \u0026#39;执行失败,没有找到对应的会话 !!!\u0026#39;; WHEN OTHERS THEN PRINT \u0026#39; \u0026#39;; PRINT SQLCODE||\u0026#39; \u0026#39;||SQLERRM; END; 写法二\r1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 CREATE OR REPLACE PROCEDURE CLOSE_USER_SESSION( SESSION_ID IN BIGINT, O_RETURN_MSG OUT VARCHAR2, O_RETURN_CODE OUT INTEGER ) IS --========================================================================= -- AUTHOR: WQ -- CREATE_DATE: 20240719 -- VERSION: 1.0 -- MARK: 普通用户 KILL 会话的方式 --========================================================================= --========================================================================= -- 业务变量 CURR_NAME VARCHAR(32); SESS_NAME VARCHAR(32); --========================================================================= BEGIN -- 校验用户，只能杀自己执行的 SELECT USER INTO CURR_NAME; SELECT USER_NAME INTO SESS_NAME FROM V$SESSIONS WHERE SESS_ID=SESSION_ID; -- 当前用户 = V$SESSION里当前会话ID用户 IF CURR_NAME = SESS_NAME THEN -- 关闭会话 SP_CLOSE_SESSION(SESSION_ID); ELSE O_RETURN_CODE := \u0026#39; \u0026#39;; O_RETURN_MSG := \u0026#39;执行失败，非当前用户的会话\u0026#39;; END IF; O_RETURN_CODE := \u0026#39;1\u0026#39;; O_RETURN_MSG := \u0026#39;执行成功\u0026#39;; EXCEPTION /* -- NO_DATA_FOUND 是达梦自带的预定义异常，为描述数据未找到 WHEN NO_DATA_FOUND THEN PRINT \u0026#39; \u0026#39;; PRINT \u0026#39;执行失败,没有找到对应的会话 !!!\u0026#39;; */ WHEN OTHERS THEN O_RETURN_CODE := SQLCODE; O_RETURN_MSG := SQLERRM; ROLLBACK; END; 2.把存储过程的执行权限授予普通用户\n1 GRANT EXECUTE ON DBAUSER.CLOSE_USER_SESSION TO TESTUSER; 3.普通用户查询需要 KILL 的会话ID 并 执行存储过程\n1 2 3 4 5 -- 查询 会话 ID SELECT * FROM SYS.V$SESSIONS A WHERE A.STATE = \u0026#39;ACTIVE\u0026#39;; -- 执行存储过程 CALL TEST.CLOSE_USER_SESSION(\u0026#39;140052047263656\u0026#39;,NULL,NULL); ","date":"2024-08-27T21:01:48+08:00","permalink":"http://localhost:1313/posts/2024/08/sp-%E6%97%A0dba%E6%9D%83%E9%99%90%E5%A6%82%E4%BD%95kill%E4%BC%9A%E8%AF%9D/sp-%E6%97%A0dba%E6%9D%83%E9%99%90%E5%A6%82%E4%BD%95kill%E4%BC%9A%E8%AF%9D/","title":"SP 无DBA权限如何KILL会话"},{"content":"背景\r在对项目进行信创迁移，从 ORALCE 迁移到达梦数据库，为了更好的平滑过渡，对达梦实例 dm.ini 文件中修改 COMPATIBLE_MODE = 2开启兼容 ORACLE 语法的模式。然后使用 DTS 进行迁移时，会将 ORACLE 中的 DATE DATETIME 数据类型自动转换为 TIMESTAMP 类型。且经过验证，后续的建表，如果是包含了 DATE DATETIME 类型，创建后也会被转换为 TIMESTAMP 类型。\n这个时候，如果在存储过程中使用 DATEDIFF 函数，会出现数据类型不对的报错，所以这里需要进行相应的改造。\n有两个办法：\n1）对相应的处理逻辑进行手动修改（解决方法一）\n2）在 DTS 迁移时，对 ORACLE - DM 进行数据类型映射（解决方法二，该方法经咨询达梦技术方获取）\n解决方法一\r原先对于 DATE数据类型使用 DATEDIFF 进行日期相减\n现在使用 TRUNC 函数将时间戳转换为日期，再进行日期相减\nTRUNC是截断数字，也有截断日期的用法\n测试用例\r1 2 3 4 5 6 7 8 9 10 11 12 13 14 DROP TABLE IF EXISTS TEST.T_WEATHER; CREATE TABLE TEST.T_WEATHER( ID INT, RECORDDATE DATE, TEMPERATURE INT ); INSERT INTO TEST.T_WEATHER VALUES(1, \u0026#39;2024-08-10\u0026#39;, 37); INSERT INTO TEST.T_WEATHER VALUES(2, \u0026#39;2024-08-11\u0026#39;, 36); INSERT INTO TEST.T_WEATHER VALUES(3, \u0026#39;2024-08-12\u0026#39;, 38); INSERT INTO TEST.T_WEATHER VALUES(4, \u0026#39;2024-08-13\u0026#39;, 39); INSERT INTO TEST.T_WEATHER VALUES(5, \u0026#39;2024-08-14\u0026#39;, 37); INSERT INTO TEST.T_WEATHER VALUES(6, \u0026#39;2024-08-15\u0026#39;, 37); COMMIT; 原先的处理逻辑\r1 2 3 4 5 6 7 8 9 10 11 12 SELECT T.* FROM ( SELECT A.ID, A.RECORDDATE, A.TEMPERATURE, LEAD(A.RECORDDATE, 1, NULL) OVER(ORDER BY A.RECORDDATE) AS DD, LEAD(A.TEMPERATURE, 1, NULL) OVER(ORDER BY A.RECORDDATE) AS WD FROM TEST.T_WEATHER A ) T WHERE T.WD \u0026gt; T.TEMPERATURE AND DATEDIFF(T.DD, T.RECORDDATE) = 1 ; 报错\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 [执行语句1]: SELECT T.* FROM ( SELECT A.ID, A.RECORDDATE, A.TEMPERATURE, LEAD(A.RECORDDATE, 1, NULL) OVER(ORDER BY A.RECORDDATE) AS DD, LEAD(A.TEMPERATURE, 1, NULL) OVER(ORDER BY A.RECORDDATE) AS WD FROM TEST.T_WEATHER A ) T WHERE T.WD \u0026gt; T.TEMPERATURE AND DATEDIFF(T.DD, T.RECORDDATE) = 1 ; 执行失败(语句1) -2007: 第 12 行, 第 26 列[T]附近出现错误: 语法分析出错 改造后的处理逻辑\r1 2 3 4 5 6 7 8 9 10 11 12 SELECT T.* FROM ( SELECT A.ID, A.RECORDDATE, A.TEMPERATURE, LEAD(A.RECORDDATE, 1, NULL) OVER(ORDER BY A.RECORDDATE) AS DD, LEAD(A.TEMPERATURE, 1, NULL) OVER(ORDER BY A.RECORDDATE) AS WD FROM TEST.T_WEATHER A ) T WHERE T.WD \u0026gt; T.TEMPERATURE AND TRUNC(T.DD - 1) = TRUNC(T.RECORDDATE) ; 正常执行\n附：TRUNC 用法\r截取日期\r1 2 3 4 5 6 7 SELECT TRUNC(A.RECORDDATE, \u0026#39;YYYY\u0026#39;) FROM TEST.T_WEATHER A; -- 返回当年第一天 SELECT TRUNC(A.RECORDDATE, \u0026#39;MM\u0026#39;) FROM TEST.T_WEATHER A; -- 返回当月第一天 SELECT TRUNC(A.RECORDDATE, \u0026#39;DD\u0026#39;) FROM TEST.T_WEATHER A; -- 返回当前年月日，缺省值 DD SELECT TRUNC(A.RECORDDATE, \u0026#39;HH\u0026#39;) FROM TEST.T_WEATHER A; -- 返回当前小时 SELECT TRUNC(A.RECORDDATE, \u0026#39;MI\u0026#39;) FROM TEST.T_WEATHER A; -- 返回当前时间，没有秒 SELECT TRUNC(A.RECORDDATE, \u0026#39;D\u0026#39;) FROM TEST.T_WEATHER A; -- 返回当前星期的第一天（星期天为第一天） 日期计算\r1 2 3 4 -- 在当前日期的基础上，增加一天（减少就 - ） SELECT TRUNC(A.RECORDDATE, \u0026#39;YYYY\u0026#39;) + 1 FROM TEST.T_WEATHER A; SELECT TRUNC(A.RECORDDATE, \u0026#39;MM\u0026#39;) + 1 FROM TEST.T_WEATHER A; SELECT TRUNC(A.RECORDDATE, \u0026#39;DD\u0026#39;) + 1 FROM TEST.T_WEATHER A; 解决方法二\r在 DTS 中使用数据类型映射，此方法为迁移时使用。或者在使用 DTS 工具刷入 SQL 脚本时使用。\n","date":"2024-08-26T21:02:51+08:00","permalink":"http://localhost:1313/posts/2024/08/sql-%E8%BE%BE%E6%A2%A6date%E7%B1%BB%E5%9E%8B%E8%87%AA%E5%8A%A8%E8%BD%AC%E6%8D%A2%E4%B8%BAtimestamp%E7%B1%BB%E5%9E%8B%E7%9A%84%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95/","title":"SQL-达梦DATE类型自动转换为TIMESTAMP类型的解决方法"},{"content":"新增实例与数据守护、监视器\r说明\r在原先的 A 、B 机器搭建好的实时主备集群已有实例的基础上，新增一个实例，即一个集群，多个实例的效果\n并且，一定要事先规划好端口配置、实例名、路径、数据守护组名\n1.规划的端口是否与现有的实例端口冲突\n2.主备机器端口之间是否打通\n3.实例路径、数据守护组都要配置端口的\n部署信息\rA机器 B机器 IP 192.168.163.9 192.168.163.10 实例名 GRP_TEST_01 GRP_TEST_02 实例端口 5236 5236 守护进程端口 5536 5536 MAL端口 5336 5336 守护组 GRP1 GPR1 安装目录 /home/dmdba/dmdbms /home/dmdba/dmdbms 实例目录 /home/dmdba/dmdbms/DMDB /home/dmdba/dmdbms/DMDB 归档上限 51200 51200 新增实例规划\rA机器 B机器 IP 192.168.163.9 192.168.163.10 实例名 GRP_ADDTEST_01 GRP_ADDTEST_02 实例端口 5237 5237 守护进程端口 5537 5537 MAL端口 5337 5337 守护组 GRP2 GPR2 实例目录 /home/dmdba/ADDTEST_data /home/dmdba/ADDTEST_data 归档上限 51200 51200 初始化实例\r本次新增并没有停止已有实例服务\n注意：\n除非必要说明，默认使用 dmdba 数据库用户进行操作 配置过程中需要使用对于的目录，目录别整错了 A 机器新增实例\r1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 [root@linux1 bin]# ./dminit path=/home/dmdba/ADDTEST_data PAGE_SIZE=32 EXTENT_SIZE=32 CASE_SENSITIVE=y CHARSET=0 DB_NAME=ADDTEST INSTANCE_NAME=GRP_ADDTEST_01 PORT_NUM=5237 initdb V8 db version: 0x7000c file dm.key not found, use default license! License will expire on 2025-03-21 Normal of FAST Normal of DEFAULT Normal of RECYCLE Normal of KEEP Normal of ROLL log file path: /home/dmdba/ADDTEST_data/ADDTEST/ADDTEST01.log log file path: /home/dmdba/ADDTEST_data/ADDTEST/ADDTEST02.log write to dir [/home/dmdba/ADDTEST_data/ADDTEST]. create dm database success. 2024-07-27 10:09:55 这里我忘记了切换到 dmdba 用户下了，问题不大，我更改实例目录权限，将目录权限改成 dmdba\n1 2 cd /home/dmdba chown dmdba:dinstall -R ADDTEST_data/ B 机器新增实例\r1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 [root@linux2 bin]# su - dmdba 上一次登录：一 7月 22 22:01:45 CST 2024pts/0 上 [dmdba@linux2 ~]$ cd /home/dmdba/dmdbms/bin [dmdba@linux2 bin]$ ./dminit path=/home/dmdba/ADDTEST_data PAGE_SIZE=32 EXTENT_SIZE=32 CASE_SENSITIVE=y CHARSET=0 DB_NAME=ADDTEST INSTANCE_NAME=GRP_ADDTEST_01 PORT_NUM=5237 initdb V8 db version: 0x7000c file dm.key not found, use default license! License will expire on 2025-03-21 Normal of FAST Normal of DEFAULT Normal of RECYCLE Normal of KEEP Normal of ROLL log file path: /home/dmdba/ADDTEST_data/ADDTEST/ADDTEST01.log log file path: /home/dmdba/ADDTEST_data/ADDTEST/ADDTEST02.log write to dir [/home/dmdba/ADDTEST_data/ADDTEST]. create dm database success. 2024-07-27 10:15:34 配置 A 机器\r启动新增的实例服务\r前台命令启动，启动后该窗口不能动，需要重新开一个窗口\n1 2 [dmdba@linux1 ~]$ cd /home/dmdba/dmdbms/bin [dmdba@linux1 bin]$ ./dmserver /home/dmdba/ADDTEST_data/ADDTEST/dm.ini 开启归档\r注意：\n这里使用 @IP:PORT 的形式，来区分进入哪个实例 归档路径别填错了，在新增的实例数据文件目录下 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 [dmdba@linux1 bin]$ ./disql SYSDBA/SYSDBA@192.168.163.9:5237 服务器[192.168.163.9:5237]:处于普通打开状态 登录使用时间 : 7.226(ms) disql V8 SQL\u0026gt; ALTER DATABASE MOUNT; 操作已执行 已用时间: 2.814(毫秒). 执行号:0. SQL\u0026gt; ALTER DATABASE ARCHIVELOG; 操作已执行 已用时间: 23.121(毫秒). 执行号:0. SQL\u0026gt; ALTER DATABASE ADD ARCHIVELOG \u0026#39;DEST=/home/dmdba/ADDTEST_data/ADDTEST/arch, TYPE=LOCAL, FILE_SIZE=1024, SPACE_LIMIT=10240\u0026#39;; 操作已执行 已用时间: 3.945(毫秒). 执行号:0. SQL\u0026gt; ALTER DATABASE OPEN; 操作已执行 已用时间: 22.566(毫秒). 执行号:0. 备份数据\r1 2 3 SQL\u0026gt; BACKUP DATABASE BACKUPSET \u0026#39;/home/dmdba/ADDTEST_data/ADDTEST/bak/BACKUP_FILE_ADDTEST\u0026#39;; 操作已执行 已用时间: 00:00:07.540. 执行号:64401. 修改 dm.ini\r1 2 3 4 5 6 SQL\u0026gt; SP_SET_PARA_VALUE (2,\u0026#39;PORT_NUM\u0026#39;,5237); #数据库实例监听端口，配置成新的端口 SQL\u0026gt; SP_SET_PARA_VALUE (2,\u0026#39;DW_INACTIVE_INTERVAL\u0026#39;,60); #接收守护进程消息超时时间 SQL\u0026gt; SP_SET_PARA_VALUE (2,\u0026#39;ALTER_MODE_STATUS\u0026#39;,0); #不允许手工方式修改实例模式/状态/OGUID SQL\u0026gt; SP_SET_PARA_VALUE (2,\u0026#39;ENABLE_OFFLINE_TS\u0026#39;,2); #不允许备库 OFFLINE 表空间 SQL\u0026gt; SP_SET_PARA_VALUE (2,\u0026#39;MAL_INI\u0026#39;,1); #打开 MAL 系统 SQL\u0026gt; SP_SET_PARA_VALUE (2,\u0026#39;RLOG_SEND_APPLY_MON\u0026#39;,64); #统计最近 64 次的日志重演信息 退出并关闭数据库服务\r1 2 3 SQL\u0026gt; exit; # 到开启服务的linux窗口，终止前台服务 修改 dmarch.ini\r1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 [dmdba@linux1 bin]$ vi /home/dmdba/ADDTEST_data/ADDTEST/dmarch.ini #DaMeng Database Archive Configuration file #this is comments ARCH_WAIT_APPLY = 0 [ARCHIVE_LOCAL1] ARCH_TYPE = LOCAL ARCH_DEST = /home/dmdba/ADDTEST_data/ADDTEST/arch ARCH_FILE_SIZE = 1024 ARCH_SPACE_LIMIT = 10240 ARCH_FLUSH_BUF_SIZE = 0 ARCH_HANG_FLAG = 1 [ARCHIVE_REALTIME1] ARCH_TYPE = REALTIME ARCH_DEST = GRP_ADDTEST_02 创建 dmmal.ini\r注意：文件目录、实例名、端口别配置错了！！\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 [dmdba@linux1 bin]$ vi /home/dmdba/ADDTEST_data/ADDTEST/dmmal.ini MAL_CHECK_INTERVAL = 10 #MAL 链路检测时间间隔 MAL_CONN_FAIL_INTERVAL = 10 #判定 MAL 链路断开的时间 MAL_TEMP_PATH = /home/dmdba/ADDTEST_data/ADDTEST/malpath/ #临时文件目录 MAL_BUF_SIZE = 512 #单个 MAL 缓存大小，单位 MB MAL_SYS_BUF_SIZE = 2048 #MAL 总大小限制，单位 MB MAL_COMPRESS_LEVEL = 0 #MAL 消息压缩等级，0 表示不压缩 [MAL_INST1] MAL_INST_NAME = GRP_ADDTEST_01 #实例名，和 dm.ini 的 INSTANCE_NAME 一致 MAL_HOST = 192.168.163.9 #MAL 系统监听 TCP 连接的 IP 地址 MAL_PORT = 5337 #MAL 系统监听 TCP 连接的端口 MAL_INST_HOST = 192.168.163.9 #实例的对外服务 IP 地址 MAL_INST_PORT = 5237 #实例对外服务端口，和 dm.ini 的 PORT_NUM 一致 MAL_DW_PORT = 5437 #实例对应的守护进程监听 TCP 连接的端口 MAL_INST_DW_PORT = 5537 #实例监听守护进程 TCP 连接的端口 [MAL_INST2] MAL_INST_NAME = GRP_ADDTEST_02 MAL_HOST = 192.168.163.10 MAL_PORT = 5337 MAL_INST_HOST = 192.168.163.10 MAL_INST_PORT = 5237 MAL_DW_PORT = 5437 MAL_INST_DW_PORT = 5537 创建 dmwatcher.ini\r注意：\n数据守护组名，别错了，这里是 [GRP2] 实例路径也别整错了 数据守护的 OGUID 需要唯一，与其他实例的 OGUID 不能相同，也需要改 1 2 3 4 5 6 7 8 9 10 11 12 13 14 [dmdba@linux1 bin]$ vi /home/dmdba/ADDTEST_data/ADDTEST/dmwatcher.ini [GRP2] DW_TYPE = GLOBAL #全局守护类型 DW_MODE = AUTO #MANUAL：故障手切 AUTO：故障自切 DW_ERROR_TIME = 20 #远程守护进程故障认定时间 INST_ERROR_TIME = 20 #本地实例故障认定时间 INST_RECOVER_TIME = 60 #主库守护进程启动恢复的间隔时间 INST_OGUID = 45332 #守护系统唯一 OGUID 值 INST_INI = /home/dmdba/ADDTEST_data/ADDTEST/dm.ini #dm.ini 文件路径 INST_AUTO_RESTART = 1 #打开实例的自动启动功能 INST_STARTUP_CMD = /home/dmdba/dmdbms/bin/dmserver #命令行方式启动 RLOG_SEND_THRESHOLD = 0 #指定主库发送日志到备库的时间阈值，默认关闭 RLOG_APPLY_THRESHOLD = 0 #指定备库重演日志的时间阈值，默认关闭 拷贝备份文件到备库\r备份文件就是【2.3 步骤】执行的\n1 BACKUP DATABASE BACKUPSET \u0026#39;/home/dmdba/ADDTEST_data/ADDTEST/bak/BACKUP_FILE_ADDTEST\u0026#39;; 生成的 BACKUP_FILE_ADDTEST 文件\n如下拷贝\n1 2 3 4 5 [dmdba@linux1 bin]$ scp -r /home/dmdba/ADDTEST_data/ADDTEST/bak/BACKUP_FILE_ADDTEST dmdba@192.168.163.10:/home/dmdba/ADDTEST_data/ADDTEST/bak/ dmdba@192.168.163.10\u0026#39;s password: !@#$qwer BACKUP_FILE_ADDTEST.bak 100% 30MB 19.7MB/s 00:01 BACKUP_FILE_ADDTEST_1.bak 100% 41KB 13.9MB/s 00:00 BACKUP_FILE_ADDTEST.meta 100% 110KB 9.6MB/s 00:00 注册服务\r使用 root 用户操作\n注意：\n实例路径别错、实例名别错 数据守护的名称记得也改一下，别冲突 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 [root@linux1 ~]# cd /home/dmdba/dmdbms/script/root/ #################### # 创建数据库服务 #################### [root@linux1 root]# ./dm_service_installer.sh -t dmserver -p GRP_ADDTEST_01 -dm_ini /home/dmdba/ADDTEST_data/ADDTEST/dm.ini -m mount Created symlink from /etc/systemd/system/multi-user.target.wants/DmServiceGRP_ADDTEST_01.service to /usr/lib/systemd/system/DmServiceGRP_ADDTEST_01.service. 创建服务(DmServiceGRP_ADDTEST_01)完成 #################### # 创建数据守护服务 # 数据守护服务的名称别跟原有的冲突 -p 参数 #################### [root@linux1 root]# ./dm_service_installer.sh -t dmwatcher -p WatcherADDTEST -watcher_ini /home/dmdba/ADDTEST_data/ADDTEST/dmwatcher.ini Created symlink from /etc/systemd/system/multi-user.target.wants/DmWatcherServiceWatcherADDTEST.service to /usr/lib/systemd/system/DmWatcherServiceWatcherADDTEST.service. 创建服务(DmWatcherServiceWatcherADDTEST)完成 如果需要删除服务\r1 2 [root@~]# ./dm_service_uninstaller.sh -n DmServiceGRP_ADDTEST_01 [root@~]# ./dm_service_uninstaller.sh -n DmWatcherServiceWatcherADDTEST 配置 B 机器\rB 机器上是备库，将数据还原与 A 机器的主库一致\n无必要说明，默认使用 dmdba 用户操作\n备库恢复数据\r1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 [dmdba@linux2 bin]$ ./dmrman CTLSTMT=\u0026#34;RESTORE DATABASE \u0026#39;/home/dmdba/ADDTEST_data/ADDTEST/dm.ini\u0026#39; FROM BACKUPSET \u0026#39;/home/dmdba/ADDTEST_data/ADDTEST/bak/BACKUP_FILE_ADDTEST\u0026#39;\u0026#34; dmrman V8 RESTORE DATABASE \u0026#39;/home/dmdba/ADDTEST_data/ADDTEST/dm.ini\u0026#39; FROM BACKUPSET \u0026#39;/home/dmdba/ADDTEST_data/ADDTEST/bak/BACKUP_FILE_ADDTEST\u0026#39; file dm.key not found, use default license! Normal of FAST Normal of DEFAULT Normal of RECYCLE Normal of KEEP Normal of ROLL [Percent:100.00%][Speed:0.00M/s][Cost:00:00:03][Remaining:00:00:00] restore successfully. time used: 00:00:03.464 [dmdba@linux2 bin]$ ./dmrman CTLSTMT=\u0026#34;RECOVER DATABASE \u0026#39;/home/dmdba/ADDTEST_data/ADDTEST/dm.ini\u0026#39; FROM BACKUPSET \u0026#39;/home/dmdba/ADDTEST_data/ADDTEST/bak/BACKUP_FILE_ADDTEST\u0026#39;\u0026#34; dmrman V8 RECOVER DATABASE \u0026#39;/home/dmdba/ADDTEST_data/ADDTEST/dm.ini\u0026#39; FROM BACKUPSET \u0026#39;/home/dmdba/ADDTEST_data/ADDTEST/bak/BACKUP_FILE_ADDTEST\u0026#39; file dm.key not found, use default license! Database mode = 2, oguid = 0 Normal of FAST Normal of DEFAULT Normal of RECYCLE Normal of KEEP Normal of ROLL EP[0]\u0026#39;s cur_lsn[42819], file_lsn[42819] [Percent:100.00%][Speed:0.00PKG/s][Cost:00:00:00][Remaining:00:00:00] recover successfully! time used: 00:00:03.146 [dmdba@linux2 bin]$ ./dmrman CTLSTMT=\u0026#34;RECOVER DATABASE \u0026#39;/home/dmdba/ADDTEST_data/ADDTEST/dm.ini\u0026#39; UPDATE DB_MAGIC\u0026#34; dmrman V8 RECOVER DATABASE \u0026#39;/home/dmdba/ADDTEST_data/ADDTEST/dm.ini\u0026#39; UPDATE DB_MAGIC file dm.key not found, use default license! Database mode = 2, oguid = 0 Normal of FAST Normal of DEFAULT Normal of RECYCLE Normal of KEEP Normal of ROLL EP[0]\u0026#39;s cur_lsn[42900], file_lsn[42900] recover successfully! time used: 00:00:01.192 如果少执行了中间的 RECOVER DATABASE 步骤，则会报错\n1 2 [-8308]:需要先执行RECOVER DATABASE操作，再执行RECOVER DATABASE UPDATE DB_MAGIC操作 dmrman_main end, code[-8308], return -1. 创建 dmarch.ini\rA 机器开了归档， B 机器也要开归档（可以简单的理解通过归档同步数据）\n因为没启 B 机器的备库实例服务，要手动创建\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 [dmdba@linux2 bin]$ vi /home/dmdba/ADDTEST_data/ADDTEST/dmarch.ini ARCH_WAIT_APPLY = 0 #0：高性能 1：事务一致 [ARCHIVE_LOCAL] ARCH_TYPE = LOCAL #本地归档类型 ARCH_DEST = /home/dmdba/ADDTEST_data/ADDTEST/arch/ #本地归档存放路径 ARCH_FILE_SIZE = 1024 #单个归档大小，单位 MB ARCH_SPACE_LIMIT = 10240 #归档上限，单位 MB ARCH_FLUSH_BUF_SIZE = 0 ARCH_HANG_FLAG = 1 [ARCHIVE_REALTIME1] ARCH_TYPE = REALTIME #实时归档类型 ARCH_DEST = GRP_ADDTEST_01 #实时归档目标实例名，这里则填主库的实例 修改 dm.ini\r并且确保文件里的实例名为：GRP_ADDTEST_02 ，端口为 5237 ，并且配置如下\n1 2 3 4 5 6 7 8 9 10 [dmdba@linux2 DMDB]$ vi /home/dmdba/dmdbms/DMDB/dm.ini INSTANCE_NAME = GRP_TEST_02 PORT_NUM = 5237 #数据库实例监听端口 DW_INACTIVE_INTERVAL = 60 #接收守护进程消息超时时间 ALTER_MODE_STATUS = 0 #不允许手工方式修改实例模式/状态/OGUID ENABLE_OFFLINE_TS = 2 #不允许备库 OFFLINE 表空间 MAL_INI = 1 #打开 MAL 系统 ARCH_INI = 1 #打开归档配置 RLOG_SEND_APPLY_MON = 64 #统计最近 64 次的日志重演信息 创建 dmmal.ini\r同主库配置\n创建 dmwatcher.ini\r同主库配置\n注册服务\r使用 root 用户执行\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 [root@linux2 ~]# cd /home/dmdba/dmdbms/script/root/ #################### # 创建数据库服务 #################### [root@linux2 root]# ./dm_service_installer.sh -t dmserver -p GRP_ADDTEST_02 -dm_ini /home/dmdba/ADDTEST_data/ADDTEST/dm.ini -m mount Created symlink from /etc/systemd/system/multi-user.target.wants/DmServiceGRP_ADDTEST_01.service to /usr/lib/systemd/system/DmServiceGRP_ADDTEST_01.service. 创建服务(DmServiceGRP_ADDTEST_01)完成 #################### # 创建数据守护服务 # 数据守护服务的名称别跟原有的冲突 -p 参数 #################### [root@linux2 root]# ./dm_service_installer.sh -t dmwatcher -p WatcherADDTEST -watcher_ini /home/dmdba/ADDTEST_data/ADDTEST/dmwatcher.ini Created symlink from /etc/systemd/system/multi-user.target.wants/DmWatcherServiceWatcherADDTEST.service to /usr/lib/systemd/system/DmWatcherServiceWatcherADDTEST.service. 创建服务(DmWatcherServiceWatcherADDTEST)完成 配置新实例的监视器\r使用 dmdba 操作\n创建 dmmonitor.ini\r在主库机器上创建，A 机器（在 B 机器或者第三台机器上都可以，随意），这个是确认监视器\n监视器的日志路径最好使用绝对路径，不然就是默认在达梦数据库的按照目录下\n还有就是，日志路径最好与原有的实例监视器日志路径区分，否则两个实例的监视器日志会写到一起\n1 2 3 4 5 6 7 8 9 10 11 12 13 [dmdba@linux1 root]# vi /home/dmdba/ADDTEST_data/ADDTEST/dmmonitor.ini MON_DW_CONFIRM = 1 #0：非确认（故障手切） 1：确认（故障自切） MON_LOG_PATH = ../log_monitor/ADDTEST #监视器日志文件存放路径 MON_LOG_INTERVAL = 60 #每隔 60s 定时记录系统信息到日志文件 MON_LOG_FILE_SIZE = 32 #单个日志大小，单位 MB MON_LOG_SPACE_LIMIT = 1024 #日志上限，单位 MB [GRP2] MON_INST_OGUID = 45332 #组 GRP2 的唯一 OGUID 值 MON_DW_IP = 192.168.163.9:5437 #IP 对应 MAL_HOST，PORT 对应 MAL_DW_PORT MON_DW_IP = 192.168.163.10:5437 创建 dmmonitor_manual.ini\r非确认监视器，配置同上，除了 MON_DW_CONFIRM 是 0 外\n1 2 3 4 5 6 7 8 9 10 11 12 [dmdba@linux1 root]# vi /home/dmdba/ADDTEST_data/ADDTEST/dmmonitor_manual.ini MON_DW_CONFIRM = 1 #0：非确认（故障手切） 1：确认（故障自切） MON_LOG_PATH = ../log_monitor/ADDTEST #监视器日志文件存放路径 MON_LOG_INTERVAL = 60 #每隔 60s 定时记录系统信息到日志文件 MON_LOG_FILE_SIZE = 32 #单个日志大小，单位 MB MON_LOG_SPACE_LIMIT = 1024 #日志上限，单位 MB [GRP2] MON_INST_OGUID = 45332 #组 GRP2 的唯一 OGUID 值 MON_DW_IP = 192.168.163.9:5437 #IP 对应 MAL_HOST，PORT 对应 MAL_DW_PORT MON_DW_IP = 192.168.163.10:5437 注册监视器服务\r使用root 用户操作\n1 2 3 [root@linux1 root]# ./dm_service_installer.sh -t dmmonitor -p MonitorADDTEST -monitor_ini /home/dmdba/ADDTEST_data/ADDTEST/dmmonitor.ini Created symlink from /etc/systemd/system/multi-user.target.wants/DmMonitorServiceMonitorADDTEST.service to /usr/lib/systemd/system/DmMonitorServiceMonitorADDTEST.service. 创建服务(DmMonitorServiceMonitorADDTEST)完成 启动监视器服务\r1 2 [dmdba@linux1 bin]$ ./DmMonitorServiceMonitorADDTEST start Starting DmMonitorServiceMonitorADDTEST: [ FAILED ] 监视器需要在实例服务起来后才能启，顺序如下：\n数据库实例 \u0026raquo; 守护进程 \u0026raquo; 监视器\n启动服务\r启动数据库并修改参数\rA 机器启动、修改\r启动实例服务报错\r主要是修改 OGUID（就是数据守护的组） 与数据库模式\n1 2 [dmdba@linux1 bin]$ ./DmServiceGRP_ADDTEST_01 start Starting DmServiceGRP_ADDTEST_01: [ FAILED ] 查看最近的日志\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 cd ../log [dmdba@linux1 log]$ ls -lrt 总用量 2384 -rw-r--r--. 1 dmdba dinstall 400805 7月 21 00:02 install_ant.log -rwxr-xr-x. 1 dmdba dinstall 480 7月 21 00:02 install.log -rw-r--r--. 1 dmdba dinstall 0 7月 21 00:03 DmAPService.log -rw-r--r--. 1 dmdba dinstall 0 7月 21 00:43 DmServiceDMSERVER.log -rw-r--r--. 1 dmdba dinstall 97806 7月 21 00:57 dm_DMDBSERVER_202407.log -rw-r--r--. 1 dmdba dinstall 0 7月 21 11:19 DmServiceGRP_TEST_01.log -rw-r--r--. 1 dmdba dinstall 0 7月 21 14:48 DmWatcherServiceWatcher.log -rw-r--r--. 1 dmdba dinstall 0 7月 22 21:34 DmMonitorServiceMonitor.log -rw-r--r--. 1 dmdba dinstall 540272 7月 27 09:47 dm_dmwatcher_GRP_TEST_01_202407.log -rw-r--r--. 1 root root 2193 7月 27 10:09 dm_GRP_ADDTEST_01_202407.log -rw-r--r--. 1 dmdba dinstall 2385 7月 27 10:26 dm_dmap_202407.log -rw-r--r--. 1 dmdba dinstall 1188 7月 27 10:26 dm_dmap_br_202407.log -rw-r--r--. 1 dmdba dinstall 36265 7月 27 10:26 dm_BAKRES_202407.log -rw-r--r--. 1 dmdba dinstall 0 7月 27 11:45 DmMonitorServiceMonitorADDTEST.log -rw-r--r--. 1 dmdba dinstall 1329521 7月 27 11:56 dm_GRP_TEST_01_202407.log -rw-r--r--. 1 dmdba dinstall 0 7月 27 11:56 DmServiceGRP_ADDTEST_01.log -rw-r--r--. 1 dmdba dinstall 5324 7月 27 11:56 dm_unknown_202407.log -rw-r--r--. 1 dmdba dinstall 4353 7月 27 11:57 dmsvc_sh.log 最近更新的日志 dmsvc_sh.log ，查看日志\n1 2 3 [dmdba@linux1 log]$ tail -f dmsvc_sh.log [2024-07-27 11:56:52] [localhost] [2886311096] [DmServiceGRP_ADDTEST_01] start service by dmdba [2024-07-27 11:57:08] [localhost] [2886311096] [DmServiceGRP_ADDTEST_01] failed to start service by dmdba (code:0) 既然是 dmsvc_sh.log 报错了，猜测与 dm_svc.conf 配置有关，这个是用来配置服务名连接的文件\n文件内容如下：\n1 2 3 4 5 6 7 8 9 10 11 TIME_ZONE=(480) LANGUAGE=(CN) GRP1=(192.168.163.9:5236,192.168.163.10:5236) # 服务配置 [GRP1] TIME+ZONE=(+480) # 指定优先登录的服务器模式 0-优先PRIMARY 1-只连接主库 2-只连接备库 3-优先STANDBY 4-优先NORMAL（缺省默认） LOGIN_MODE=(0) SWITCH_TIME=(3) SWITCH_INTERVAL=(200) 尝试添加新增的实例服务名进去\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 TIME_ZONE=(480) LANGUAGE=(CN) GRP1=(192.168.163.9:5236,192.168.163.10:5236) GRP2=(192.168.163.9:5237,192.168.163.10:5237) # 服务配置 [GRP1] TIME+ZONE=(+480) # 指定优先登录的服务器模式 0-优先PRIMARY 1-只连接主库 2-只连接备库 3-优先STANDBY 4-优先NORMAL（缺省默认） LOGIN_MODE=(0) SWITCH_TIME=(3) SWITCH_INTERVAL=(200) [GRP2] TIME+ZONE=(+480) # 指定优先登录的服务器模式 0-优先PRIMARY 1-只连接主库 2-只连接备库 3-优先STANDBY 4-优先NORMAL（缺省默认） LOGIN_MODE=(0) SWITCH_TIME=(3) SWITCH_INTERVAL=(200) 还是报错\n额。。。\n理论上讲，实例的报错应该是写入实例的日志文件啊？怎么最近写入的日志只有 dmsvc_sh.log ？\n发现启动报错的日志没写进去，原来是日志文件的用户主组是 root，先用 root 变更\n1 chown -R dmdba:dinstall /home/dmdba/dmdbms/log/* 重启切换到 dmdba 启动新增的实例服务，并查看实例日志 ``\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 [dmdba@linux1 bin]$ ./DmServiceGRP_ADDTEST_01 start Starting DmServiceGRP_ADDTEST_01: [ FAILED ] [dmdba@linux1 log]$ tail -f dm_GRP_ADDTEST_01_202407.log 2024-07-27 12:13:15.145 [INFO] database P0000080255 T0000000000000080298 dm_mal_tsk_thd started, src_site:0, dest_site:1, port_data 2024-07-27 12:13:15.145 [INFO] database P0000080255 T0000000000000080297 dm_mal_recv_thd started, src_site:0, dest_site:0, port_data 2024-07-27 12:13:15.195 [INFO] database P0000080255 T0000000000000080255 rsys_rarch_obj_fil_collect path:[/home/dmdba/ADDTEST_data/ADDTEST/arch] begin. 2024-07-27 12:13:15.200 [INFO] database P0000080255 T0000000000000080255 rsys_rarch_obj_fil_collect seqno[0] end, total 1 rfils, last_g_seqno:5043 2024-07-27 12:13:15.200 [INFO] database P0000080255 T0000000000000080255 rsys_rarch_obj_fil_collect seqno[0] end, total_size 69632. 2024-07-27 12:13:15.201 [INFO] database P0000080255 T0000000000000080255 rsys_rarch_obj_fil_collect path:[GRP_ADDTEST_02] begin. 2024-07-27 12:13:15.203 [FATAL] database P0000080255 T0000000000000080304 comm_create_lsnr_sockets_low failed to create socket or listen port:5336, errno:107. 2024-07-27 12:13:15.203 [FATAL] database P0000080255 T0000000000000080304 [for dem]SYSTEM SHUTDOWN ABORT. 2024-07-27 12:13:15.204 [FATAL] database P0000080255 T0000000000000080304 MAL listener can not get the address information 2024-07-27 12:13:15.204 [INFO] database P0000080255 T0000000000000080304 total 0 rfil opened! 注意 FATAL 类型的日志，这个就是关键信息！\n1 2 comm_create_lsnr_sockets_low failed to create socket or listen port:5336, errno:107. MAL listener can not get the address information 问题就出现在 MAL 的 5336 端口上\n查看 dmmal.ini 文件，果然，MAL_PORT 忘改了，还是原来的实例端口，新实例的 MAL 端口与之前的冲突了，修改它为 5337\n正常启动\r1 2 [dmdba@linux1 bin]$ ./DmServiceGRP_ADDTEST_01 start Starting DmServiceGRP_ADDTEST_01: [ OK ] 修改参数\r1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 [dmdba@linux1 bin]$ ./disql SYSDBA/SYSDBA@192.168.163.9:5237 服务器[192.168.163.9:5237]:处于普通配置状态 登录使用时间 : 6.374(ms) disql V8 SQL\u0026gt; SP_SET_PARA_VALUE(1,\u0026#39;ALTER_MODE_STATUS\u0026#39;,1); DMSQL 过程已成功完成 已用时间: 12.962(毫秒). 执行号:1. SQL\u0026gt; SP_SET_OGUID(45332); DMSQL 过程已成功完成 已用时间: 5.791(毫秒). 执行号:2. SQL\u0026gt; ALTER DATABASE PRIMARY; 操作已执行 已用时间: 16.329(毫秒). 执行号:0. SQL\u0026gt; SP_SET_PARA_VALUE(1,\u0026#39;ALTER_MODE_STATUS\u0026#39;,0); DMSQL 过程已成功完成 已用时间: 28.218(毫秒). 执行号:3. B 机器启动、修改\r1 2 3 4 5 6 7 8 9 [dmdba@linux2 bin]$ ./DmServiceGRP_ADDTEST_02 start Starting DmServiceGRP_ADDTEST_02: [ FAILED ] dmdba@linux2 log]$ cat dm_GRP_ADDTEST_02_202407.log 2024-07-27 12:26:28.172 [INFO] database P0000076312 T0000000000000076312 INI parameter DW_PORT changed, the original value 0, new value 5537 2024-07-27 12:26:28.173 [ERROR] database P0000076312 T0000000000000076312 Read ini file(/home/dmdba/ADDTEST_data/ADDTEST/dmarch.ini) error in line 13, code(-952) 2024-07-27 12:26:28.173 [INFO] database P0000076312 T0000000000000076312 INI parameter DPC_2PC changed, the original value 1, new value 0 2024-07-27 12:26:28.203 [FATAL] database P0000076312 T0000000000000076312 dmserver startup failed, code = -952 [archive_dest can not be self instance] 2024-07-27 12:26:28.204 [FATAL] database P0000076312 T0000000000000076312 nsvr_ini_file_read failed, [code: -952] 额。。。\n这个也报错了，看日志里的 ERROR\n1 database P0000076312 T0000000000000076312 Read ini file(/home/dmdba/ADDTEST_data/ADDTEST/dmarch.ini) error in line 13, code(-952) 又忘记修改了，dmarch.ini 归档配置文件里，复制贴贴主库的配置，没有修改实时归档的目标实例为主库\n修改 ARCH_DEST = GRP_ADDTEST_01\n重新启动\n1 2 [dmdba@linux2 bin]$ ./DmServiceGRP_ADDTEST_02 start Starting DmServiceGRP_ADDTEST_02: [ OK ] 修改参数，OGUID 和数据库模式\n这里修改为备库\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 [dmdba@linux2 bin]$ ./disql SYSDBA/SYSDBA@192.168.163.10:5237 服务器[192.168.163.10:5237]:处于普通配置状态 登录使用时间 : 11.200(ms) disql V8 SQL\u0026gt; SP_SET_PARA_VALUE(1,\u0026#39;ALTER_MODE_STATUS\u0026#39;,1); DMSQL 过程已成功完成 已用时间: 47.346(毫秒). 执行号:1. SQL\u0026gt; SP_SET_OGUID(45332); DMSQL 过程已成功完成 已用时间: 8.650(毫秒). 执行号:2. SQL\u0026gt; ALTER DATABASE STANDBY; 操作已执行 已用时间: 20.649(毫秒). 执行号:0. SQL\u0026gt; SP_SET_PARA_VALUE(1,\u0026#39;ALTER_MODE_STATUS\u0026#39;,0); DMSQL 过程已成功完成 已用时间: 33.556(毫秒). 执行号:3. 启动守护进程\rA 、 B 机器都启动\n1 2 [dmdba@linux1 bin]$ ./DmWatcherServiceWatcherADDTEST start Starting DmWatcherServiceWatcherADDTEST: [ OK ] 启动监视器\r监视器是配置在 A 机器上，即主库的机器上的\n1 2 [dmdba@linux1 bin]$ ./DmMonitorServiceMonitorADDTEST start Starting DmMonitorServiceMonitorADDTEST: [ FAILED ] 好了，监视器启动也报错\n日志也没有，奇怪了，通过前台启动看看\n1 2 3 4 5 [dmdba@linux1 bin]$ ./dmmonitor /home/dmdba/ADDTEST_data/ADDTEST/dmmonitor.ini Invalid [group_name] or the file contains unrecognized characters! Read ini file(/home/dmdba/ADDTEST_data/ADDTEST/dmmonitor.ini) error in line 1, code(-803) DMMONITOR[4.0] V8 Read ini failed, please check the ini path(/home/dmdba/ADDTEST_data/ADDTEST/dmmonitor.ini) or invalid configuration or permission denied! 配置无效或者权限被拒绝\n又是复制贴贴的报错，复制进SHELL里，头两个字母被吞掉了\n1 2 [dmdba@linux1 bin]$ ./DmMonitorServiceMonitorADDTEST start Starting DmMonitorServiceMonitorADDTEST: [ OK ] 验证连接\r在达梦数据库服务器上配置 dm_svc.conf ，同时在应用服务器上配置 dm_svc.conf\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 TIME_ZONE=(480) LANGUAGE=(CN) GRP1=(192.168.163.9:5236,192.168.163.10:5236) GRP2=(192.168.163.9:5237,192.168.163.10:5237) # 服务配置 [GRP1] TIME+ZONE=(+480) # 指定优先登录的服务器模式 0-优先PRIMARY 1-只连接主库 2-只连接备库 3-优先STANDBY 4-优先NORMAL（缺省默认） LOGIN_MODE=(0) SWITCH_TIME=(3) SWITCH_INTERVAL=(200) [GRP2] TIME+ZONE=(+480) # 指定优先登录的服务器模式 0-优先PRIMARY 1-只连接主库 2-只连接备库 3-优先STANDBY 4-优先NORMAL（缺省默认） LOGIN_MODE=(0) SWITCH_TIME=(3) SWITCH_INTERVAL=(200) 使用达梦管理工具连接，一切正常\n注意\r在服务启动时，一般都使用后台运行的方式，即达梦通过注册服务后生成的 DmServiceXXXX``DmWatcherXXXX``DmMonitorXXXX 文件去启动\n当如果这个方式启动出现报错时，但是日志又没有记录，可以使用前台命令启动，让前台直接打印启动过程的信息\n1 2 cd /home/dmdba/dmdbms/bin ./dmserver /path/to/dm.ini # dmwatcher.ini dmmonitor.ini ","date":"2024-08-19T20:02:15+08:00","permalink":"http://localhost:1313/posts/2024/08/%E4%B8%BB%E5%A4%87%E9%9B%86%E7%BE%A4-%E6%96%B0%E5%A2%9E%E8%BE%BE%E6%A2%A6%E5%AE%9E%E4%BE%8B%E5%B9%B6%E9%85%8D%E7%BD%AE%E5%AE%9E%E6%97%B6%E4%B8%BB%E5%A4%87%E9%9B%86%E7%BE%A4%E4%B8%89/","title":"主备集群-新增达梦实例并配置实时主备集群（三）"},{"content":"问题一：非正常时间格式转换问题\r背景\r最近在项目上，使用ETL工具配置任务，将上游数据直接推送到kafka topic 中，让另一个系统去消费这些实时成交的数据。\n之前经验的不足，没有对推送的数据做限制，导致每次推送到topic 里都是全量数据，几百万的数据被反复推送到topic里。需要对推送的任务进行修改，增量推送数据到kafka，经过咨询，使用单调递增的流水字段去配置，推送过的数据就不再反复推送。\n并且为了避免数据的重复，还需要设置主键，确保每一条数据都是为唯一。\n问题\r我使用每笔交易的时间去做流水字段，简单的进行了to_date()，发现报错了：非法的时间日期类型数据。\n查看上游的数据，交易时间为：\n我们想要的时间是 15:05:17 09:31:58 时分秒格式的，并且另一个系统所需要的为字符串类型\n解决\r首先，对于10点之前的数据肯定要在前边补充一个0，让它是正常的时间数据格式，使用lpad 函数\n然后再将利用to_date 进行转换\nto_date 转换是默认加上了年月日的，还需要再进行一次to_char转换，转换为需要用到的字符串格式\n问题二：上下游编码不一致产生的日期格式转换问题\r背景\r在某合规系统，利害关系人的数据源变更，我们采集的上游由数据库A变更为数据库B，原先写的SP转换突然就报错了，其中有一段日期转换出错了，经过查看采集过来的数据，发现B库的日期格式与A库的日期格式不一致。\n原先A库的日期格式是YYYY-MM-DD HH24.MI.SS.FF\n但是变更源库后，表的日期格式是YY-MON-DD HH.MI.SS.FF9 PM的格式\n问题\r原先，我们系统里，只需要将日期做如下的转换即可\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 insert into CMSCONFIG.T_XXX_REPORT_XXX (app_no , app_emp_no , emp_no , report_type2 , status , app_time , approve_time ) select a.id, a.brokerid, a.brokerid, \u0026#39;1\u0026#39;, \u0026#39;1\u0026#39;, to_date(to_char(to_timestamp(a.updatetime,\u0026#39;yyyy-mm-dd hh24:mi:ss.ff\u0026#39;),\u0026#39;yyyy/mm/dd hh24:mi:ss\u0026#39;),\u0026#39;yyyy/mm/dd hh24:mi:ss\u0026#39;), to_date(to_char(to_timestamp(a.updatetime,\u0026#39;yyyy-mm-dd hh24:mi:ss.ff\u0026#39;),\u0026#39;yyyy/mm/dd hh24:mi:ss\u0026#39;),\u0026#39;yyyy/mm/dd hh24:mi:ss\u0026#39;) from NC11.ST_EM_XXXXXXON a where not exists (select 1 from CMSCONFIG.T_XXX_REPORT_XXX t where a.id = t.app_no and t.report_type2 = \u0026#39;1\u0026#39;); 1 2 3 4 5 select to_date(to_char(to_timestamp(\u0026#39;2024-6-1 17.38.54.000000000\u0026#39;, \u0026#39;yyyy-mm-dd hh24:mi:ss.ff\u0026#39;), \u0026#39;yyyy/mm/dd hh24:mi:ss\u0026#39;), \u0026#39;yyyy/mm/dd hh24:mi:ss\u0026#39;) as datetime from dual; 但是换库之后，日期格式改变了，变为了如下形式：\n1 \u0026#39;18-MAR-24 03.44.12.000000000 PM\u0026#39; 此时，还是继续使用上述的SQL进行日期转换，则会报错无效的月份\n当时尝试了很多\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 -- 在Oracle中报错日期格式无法识别 SELECT TO_DATE(\u0026#39;18-MAR-24 03.44.12.000000000 PM\u0026#39;, \u0026#39;YY-MON-DD HH.MI.SS.FF9 PM\u0026#39;) AS datetime FROM dual; -- 在Oracle中报错无效的月份 SELECT TO_TIMESTAMP(\u0026#39;18-MAR-24 03.44.12.000000000 PM\u0026#39;, \u0026#39;YY-MON-DD HH.MI.SS.FF9 PM\u0026#39;) AS datetime FROM dual; -- 在Oracle中报错要求AM/A.M.或PM/P.M. SELECT TO_TIMESTAMP(\u0026#39;18-3-24 03.44.12.000000000 PM\u0026#39;, \u0026#39;YY-MM-DD HH.MI.SS.FF9 PM\u0026#39;) AS datetime FROM dual; 到底应该如何将 \u0026lsquo;18-MAR-24 03.44.12.000000000 PM\u0026rsquo; 转换为 \u0026lsquo;2024/3/18 15:44:12\u0026rsquo; 呢？？？\n当时百度了很多路子，试过很多方法，在一篇帖子上看到可能跟NLS_LANGUAGE有关，随后去ORACLE官网看相关解答：\n语言环境的不一致可能会导致数据不一致，有可能这个原因\n解决\r有了方向后，开始尝试\n查看本地库的NLS_LANGUAGE参数\n上游的库NLS_LANGUAGE，让客户帮忙咨询，是american\n在本地尝试\n1 2 3 4 5 6 select to_date( to_char( to_timestamp(\u0026#39;18-MAR-24 03.44.12.000000000 PM\u0026#39;, \u0026#39;DD-MON-RR HH.MI.SS.FF AM\u0026#39;, \u0026#39;NLS_DATE_LANGUAGE = AMERICAN\u0026#39;), \u0026#39;YYYY/MM/DD HH24:MI:SS\u0026#39;), \u0026#39;YYYY/MM/DD HH24:MI:SS\u0026#39;) AS datetime from dual; 可以转换出结果，没问题。就是这样，在to_timestamp里加入NLS_LANGUAGE=AMERICAN 参数可以解决。\n把这段逻辑替换到SP对应的代码里，成功解决日期报错的问题。\n","date":"2024-08-15T21:02:51+08:00","permalink":"http://localhost:1313/posts/2024/08/sql-%E6%97%A5%E6%9C%9F%E6%97%B6%E9%97%B4%E8%BD%AC%E6%8D%A2%E9%97%AE%E9%A2%98/","title":"SQL-日期时间转换问题"},{"content":"更新\r20240909\n优化了监控日志按照 年月 目录存放 新增对同一个数据库多实例情况的巡检 简要说明\r这个 shell 脚本用于数据库服务器上的日常检查：\n系统检查：系统时间、CPU、内存、磁盘、IO 达梦数据库服务：实例、数据守护、集群状态 实例检查：日志是否出现 ERROR \\ FATAL 等报错，出现报错则将报错信息重定向到存放报错的文件 这个 shell 脚本使用的命令都是平时工作中使用到的命令\n特别是查看文件内容并输出指定的内容，使用 grep awk sed cut 等命令结合。\n例如 awk '/^avg-cpu/ {getline; print$6}' 找到 avg-cpu开头的行，然后使用 getline读取下一行列的内容并输出第 6 列\n例如 grep -e 使用正则表达式\n例如 awk -v 使用变量\n还有使用 while 循环打印内容，if 进行条件判断，还有对 |管道符的用法，它可以将上一个命令返回的内容传递给下一个命令\n复用性\r此脚本直接拿到新机器执行，只需要修改 实例数据文件 的路径就可以了，虽然在脚本里可以实现查找实例数据文件，考虑到有的服务器上文件特别多，每次执行脚本都查找一遍，效率不好（虽然也不差这几秒）。\n此外，达梦数据库的配置文件名称其实都是一致的，不需要修改\n脚本\r1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 #!/bin/bash #################################################################################################### # Author:\tWei Qi # Remark:\t1.系统检查：CPU、内存、磁盘、IO、网络、系统时间 # 2.数据库服务检查：实例、守护、监视器 # 3.实例检查：日志、会话 # 全局变量使用 VarName 方式命名，局部变量使用 var_name 方式命名 # CreateDate:\t2024-07-23 # Version:\t1.0 # ModifyDate: # ModifyRemark: #################################################################################################### ###################################### 全局变量 手动修改 ############################################ # 服务、实例全局变量 # 服务配置文件名 DmIniName=\u0026#34;dm.ini\u0026#34; DmWatcherIniName=\u0026#34;dmwatcher.ini\u0026#34; DmMonitorIniName=\u0026#34;dmmonitor.ini\u0026#34; DmMalIniName=\u0026#34;dmmal.ini\u0026#34; # 配置备库 IP PORT # TelnetIP=\u0026#34;10.xx.xx.xxx\u0026#34; # TelnetPORT=\u0026#34;5236\u0026#34; ## 查找 数据库用户 的主目录 ## cut -d: 是根据 : 进行分割\t-f6 是返回分割后的第6列 # UserHomePath=$(getent passwd dmdba | cut -d: -f6) # 有的实例数据文件不在主目录下，手动配置 UserHomePath=\u0026#34;/u01/dmdata/zgfxq\u0026#34; # 定义变量，实例配置文件路径 FindDmIniPath=$(find ${UserHomePath} -name ${DmIniName}) DmIniPath=${FindDmIniPath} # DmIniPath=$(find / -name \u0026#34;dm.ini\u0026#34;) # FindDmWatcherIniPath=$(find ${UserHomePath} -name ${DmWatcherIniName}) # DmWatcherIniPath=${FindDmWatcherIniPath} # FindDmMonitorIniPath=$(find ${UserHomePath} -name ${DmMonitorIniName}) # DmMonitorIniPath=${FindDmMonitorIniPath} FindDmMalIniPath=$(find ${UserHomePath} -name ${DmMalIniName}) DmMalIniPath=${FindDmMalIniPath} echo \u0026#34;DmIniPath : ${DmIniPath}\u0026#34; echo \u0026#34;DmMalIniPath : ${DmMalIniPath}\u0026#34; # 定义达梦各服务端口变量 # grep -w 使用精准匹配 AllDmServicePort=$(cat \u0026#34;${DmIniPath}\u0026#34; | grep -w PORT_NUM | awk \u0026#39;{print $3}\u0026#39;)\t# 数据实例端口 AllDmWatcherPort=$(cat \u0026#34;${DmMalIniPath}\u0026#34; | grep -w MAL_DW_PORT | awk \u0026#39;{print $3}\u0026#39;)\t# 数据守护进程端口 echo \u0026#34;AllDmServicePort : ${AllDmServicePort}\u0026#34; echo \u0026#34;AllDmWatcherPort : ${AllDmWatcherPort}\u0026#34; # 获取实例名称 DmInstanceName=$(cat \u0026#34;${DmIniPath}\u0026#34; | grep -w INSTANCE_NAME | awk \u0026#39;{print $3}\u0026#39;) # 获取当前 IP # GetSystemIp=$(hostname -I) #################################################################################################### # 巡检开始 echo \u0026#34;巡检脚本开始\u0026#34; ########################################## 系统巡检 ################################################ # 系统时间检查 getSystemTime() { current_time=$(date) echo \u0026#34;当前系统时间: ${current_time}\u0026#34; echo \u0026#34;\u0026#34; } # 当前系统信息 getOsSystem() { os_type=$(uname) os_hostname=$(hostname) os_ip=$(hostname -I | awk \u0026#39;{print $1}\u0026#39;) echo \u0026#34;当前机器：${os_type} | ${os_hostname} | ${os_ip}\u0026#34; echo \u0026#34;\u0026#34; } # 获取CPU使用率 getCpuUsage() { # 使用 bn1 获取固定的 top 输出 cpu_usage=$(top -bn1 | grep \u0026#34;Cpu(s)\u0026#34; | sed \u0026#34;s/.*, *\\([0-9.]*\\)%* id.*/\\1/\u0026#34; | awk \u0026#39;{print 100 - $1}\u0026#39;) echo \u0026#34;CPU使用率: ${cpu_usage}%\u0026#34; echo \u0026#34;\u0026#34; } # 获取内存使用率 getMemUsage() { mem_total=$(free -h | grep Mem | awk \u0026#39;{print $2}\u0026#39;) mem_used=$(free -h | grep Mem | awk \u0026#39;{print $3}\u0026#39;) mem_usage=$(free -h | grep Mem | awk \u0026#39;{print$3/$2 * 100.0}\u0026#39;) echo \u0026#34;内存总量：${mem_total}; 内存使用：${mem_used}; 内存使用率: ${mem_usage}%\u0026#34; echo \u0026#34;\u0026#34; } # 获取磁盘空间使用情况 getDiskUsage() { echo \u0026#34;磁盘空间使用情况：\u0026#34; # 获取标题行 # df -h | head -n 1 # 排除这些盘，并循环打印排除后的每一行 df -h | grep -vE \u0026#39;^Filesystem|tmpfs|cdrom\u0026#39; | while read line do echo \u0026#34;${line}\u0026#34; done echo \u0026#34;\u0026#34; } # 获取磁盘IO监控数据 getIoStat() { echo \u0026#34;磁盘IO情况: \u0026#34; iostat # 判断 iowait 值 iostatIowait=$(iostat | awk \u0026#39;/^avg-cpu/ {getline; print$4 * 100.0}\u0026#39;) if [[ $iostatIowait -ge 80 ]]; then echo \u0026#34;磁盘 IO ${iostatIowait}% 大于 80%，可能存在 IO 瓶颈\u0026#34; else echo \u0026#34;磁盘 IO ${iostatIowait}% 正常\u0026#34; fi # 判断 idel 值 iostatIdel=$(iostat | awk \u0026#39;/^avg-cpu/ {getline; print$6}\u0026#39;) # bash 只支持整数比较, 采用 bc 进行判断是否为 true, true = 1 则返回 # if [[ $iostatIdel -ge 80 ]]; then if [[ $(echo \u0026#34;$iostatIdel \u0026gt;= 80\u0026#34; | bc) -eq 1 ]]; then echo \u0026#34;当前 CPU ${iostatIdel}% 资源充足\u0026#34; elif [[ $(echo \u0026#34;$iostatIdel \u0026lt;= 10\u0026#34;| bc) -eq 1 ]]; then echo \u0026#34;当前 CPU ${iostatIdel}% 资源紧张\u0026#34; else echo \u0026#34;当前 CPU ${iostatIdel}% 资源适中\u0026#34; fi echo \u0026#34;\u0026#34; } # 获取网络资源监控数据 # getNetwork() { # echo \u0026#34;网络接口流量统计(单位: KB/s): \u0026#34; # sar -n DEV 1 1 | grep Average # echo \u0026#34;\u0026#34; # } ########################################## 服务巡检 ################################################ echo \u0026#34;服务检查开始 --------------------------- \u0026#34; # 达梦数据库服务 getDatabaseService() { dm_service=$(ps -ef | grep dmserver | grep \u0026#34;${DmIniName}\u0026#34; | grep -v grep | awk \u0026#39;{print $1,$2}\u0026#39;) dm_service_port=$(netstat -nltp | grep \u0026#34;${AllDmServicePort}\u0026#34; | awk \u0026#39;{print $4}\u0026#39; | cut -d: -f4) # 检查变量是否非空 if [ -n \u0026#34;${dm_service}\u0026#34; ] \u0026amp;\u0026amp; [ -n \u0026#34;${dm_service_port}\u0026#34; ]; then echo \u0026#34;当前用户、进程 PID : ${dm_service}, 端口：${dm_service_port} | dm 正常\u0026#34; else echo \u0026#34;没有找到 达梦服务 进程\u0026#34; fi } # 达梦数据守护服务 getDatabaseWatcher() { dm_watcher=$(ps -ef | grep \u0026#34;${DmWatcherIniName}\u0026#34; | grep -v grep | awk \u0026#39;{print $1,$2}\u0026#39;) dm_watcher_port=$(netstat -nltp | grep \u0026#34;${AllDmWatcherPort}\u0026#34; | awk \u0026#39;{print $4}\u0026#39; | cut -d: -f4) # 检查变量是否非空 if [ -n \u0026#34;${dm_watcher}\u0026#34; ] \u0026amp;\u0026amp; [ -n \u0026#34;${dm_watcher_port}\u0026#34; ]; then echo \u0026#34;当前用户、进程 PID : ${dm_watcher} | dmwatcher 正常\u0026#34; else echo \u0026#34;没有找到 达梦数据守护 进程\u0026#34; fi } # 达梦确认监视器服务 getDatabaseMonitor() { dm_monitor=$(ps -ef | grep ${DmMonitorIniName} | grep -v grep | awk \u0026#39;{print $1,$2}\u0026#39;) # 检查变量是否非空 if [ -n \u0026#34;${dm_monitor}\u0026#34; ]; then echo \u0026#34;当前用户、进程 PID : ${dm_monitor} | dmmonitor 正常\u0026#34; else echo \u0026#34;没有找到 达梦监视器 进程\u0026#34; fi } # 主备网络连通 # getDatabaseTelnetIpPort() { # telnet \u0026#34;${TelnetIP}\u0026#34; \u0026#34;${TelnetPORT}\u0026#34; # if [ $? -eq 0 ]; then # echo \u0026#34;达梦端口连通正常\u0026#34; # else # echo \u0026#34;达梦端口连通失败！！！\u0026#34; # fi # } ########################################## 实例巡检 ################################################ # 日志检查 # 变量 # 实例路径（用户主目录） DmServicePath=$(getent passwd dmdba | cut -d: -f6) # 获取当前目录 PwdPath=$(cd \u0026#34;$(dirname \u0026#34;$0\u0026#34;)\u0026#34; || exit; pwd) echo \u0026#34;PwdPath : ${PwdPath}\u0026#34; # 获取当前日期 CurrentYearMonth=$(date +%Y%m) CurrentYearMonthDay=$(date +%Y-%m-%d) # 检查目录文件是否存在, 不存在则创建，用于存放 ErrorLog LogPathName=\u0026#34;dmErrorLog\u0026#34; LogFileName=\u0026#34;dm_error_log_$(date +%Y%m%d).log\u0026#34; # 判断目录文件 getCreateDir() { if [ ! -d \u0026#34;${PwdPath}/${LogPathName}\u0026#34; ]; then mkdir -p \u0026#34;${PwdPath}/${LogPathName}\u0026#34; echo \u0026#34;日志目录已创建\u0026#34; else echo \u0026#34;日志目录已存在\u0026#34; fi } getCreateFile() { if [ ! -f \u0026#34;${PwdPath}/${LogPathName}/${LogFileName}\u0026#34; ]; then touch \u0026#34;${PwdPath}/${LogPathName}/${LogFileName}\u0026#34; echo \u0026#34;日志文件已创建\u0026#34; else echo \u0026#34;日志文件已存在\u0026#34; fi } echo \u0026#34;实例检查开始 --------------------------- \u0026#34; # 会话数量 getMaxSession() { max_session=$(netstat -nat | awk \u0026#39;{print $4}\u0026#39; | grep 5236 | wc -l) # 引用配置文件路径变量 cat_dmini_max_session=$(cat ${DmIniPath} | grep MAX_SESSIONS | awk \u0026#39;{print $3}\u0026#39;) echo \u0026#34;当前会话数量：${max_session}, 达梦最大会话数量：${cat_dmini_max_session}, 活动会话占比：${max_session}/${cat_dmini_max_session}\u0026#34; echo \u0026#34;\u0026#34; } # 实例日志 getDmServiceLog() { dmservice_log_full_path=\u0026#34;${DmServicePath}/dmdbms/log/dm_${DmInstanceName}_${CurrentYearMonth}.log\u0026#34; cat_dmservice_error_log=$(cat ${dmservice_log_full_path} | grep -e \u0026#39;\\[ERROR]\u0026#39; -e \u0026#39;\\[FATAL]\u0026#39; | grep ${CurrentYearMonthDay}) if [ $? -eq 0 ]; then save_dmserver_error_log=\u0026#34;${PwdPath}/${LogPathName}/${LogFileName}\u0026#34; echo \u0026#34;${cat_dmservice_error_log}\u0026#34; \u0026gt;\u0026gt; \u0026#34;${save_dmserver_error_log}\u0026#34; if [ -s \u0026#34;${save_dmserver_error_log}\u0026#34; ]; then echo \u0026#34;警告：今天 ${CurrentYearMonthDay} 数据库实例日志已写入\u0026#34; echo \u0026#34;================ ${CurrentYearMonthDay} : dm_${DmInstanceName}_${CurrentYearMonth}.log 写入完成 =======================\u0026#34; \u0026gt;\u0026gt; ${save_dmserver_error_log} else echo \u0026#34;数据库实例日志无新内容\u0026#34; fi\telse echo \u0026#34;正常：${CurrentYearMonthDay} 数据库实例日志 dm_server 无 Error or Fatal\u0026#34; fi # echo \u0026#34;\u0026#34; } # 数据守护日志 getDmWatcherLog() { dmwatcher_log_full_path=\u0026#34;${DmServicePath}/dmdbms/log/dm_dmwatcher_${DmInstanceName}_${CurrentYearMonth}.log\u0026#34; cat_dmwatcher_error_log=$(cat ${dmwatcher_log_full_path} | grep -e \u0026#39;\\[ERROR]\u0026#39; -e \u0026#39;\\[FATAL]\u0026#39; | grep ${CurrentYearMonthDay}) # 有输出内容则返回状态码 0 ，表示成功匹配到了相应的内容 if [ $? -eq 0 ]; then save_dmserver_error_log=\u0026#34;${PwdPath}/${LogPathName}/${LogFileName}\u0026#34; echo \u0026#34;${cat_dmwatcher_error_log}\u0026#34; \u0026gt;\u0026gt; \u0026#34;${save_dmserver_error_log}\u0026#34; if [ -s \u0026#34;${save_dmserver_error_log}\u0026#34; ]; then echo \u0026#34;警告：今天 ${CurrentYearMonthDay} 数据守护日志已写入\u0026#34; echo \u0026#34;================= ${CurrentYearMonthDay} : dm_dmwatcher_${DmInstanceName}_${CurrentYearMonth}.log 写入完成 ======================= \u0026#34; \u0026gt;\u0026gt; ${save_dmserver_error_log} else echo \u0026#34;数据守护日志无新内容\u0026#34; fi else echo \u0026#34;正常：${CurrentYearMonthDay} 数据守护进程日志 dm_watcher 无 Error or Fatal\u0026#34; fi\t# echo \u0026#34;\u0026#34; } # 监视器（检查集群状态） getDmMonitorLog() { dmmonitor_log_full_path=\u0026#34;${DmServicePath}/dmdbms/log/\u0026#34; save_dmserver_error_log=\u0026#34;${PwdPath}/${LogPathName}/${LogFileName}\u0026#34; # ls -lt 按修改时间，正序排序， head -n 1 显示第一个文件（最新文件） dmmonitor_log_new_head=$(ls -lt \u0026#34;${dmmonitor_log_full_path}\u0026#34; | grep dmmonitor | head -n 1 | awk \u0026#39;{print $9}\u0026#39;) # 从 dmmal.ini 获取集群各个节点IP # grep -n 打印行号， -w 输出相关的行内容 get_dmgroup_ip_a=$(cat \u0026#34;${DmMalIniPath}\u0026#34; | grep -n MAL_INST_HOST | grep -w 8 | awk \u0026#39;{print $3}\u0026#39;) get_dmgroup_ip_b=$(cat \u0026#34;${DmMalIniPath}\u0026#34; | grep -n MAL_INST_HOST | grep -w 18 | awk \u0026#39;{print $3}\u0026#39;) # 需要绝对路径，不然找不到这个日志名 cat_dmmonit_status=$(tail -n 35 \u0026#34;${dmmonitor_log_full_path}/${dmmonitor_log_new_head}\u0026#34;) # awk 使用 ip1 和 ip2 存储 集群IP 信息，找到第 5 列 ISTATUS 的值 # 使用正确的方式传递变量给 awk\t。 这里将这个变量的输出内容 \u0026lt;\u0026lt;\u0026lt; 传给 awk 命令 check_dmmonitor_status=$(awk -v ip1=\u0026#34;${get_dmgroup_ip_a}\u0026#34; -v ip2=\u0026#34;${get_dmgroup_ip_b}\u0026#34; \u0026#39;$1 == ip1 { istatus1 = $5 }$1 == ip2 { istatus2 = $5 } END { print istatus1, istatus2 }\u0026#39; \u0026lt;\u0026lt;\u0026lt; \u0026#34;${cat_dmmonit_status}\u0026#34;) # 检查 istatus1 和 istatus2 的值 if [[ $check_dmmonitor_status == *\u0026#34;OPEN\u0026#34;* ]]; then echo \u0026#34;正常：集群节点服务状态为 OPEN\u0026#34; else echo \u0026#34;警告：集群节点服务状态不为 OPEN\u0026#34; # 如果服务异常，将状态写入日志文件 echo \u0026#34;警告：${CurrentYearMonthDay} 集群节点服务状态异常 -${check_dmmonitor_status}\u0026#34; \u0026gt;\u0026gt; ${save_dmserver_error_log} echo \u0026#34;================= ${CurrentYearMonthDay} : dmmonitor_${DmInstanceName}_${CurrentYearMonth}.log 写入完成 ======================= \u0026#34; \u0026gt;\u0026gt; ${save_dmserver_error_log} fi echo \u0026#34;\u0026#34; } # 保存巡检报告 report_file=\u0026#34;/opt/checkDayBash/log/system_check_$(date +%Y%m%d%H%M%S).log\u0026#34; { echo \u0026#34;============================== 系统巡检 ==============================\u0026#34; getSystemTime\t# ok getOsSystem\t# ok getCpuUsage\t# ok getMemUsage\t# ok getDiskUsage\t# ok getIoStat\t# ok # getNetwork\t# ok echo \u0026#34;\u0026#34; echo \u0026#34;=========================== 数据库服务巡检 ===========================\u0026#34; getDatabaseService\t# ok getDatabaseWatcher\t# ok getDatabaseMonitor\t# ok # getDatabaseTelnetIpPort\t# ok echo \u0026#34;\u0026#34; echo \u0026#34;============================== 实例巡检 ==============================\u0026#34; getCreateDir getCreateFile echo \u0026#34;日志检查: \u0026#34; echo \u0026#34;\u0026#34; getDmServiceLog\t# ok getDmWatcherLog\t# ok getDmMonitorLog # ok getMaxSession\t# ok } \u0026gt; \u0026#34;${report_file}\u0026#34; echo \u0026#34;巡检脚本结束\u0026#34; echo \u0026#34;巡检报告已保存至 ${report_file}\u0026#34; 效果\r查看巡检报告\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 ============================== 系统巡检 ============================== 当前系统时间: 2024年 07月 26日 星期五 08:37:26 CST 当前机器：Linux | YD-FXQDB01-3-161 | 1X.XXX.XXX.161 CPU使用率: 0.2% 内存总量：254Gi; 内存使用：37Gi; 内存使用率: 14.5669% 磁盘空间使用情况： 文件系统 容量 已用 可用 已用% 挂载点 /dev/mapper/klas-root 860G 107G 754G 13% / /dev/sda2 1014M 194M 821M 20% /boot /dev/sda1 511M 6.5M 505M 2% /boot/efi /dev/loop0 1.1G 1.1G 0 100% /mnt/dmrom 磁盘IO情况: Linux 4.19.90-24.4.v2101.ky10.aarch64 (YD-FXQDB01-3-161) 2024年07月26日 _aarch64_ (64 CPU) avg-cpu: %user %nice %system %iowait %steal %idle 0.03 0.00 0.02 0.00 0.00 99.95 Device tps kB_read/s kB_wrtn/s kB_dscd/s kB_read kB_wrtn kB_dscd dm-0 6.61 0.23 369.90 0.00 863876 1365033852 0 loop0 0.00 0.46 0.00 0.00 1686907 0 0 sda 6.39 0.24 369.90 0.00 887725 1365036529 0 磁盘 IO 0% 正常 当前 CPU 99.95% 资源充足 =========================== 数据库服务巡检 =========================== 当前用户、进程 PID : dmdba 2834456, 端口：5236 | dm 正常 当前用户、进程 PID : dmdba 2616858 | dmwatcher 正常 当前用户、进程 PID : dmdba 2617379 | dmmonitor 正常 ============================== 实例巡检 ============================== 日志目录已存在 日志文件已创建 日志检查: 正常：2024-07-26 数据库实例日志 dm_server 无 Error or Fatal 正常：2024-07-26 数据守护进程日志 dm_watcher 无 Error or Fatal 正常：集群节点服务状态为 OPEN 当前会话数量：79, 达梦最大会话数量：5000, 活动会话占比：79/5000 脚本 20240911\r在函数内部定义一个参数，用来传入数组里的变量，实现循环的效果。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 #!/bin/bash ##################################################################################### # Author:\tWei Qi # Remark:\t1.系统检查：CPU、内存、磁盘、IO、网络、系统时间 # 2.数据库服务检查：实例、守护、监视器 # 3.实例检查：日志、会话 # 全局变量使用 VarName 方式命名，局部变量使用 var_name 方式命名 # CreateDate:\t2024-07-23 # Version:\t2.0 # Modify： 2024-09-11 1.采用循环传参的方式，增加检查第二个数据库实例的数据库服务状态、日志、会话 # 2.优化日志输出，以年月为一个目录存放 ##################################################################################### ################################ 全局变量 手动修改 ##################################### # 数据库实例 DBInstanceName=(\u0026#34;AMOP\u0026#34; \u0026#34;zgfxq\u0026#34; ) # 数据库实例配置文件 DmIniName=\u0026#34;dm.ini\u0026#34; DmWatcherIniName=\u0026#34;dmwatcher.ini\u0026#34; DmMalIniName=\u0026#34;dmmal.ini\u0026#34; DmMonitorIniName=\u0026#34;dmmonitor.ini\u0026#34; # 数据库服务路径 DmServicePath=$(getent passwd dmdba | cut -d: -f6) ############################### 判断目录是否创建 ##################################### # 创建存放日志的文件 # 获取当前目录 PwdPath=$(cd \u0026#34;$(dirname \u0026#34;$0\u0026#34;)\u0026#34; || exit; pwd) # 获取当前日期 CurrentYearMonth=$(date +%Y%m) CurrentYearMonthDay=$(date +%Y-%m-%d) # 检查目录文件是否存在, 不存在则创建，用于存放 ErrorLog LogPathName=\u0026#34;dmErrorLog\u0026#34; LogFileName=\u0026#34;dm_error_log_$(date +%Y%m%d).log\u0026#34; # 创建存放达梦日志的错误输出文件 getCreateDirDm() { if [ ! -d \u0026#34;${PwdPath}/${LogPathName}/${CurrentYearMonth}\u0026#34; ]; then mkdir -p \u0026#34;${PwdPath}/${LogPathName}/${CurrentYearMonth}\u0026#34; echo \u0026#34;[OK] 达梦日志记录目录已创建\u0026#34; else echo \u0026#34;[WARNING] 达梦日志记录目录已创建\u0026#34; fi } getCreateFileDm() { if [ ! -f \u0026#34;${PwdPath}/${LogPathName}/${CurrentYearMonth}/${LogFileName}\u0026#34; ]; then touch \u0026#34;${PwdPath}/${LogPathName}/${CurrentYearMonth}/${LogFileName}\u0026#34; echo \u0026#34;[OK] 达梦日志文件已创建\u0026#34; else echo \u0026#34;[WARNING] 达梦日志文件已存在\u0026#34; fi } # 创建存放巡检日志的文件 getCreateDirLog() { if [ ! -d \u0026#34;${PwdPath}/log/${CurrentYearMonth}\u0026#34; ]; then mkdir -p \u0026#34;${PwdPath}/log/${CurrentYearMonth}\u0026#34; echo \u0026#34;[OK] 巡检日志目录已创建\u0026#34; else echo \u0026#34;[WARNING] 巡检日志目录已存在\u0026#34; fi } #################################### 服务巡检 ######################################### # 达梦数据库服务 getDatabaseService() { local service=$1 local service_port=$2 dm_service=$(ps -ef | grep ${service} | grep \u0026#34;${DmIniName}\u0026#34; | grep -v grep | awk \u0026#39;{print $1,$2}\u0026#39;) dm_service_port=$(netstat -nltp | grep \u0026#34;${service_port}\u0026#34; | awk \u0026#39;{print $4}\u0026#39; | cut -d: -f4) # 检查变量是否非空 if [ -n \u0026#34;${dm_service}\u0026#34; ] \u0026amp;\u0026amp; [ -n \u0026#34;${dm_service_port}\u0026#34; ]; then echo \u0026#34;[OK] 当前用户、进程 PID : ${dm_service}, 端口：${dm_service_port} | dm 正常\u0026#34; else echo \u0026#34;[WARNING] 没有找到达梦服务进程\u0026#34; fi } # 达梦数据守护服务 getDatabaseWatcher() { local service=$1 local service_port=$2 dm_watcher=$(ps -ef | grep ${service} | grep \u0026#34;${DmWatcherIniName}\u0026#34; | grep -v grep | awk \u0026#39;{print $1,$2}\u0026#39;) dm_watcher_port=$(netstat -nltp | grep \u0026#34;${service_port}\u0026#34; | awk \u0026#39;{print $4}\u0026#39; | cut -d: -f4) # 检查变量是否非空 if [ -n \u0026#34;${dm_watcher}\u0026#34; ] \u0026amp;\u0026amp; [ -n \u0026#34;${dm_watcher_port}\u0026#34; ]; then echo \u0026#34;[OK] 当前用户、进程 PID : ${dm_watcher} | dmwatcher 正常\u0026#34; else echo \u0026#34;[WARNING] 没有找到达梦数据守护进程\u0026#34; fi } # 达梦确认监视器服务 getDatabaseMonitor() { local service=$1 # 检查达梦确认监视器进程 dm_monitor=$(ps -ef | grep ${service} | grep ${DmMonitorIniName} | grep -v grep | awk \u0026#39;{print $1,$2}\u0026#39;) # 检查变量是否非空 if [ -n \u0026#34;${dm_monitor}\u0026#34; ]; then echo \u0026#34;[OK] 当前用户、进程 PID : ${dm_monitor} | dmmonitor 正常\u0026#34; else echo \u0026#34;[WARNING] 没有找到达梦监视器进程\u0026#34; fi } #################################### 实例巡检 ######################################### # 会话数量 getMaxSession() { local DBServicePort=$1 max_session=$(netstat -nat | awk \u0026#39;{print $4}\u0026#39; | grep \u0026#34;${DBServicePort}\u0026#34; | wc -l) # 引用配置文件路径变量 cat_dmini_max_session=$(cat \u0026#34;${DBInstanceNameProfilePath}/${DmIniName}\u0026#34; | grep MAX_SESSIONS | awk \u0026#39;{print $3}\u0026#39;) echo \u0026#34;当前会话数量：${max_session}, 达梦最大会话数量：${cat_dmini_max_session}, 活动会话占比：${max_session}/${cat_dmini_max_session}\u0026#34; echo \u0026#34;\u0026#34; } # 实例日志 getDmServiceLog() { local DBInstanceName=$1 dmservice_log_full_path=\u0026#34;${DmServicePath}/dmdbms/log/dm_${DBInstanceName}_${CurrentYearMonth}.log\u0026#34; cat_dmservice_error_log=$(cat ${dmservice_log_full_path} | grep -e \u0026#39;\\[ERROR]\u0026#39; -e \u0026#39;\\[FATAL]\u0026#39; | grep ${CurrentYearMonthDay}) if [ $? -eq 0 ]; then save_dmserver_error_log=\u0026#34;${PwdPath}/${LogPathName}/${CurrentYearMonth}/${LogFileName}\u0026#34; echo \u0026#34;${cat_dmservice_error_log}\u0026#34; \u0026gt;\u0026gt; \u0026#34;${save_dmserver_error_log}\u0026#34; if [ -s \u0026#34;${save_dmserver_error_log}\u0026#34; ]; then echo \u0026#34;[WARNING] 今天 ${CurrentYearMonthDay} 数据库实例日志已写入\u0026#34; echo \u0026#34;================ ${CurrentYearMonthDay} : dm_${DBInstanceName}_${CurrentYearMonth}.log 写入完成 =======================\u0026#34; \u0026gt;\u0026gt; ${save_dmserver_error_log} else echo \u0026#34;数据库实例日志无新内容\u0026#34; fi\telse echo \u0026#34;[OK] ${CurrentYearMonthDay} 数据库实例日志 dm_server 无 Error or Fatal. 扫描日志文件: ${dmservice_log_full_path}\u0026#34; fi # echo \u0026#34;\u0026#34; } # 数据守护日志 getDmWatcherLog() { local DBInstanceName=$1 dmwatcher_log_full_path=\u0026#34;${DmServicePath}/dmdbms/log/dm_dmwatcher_${DBInstanceName}_${CurrentYearMonth}.log\u0026#34; cat_dmwatcher_error_log=$(cat ${dmwatcher_log_full_path} | grep -e \u0026#39;\\[ERROR]\u0026#39; -e \u0026#39;\\[FATAL]\u0026#39; | grep ${CurrentYearMonthDay}) # 有输出内容则返回状态码 0 ，表示成功匹配到了相应的内容 if [ $? -eq 0 ]; then save_dmserver_error_log=\u0026#34;${PwdPath}/${LogPathName}/${CurrentYearMonth}/${LogFileName}\u0026#34; echo \u0026#34;${cat_dmwatcher_error_log}\u0026#34; \u0026gt;\u0026gt; \u0026#34;${save_dmserver_error_log}\u0026#34; if [ -s \u0026#34;${save_dmserver_error_log}\u0026#34; ]; then echo \u0026#34;[WARNING] 今天 ${CurrentYearMonthDay} 数据守护日志已写入\u0026#34; echo \u0026#34;================= ${CurrentYearMonthDay} : dm_dmwatcher_${DBInstanceName}_${CurrentYearMonth}.log 写入完成 ======================= \u0026#34; \u0026gt;\u0026gt; ${save_dmserver_error_log} else echo \u0026#34;数据守护日志无新内容\u0026#34; fi else echo \u0026#34;[OK] ${CurrentYearMonthDay} 数据守护进程日志 dm_watcher 无 Error or Fatal. 扫描日志文件: ${dmwatcher_log_full_path}\u0026#34; fi\t# echo \u0026#34;\u0026#34; } # 监视器（检查集群状态） getDmMonitorLog() { dmmonitor_log_full_path=\u0026#34;${DmServicePath}/dmdbms/log\u0026#34; # ls -lt 按修改时间，正序排序， head -n 1 显示第一个文件（最新文件） dmmonitor_log_new_head=$(ls -lt \u0026#34;${dmmonitor_log_full_path}\u0026#34; | grep dmmonitor | head -n 1 | awk \u0026#39;{print $9}\u0026#39;) # 从 dmmal.ini 获取集群各个节点IP # grep -n 打印行号， -w 输出相关的行内容 get_dmgroup_ip_a=$(cat \u0026#34;${DBInstanceNameProfilePath}${DmMalIniName}\u0026#34; | grep -n MAL_INST_HOST | grep -w 8 | awk \u0026#39;{print $3}\u0026#39;) get_dmgroup_ip_b=$(cat \u0026#34;${DBInstanceNameProfilePath}${DmMalIniName}\u0026#34; | grep -n MAL_INST_HOST | grep -w 18 | awk \u0026#39;{print $3}\u0026#39;) # 需要绝对路径，不然找不到这个日志名 cat_dmmonit_status=$(tail -n 35 \u0026#34;${dmmonitor_log_full_path}/${dmmonitor_log_new_head}\u0026#34;) # awk 使用 ip1 和 ip2 存储 集群IP 信息，找到第 5 列 ISTATUS 的值 # 使用正确的方式传递变量给 awk\t。 这里将这个变量的输出内容 \u0026lt;\u0026lt;\u0026lt; 传给 awk 命令 check_dmmonitor_status=$(awk -v ip1=\u0026#34;${get_dmgroup_ip_a}\u0026#34; -v ip2=\u0026#34;${get_dmgroup_ip_b}\u0026#34; \u0026#39;$1 == ip1 { istatus1 = $5 }$1 == ip2 { istatus2 = $5 } END { print istatus1, istatus2 }\u0026#39; \u0026lt;\u0026lt;\u0026lt; \u0026#34;${cat_dmmonit_status}\u0026#34;) # 检查 istatus1 和 istatus2 的值 if [[ $check_dmmonitor_status == *\u0026#34;OPEN\u0026#34;* ]]; then echo \u0026#34;[OK] 集群节点服务状态为 OPEN\u0026#34; else echo \u0026#34;[WARNING] 集群节点服务状态: 非 OPEN 状态\u0026#34; fi echo \u0026#34;\u0026#34; } #################################### 系统巡检 ######################################## # 系统时间检查 getSystemTime() { current_time=$(date) echo \u0026#34;当前系统时间: ${current_time}\u0026#34; echo \u0026#34;\u0026#34; } # 当前系统信息 getOsSystem() { os_type=$(uname) os_hostname=$(hostname) os_ip=$(hostname -I | awk \u0026#39;{print $1}\u0026#39;) echo \u0026#34;当前机器：${os_type} | ${os_hostname} | ${os_ip}\u0026#34; echo \u0026#34;\u0026#34; } # 获取CPU使用率 getCpuUsage() { # 使用 bn1 获取固定的 top 输出 cpu_usage=$(top -bn1 | grep \u0026#34;Cpu(s)\u0026#34; | sed \u0026#34;s/.*, *\\([0-9.]*\\)%* id.*/\\1/\u0026#34; | awk \u0026#39;{print 100 - $1}\u0026#39;) echo \u0026#34;CPU使用率: ${cpu_usage}%\u0026#34; echo \u0026#34;\u0026#34; } # 获取内存使用率 getMemUsage() { mem_total=$(free -h | grep Mem | awk \u0026#39;{print $2}\u0026#39;) mem_used=$(free -h | grep Mem | awk \u0026#39;{print $3}\u0026#39;) mem_usage=$(free -h | grep Mem | awk \u0026#39;{print$3/$2 * 100.0}\u0026#39;) echo \u0026#34;内存总量：${mem_total}; 内存使用：${mem_used}; 内存使用率: ${mem_usage}%\u0026#34; echo \u0026#34;\u0026#34; } # 获取磁盘空间使用情况 getDiskUsage() { echo \u0026#34;磁盘空间使用情况：\u0026#34; # 获取标题行 # df -h | head -n 1 # 排除这些盘，并循环打印排除后的每一行 df -h | grep -vE \u0026#39;^Filesystem|tmpfs|cdrom\u0026#39; | while read line do echo \u0026#34;${line}\u0026#34; done echo \u0026#34;\u0026#34; } # 获取磁盘IO监控数据 getIoStat() { echo \u0026#34;磁盘IO情况: \u0026#34; iostat # 判断 iowait 值 iostatIowait=$(iostat | awk \u0026#39;/^avg-cpu/ {getline; print$4 * 100.0}\u0026#39;) if [[ $iostatIowait -ge 80 ]]; then echo \u0026#34;磁盘 IO ${iostatIowait}% 大于 80%，可能存在 IO 瓶颈\u0026#34; else echo \u0026#34;磁盘 IO ${iostatIowait}% 正常\u0026#34; fi # 判断 idel 值 iostatIdel=$(iostat | awk \u0026#39;/^avg-cpu/ {getline; print$6}\u0026#39;) # bash 只支持整数比较, 采用 bc 进行判断是否为 true, true = 1 则返回 # if [[ $iostatIdel -ge 80 ]]; then if [[ $(echo \u0026#34;$iostatIdel \u0026gt;= 80\u0026#34; | bc) -eq 1 ]]; then echo \u0026#34;当前 CPU ${iostatIdel}% 资源充足\u0026#34; elif [[ $(echo \u0026#34;$iostatIdel \u0026lt;= 10\u0026#34;| bc) -eq 1 ]]; then echo \u0026#34;当前 CPU ${iostatIdel}% 资源紧张\u0026#34; else echo \u0026#34;当前 CPU ${iostatIdel}% 资源适中\u0026#34; fi echo \u0026#34;\u0026#34; } #################################### 脚本运行 ######################################### echo \u0026#34;脚本开始 $(date +%Y-%m-%d_%H:%M:%S)\u0026#34; getCreateDirDm getCreateFileDm getCreateDirLog report_file=\u0026#34;/opt/checkDayBash/log/${CurrentYearMonth}/system_check_$(date +%Y%m%d_%H%M%S).log\u0026#34; { echo \u0026#34;============================== 系统巡检 ==============================\u0026#34; getSystemTime getOsSystem getCpuUsage getMemUsage getDiskUsage getIoStat echo \u0026#34;============================== 数据库巡检 ==============================\u0026#34; for service in \u0026#34;${DBInstanceName[@]}\u0026#34;; do # 当前实例名 echo \u0026#34;当前实例名 ${service}: \u0026#34; \u0026gt;\u0026gt; \u0026#34;${report_file}\u0026#34; # 实例配置文件路径 DBInstanceNameProfilePath=$(ps -ef | grep dmserver | grep \u0026#34;${service}\u0026#34; | grep -v grep | awk \u0026#39;{print $9}\u0026#39; | cut -d= -f2 | sed \u0026#39;s/\\dm.ini//\u0026#39;) # 数据库实例端口 DBServicePort=$(cat \u0026#34;${DBInstanceNameProfilePath}${DmIniName}\u0026#34; | grep -w PORT_NUM | awk \u0026#39;{print $3}\u0026#39;) DBWatcherPort=$(cat \u0026#34;${DBInstanceNameProfilePath}${DmMalIniName}\u0026#34; | grep -w MAL_DW_PORT | awk \u0026#39;{print $3}\u0026#39;) # echo \u0026#34;数据库实例端口：${DBServicePort}\u0026#34; # echo \u0026#34;守护端口：${DBWatcherPort}\u0026#34; echo \u0026#34;# 服务巡检\u0026#34; getDatabaseService \u0026#34;${service}\u0026#34; \u0026#34;${DBServicePort}\u0026#34; getDatabaseWatcher \u0026#34;${service}\u0026#34; \u0026#34;${DBWatcherPort}\u0026#34; getDatabaseMonitor \u0026#34;${service}\u0026#34; echo \u0026#34;# 实例巡检\u0026#34; getMaxSession \u0026#34;${DBServicePort}\u0026#34; getDmServiceLog \u0026#34;${service}\u0026#34; getDmWatcherLog \u0026#34;${service}\u0026#34; getDmMonitorLog done } \u0026gt;\u0026gt; \u0026#34;${report_file}\u0026#34; echo \u0026#34;脚本结束 $(date +%Y-%m-%d_%H:%M:%S)\u0026#34; 效果\r1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 [root@YD-FXQDB01-3-161 202409]# cat system_check_20240913_090114.log ============================== 系统巡检 ============================== 当前系统时间: 2024年 09月 13日 星期五 09:01:14 CST 当前机器：Linux | YD-FXQDB01-3-161 | 1XX.XXX.XXX.161 CPU使用率: 0.2% 内存总量：254Gi; 内存使用：49Gi; 内存使用率: 19.2913% 磁盘空间使用情况： 文件系统 容量 已用 可用 已用% 挂载点 /dev/mapper/klas-root 860G 127G 733G 15% / /dev/sda2 1014M 194M 821M 20% /boot /dev/sda1 511M 6.5M 505M 2% /boot/efi /dev/loop0 1.1G 1.1G 0 100% /mnt/dmrom 磁盘IO情况: Linux 4.19.90-24.4.v2101.ky10.aarch64 (YD-FXQDB01-3-161) 2024年09月13日 _aarch64_ (64 CPU) avg-cpu: %user %nice %system %iowait %steal %idle 0.05 0.00 0.02 0.00 0.00 99.93 Device tps kB_read/s kB_wrtn/s kB_dscd/s kB_read kB_wrtn kB_dscd dm-0 8.32 0.11 501.58 0.00 868852 3975183572 0 loop0 0.00 0.21 0.00 0.00 1686907 0 0 sda 8.12 0.11 501.58 0.00 892701 3975186249 0 磁盘 IO 0% 正常 当前 CPU 99.93% 资源充足 ============================== 数据库巡检 ============================== 当前实例名 AMOP: # 服务巡检 [OK] 当前用户、进程 PID : dmdba 2750927, 端口：5237 | dm 正常 [WARNING] 没有找到达梦数据守护进程 [WARNING] 没有找到达梦监视器进程 # 实例巡检 当前会话数量：128, 达梦最大会话数量：10000, 活动会话占比：128/10000 [OK] 2024-09-13 数据库实例日志 dm_server 无 Error or Fatal. 扫描日志文件: /home/dmdba/dmdbms/log/dm_AMOP_202409.log [OK] 2024-09-13 数据守护进程日志 dm_watcher 无 Error or Fatal. 扫描日志文件: /home/dmdba/dmdbms/log/dm_dmwatcher_AMOP_202409.log [WARNING] 集群节点服务状态: 非 OPEN 状态 当前实例名 zgfxq: # 服务巡检 [OK] 当前用户、进程 PID : dmdba 2834456, 端口：5236 | dm 正常 [OK] 当前用户、进程 PID : dmdba 2616858 | dmwatcher 正常 [OK] 当前用户、进程 PID : dmdba 2617379 | dmmonitor 正常 # 实例巡检 当前会话数量：110, 达梦最大会话数量：5000, 活动会话占比：110/5000 [OK] 2024-09-13 数据库实例日志 dm_server 无 Error or Fatal. 扫描日志文件: /home/dmdba/dmdbms/log/dm_zgfxq_202409.log [OK] 2024-09-13 数据守护进程日志 dm_watcher 无 Error or Fatal. 扫描日志文件: /home/dmdba/dmdbms/log/dm_dmwatcher_zgfxq_202409.log [OK] 集群节点服务状态为 OPEN ","date":"2024-07-23T10:02:49+08:00","permalink":"http://localhost:1313/posts/2024/07/shell-%E7%9B%91%E6%8E%A7%E8%BE%BE%E6%A2%A6%E6%95%B0%E6%8D%AE%E5%BA%93%E6%9C%8D%E5%8A%A1%E6%97%A5%E5%BF%97%E7%9B%91%E6%8E%A7%E7%8A%B6%E6%80%81/","title":"Shell 监控达梦数据库服务、日志健康状态"},{"content":"​\n挂载 windows 共享目录\r在 windows 服务器里选择需要共享的文件夹，右键 - 属性 - 共享（需开启网络共享）\n在 Linux 服务器进行挂载操作：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 # 创建一个挂载目录 mkdir /home/aml # 挂载 - 方式一 mount -t cifs -o username=@user, password=@password //IP/share_dir /home/aml # 挂载 - 方式二 mount -t cifs -v -o credentials=/var/pwd //IP/d/data/output /home/aml/ Password for gmjjb,password=sxzq@123@//10.xxx.xxx.65/d/data/output: ******** # 验证 df -h # 自动挂载 vi /etc/fstab # 加入以下内容 //IP/share_dir /home/aml cifs username=@user, password=@password 0 0 # 或者 //IP/share_dir /home/aml cifs credentials=/var/pwd 0 0 # 然后给目录读取的权限 # chown -R aml:aml /home/aml chmod -R 444 /home/aml 一般发行版Linux都默认装了 cifs 或者 samba ，可以这么查：\n1 2 3 4 5 [root@FXQ-YWYY-57-81 ~]# rpm -qa | grep samba samba-common-4.11.12-3.p01.ky10.aarch64 samba-client-4.11.12-3.p01.ky10.aarch64 [root@FXQ-YWYY-57-81 ~]# rpm -qa | grep cifs cifs-utils-6.10-0.ky10.aarch64 卸载共享目录\numount /home/aml\n挂载 NFS 文件系统\r1 2 3 4 5 6 7 8 9 10 11 # 创建一个共享目录 mkdir /mnt/nfs # 挂载 mount -t nfs ip:/path/to/share /mnt/nfs # 验证 df -h # 自动挂载 ip:/path/to/share /mnt/nfs nfs defaults 0 0 # 卸载 umount /mnt/nfs 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 [root@kylinV10arm162 ~]# mount -t cifs -o username=gmjjb,password=sxzq@123,vers=2.0 //10.xxx.xxx.65/d/data/output /home/aml/99 mount error(115): Operation now in progress Refer to the mount.cifs(8) manual page (e.g. man mount.cifs) and kernel log messages (dmesg) [root@kylinV10arm162 ~]# dmesg | grep mount [ 3.424827] XFS (dm-0): Ending clean mount [ 5.906981] audit: type=1130 audit(1717645025.410:51): pid=1 uid=0 auid=4294967295 ses=4294967295 msg=\u0026#39;unit=systemd-remount-fs comm=\u0026#34;systemd\u0026#34; exe=\u0026#34;/usr/lib/systemd/systemd\u0026#34; hostname=? addr=? terminal=? res=success\u0026#39; [ 6.702559] XFS (vda2): Ending clean mount [2777460.243716] No dialect specified on mount. Default has changed to a more secure dialect, SMB2.1 or later (e.g. SMB3), from CIFS (SMB1). To use the less secure SMB1 dialect to access old servers which do not support SMB3 (or SMB2.1) specify vers=1.0 on mount. [2778936.002401] No dialect specified on mount. Default has changed to a more secure dialect, SMB2.1 or later (e.g. SMB3), from CIFS (SMB1). To use the less secure SMB1 dialect to access old servers which do not support SMB3 (or SMB2.1) specify vers=1.0 on mount. Invalid argument sudo mount -t cifs -v -o \u0026#39;username=gmjjb,password=sxzq@123,vers=2.0\u0026#39; //10.xxx.xxx.65/d/data/output /home/aml/99/ mount.cifs kernel mount options: ip=10.xxx.xxx.65,unc=\\\\10.xxx.xxx.65\\d,vers=2.0,user=gmjjb,prefixpath=data/output,pass=******** mount error(115): Operation now in progress Refer to the mount.cifs(8) manual page (e.g. man mount.cifs) and kernel log messages (dmesg) # 查看内核日志 [root@kylinV10arm162 ~]# sudo mount -t cifs -v -o \u0026#39;username=gmjjb,password=sxzq@123,vers=1.0\u0026#39; //10.xxx.xxx.65/d/data/output /home/aml/99/ mount.cifs kernel mount options: ip=10.xxx.xxx.65,unc=\\\\10.xxx.xxx.65\\d,vers=1.0,user=gmjjb,prefixpath=data/output,pass=******** mount error(115): Operation now in progress Refer to the mount.cifs(8) manual page (e.g. man mount.cifs) and kernel log messages (dmesg) [root@kylinV10arm162 ~]# dmesg | grep mount [ 3.424827] XFS (dm-0): Ending clean mount [ 5.906981] audit: type=1130 audit(1717645025.410:51): pid=1 uid=0 auid=4294967295 ses=4294967295 msg=\u0026#39;unit=systemd-remount-fs comm=\u0026#34;systemd\u0026#34; exe=\u0026#34;/usr/lib/systemd/systemd\u0026#34; hostname=? addr=? terminal=? res=success\u0026#39; [ 6.702559] XFS (vda2): Ending clean mount [2777460.243716] No dialect specified on mount. Default has changed to a more secure dialect, SMB2.1 or later (e.g. SMB3), from CIFS (SMB1). To use the less secure SMB1 dialect to access old servers which do not support SMB3 (or SMB2.1) specify vers=1.0 on mount. [2778936.002401] No dialect specified on mount. Default has changed to a more secure dialect, SMB2.1 or later (e.g. SMB3), from CIFS (SMB1). To use the less secure SMB1 dialect to access old servers which do not support SMB3 (or SMB2.1) specify vers=1.0 on mount. [2781999.432132] CIFS: Unknown mount option \u0026#34;passowrd=sxzq@123\u0026#34; [root@kylinV10arm162 ~]# # [root@kylinV10arm162 ~]# mount -t cifs -v -o credentials=/var/pwd.txt //10.xxx.xxx.65/d/data/output /home/aml/99/ Password for gmjjb,password=sxzq@123@//10.xxx.xxx.65/d/data/output: ******** mount.cifs kernel mount options: ip=10.xxx.xxx.65,unc=\\\\10.xxx.xxx.65\\d,user=gmjjb,password=sxzq@123,prefixpath=data/output,pass=******** mount error(115): Operation now in progress Refer to the mount.cifs(8) manual page (e.g. man mount.cifs) and kernel log messages (dmesg) [root@kylinV10arm162 ~]# dmesg | grep mount [ 3.424827] XFS (dm-0): Ending clean mount [ 5.906981] audit: type=1130 audit(1717645025.410:51): pid=1 uid=0 auid=4294967295 ses=4294967295 msg=\u0026#39;unit=systemd-remount-fs comm=\u0026#34;systemd\u0026#34; exe=\u0026#34;/usr/lib/systemd/systemd\u0026#34; hostname=? addr=? terminal=? res=success\u0026#39; [ 6.702559] XFS (vda2): Ending clean mount [2777460.243716] No dialect specified on mount. Default has changed to a more secure dialect, SMB2.1 or later (e.g. SMB3), from CIFS (SMB1). To use the less secure SMB1 dialect to access old servers which do not support SMB3 (or SMB2.1) specify vers=1.0 on mount. [2778936.002401] No dialect specified on mount. Default has changed to a more secure dialect, SMB2.1 or later (e.g. SMB3), from CIFS (SMB1). To use the less secure SMB1 dialect to access old servers which do not support SMB3 (or SMB2.1) specify vers=1.0 on mount. [2781999.432132] CIFS: Unknown mount option \u0026#34;passowrd=sxzq@123\u0026#34; [2783009.282175] No dialect specified on mount. Default has changed to a more secure dialect, SMB2.1 or later (e.g. SMB3), from CIFS (SMB1). To use the less secure SMB1 dialect to access old servers which do not support SMB3 (or SMB2.1) specify vers=1.0 on mount. [2783282.433585] No dialect specified on mount. Default has changed to a more secure dialect, SMB2.1 or later (e.g. SMB3), from CIFS (SMB1). To use the less secure SMB1 dialect to access old servers which do not support SMB3 (or SMB2.1) specify vers=1.0 on mount. [2783470.189648] No dialect specified on mount. Default has changed to a more secure dialect, SMB2.1 or later (e.g. SMB3), from CIFS (SMB1). To use the less secure SMB1 dialect to access old servers which do not support SMB3 (or SMB2.1) specify vers=1.0 on mount. [root@kylinV10arm162 ~]# # [root@kylinV10arm162 ~]# vi /etc/samba/smb.conf # global 加入 client min protocol = CORE client max protocol = SMB3 [root@kylinV10arm162 ~]# smbclient -L //10.xxx.xxx.65/ do_connect: Connection to 10.xxx.xxx.65 failed (Error NT_STATUS_IO_TIMEOUT) [root@kylinV10arm162 ~]# ping 10.xxx.xxx.65 PING 10.xxx.xxx.65 (10.xxx.xxx.65) 56(84) bytes of data. 64 bytes from 10.xxx.xxx.65: icmp_seq=1 ttl=125 time=1.77 ms 64 bytes from 10.xxx.xxx.65: icmp_seq=2 ttl=125 time=1.11 ms 64 bytes from 10.xxx.xxx.65: icmp_seq=3 ttl=125 time=0.870 ms 64 bytes from 10.xxx.xxx.65: icmp_seq=4 ttl=125 time=0.906 ms 64 bytes from 10.xxx.xxx.65: icmp_seq=5 ttl=125 time=0.897 ms ^C --- 10.xxx.xxx.65 ping statistics --- 5 packets transmitted, 5 received, 0% packet loss, time 4111ms rtt min/avg/max/mdev = 0.870/1.109/1.765/0.338 ms [root@kylinV10arm162 ~]# 生产实践-挂载 windows 共享目录\r因为密码中含有特殊字符 @ ，所以建立了一个存放 Windows 共享目录的用户密码的文件，在命令中使用：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 [root@kylinV10arm162 mnt]# cat /var/pwd user=gmjjb pass=sxzq@123 vers=1.0 [root@kylinV10arm162 mnt]# mount -t cifs -v -o credentials=/var/pwd //10.xxx.xxx.195/d/data/output /mnt/B9/ Credential formatted incorrectly: 1.0 mount.cifs kernel mount options: ip=10.xxx.xxx.195,unc=\\\\10.xxx.xxx.195\\d,user=gmjjb,prefixpath=data/output,pass=******** [root@kylinV10arm162 mnt]# df -h Filesystem Size Used Avail Use% Mounted on devtmpfs 32G 0 32G 0% /dev tmpfs 32G 192K 32G 1% /dev/shm tmpfs 32G 1.5G 30G 5% /run tmpfs 32G 0 32G 0% /sys/fs/cgroup /dev/mapper/klas-root 483G 38G 446G 8% / tmpfs 32G 2.1M 32G 1% /tmp /dev/vda2 1014M 222M 793M 22% /boot /dev/vda1 599M 6.5M 593M 2% /boot/efi tmpfs 6.3G 0 6.3G 0% /run/user/993 tmpfs 6.3G 0 6.3G 0% /run/user/0 //10.xxx.xxx.195/d/data/output 500G 392G 109G 79% /mnt/B9\t# 已经挂载好了 然后到 /mnt/B9 目录下查看就行了\n卸载共享目录\n1 umount /home/aml 强制取消挂载时出现 Busy 问题\r我使用 umount -f /home/aml/B9 后，B9目录就变成了这样：\n1 2 3 4 5 6 7 8 d????????? ? ? ? ? ? B9 [root@kylinV10arm162 aml]# ll ls: cannot access \u0026#39;B9\u0026#39;: No such device total 8 drwxr-xr-x 2 root root 4096 Jul 12 10:10 3K drwxr-xr-x 2 root root 4096 Jul 12 10:12 99 d????????? ? ? ? ? ? B9 对这块盘进行重新取消挂载即可\n1 [root@kylinV10arm162 aml]# umount -l B9 报错 Operation now in progress\r1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 [root@kylinV10arm162 ~]# mount -t cifs -o username=gmjjb,password=sxzq@123,vers=1.0 //10.xxx.xxx.65/d/data/output /home/aml/99 mount error(115): Operation now in progress Refer to the mount.cifs(8) manual page (e.g. man mount.cifs) and kernel log messages (dmesg) [root@kylinV10arm162 ~]# dmesg | grep mount [ 3.424827] XFS (dm-0): Ending clean mount [ 5.906981] audit: type=1130 audit(1717645025.410:51): pid=1 uid=0 auid=4294967295 ses=4294967295 msg=\u0026#39;unit=systemd-remount-fs comm=\u0026#34;systemd\u0026#34; exe=\u0026#34;/usr/lib/systemd/systemd\u0026#34; hostname=? addr=? terminal=? res=success\u0026#39; [ 6.702559] XFS (vda2): Ending clean mount [2777460.243716] No dialect specified on mount. Default has changed to a more secure dialect, SMB2.1 or later (e.g. SMB3), from CIFS (SMB1). To use the less secure SMB1 dialect to access old servers which do not support SMB3 (or SMB2.1) specify vers=1.0 on mount. [2778936.002401] No dialect specified on mount. Default has changed to a more secure dialect, SMB2.1 or later (e.g. SMB3), from CIFS (SMB1). To use the less secure SMB1 dialect to access old servers which do not support SMB3 (or SMB2.1) specify vers=1.0 on mount. # 使用文件的形式也是报错 vi /var/pwd # 加入 user=\u0026lt;username\u0026gt; pass=\u0026lt;password\u0026gt; vers=1.0 chown root:root /var/pwd chmod 600 /etc/pwd [root@kylinV10arm162 ~]# mount -t cifs -v -o credentials=/var/pwd //10.xxx.xxx.65/d/data/output /home/aml/99/ Password for gmjjb,password=sxzq@123@//10.xxx.xxx.65/d/data/output: ******** mount error(115): Operation now in progress Refer to the mount.cifs(8) manual page (e.g. man mount.cifs) and kernel log messages (dmesg) ping ip能通，但telnet ip 445也不通，故该服务器访问Windows服务器的共享目录端口是不通的，需要在防火墙上开启端口，需要负责管理网络这块的去开通。\n挂载另一台报错排查及解决\rPermission denied\r1 2 3 4 [root@kylinV10arm162 ~]# mount -t cifs -v -o \u0026#39;username=gmjjb,password=sxzq@123,sec=ntlmssp,vers=1.0\u0026#39; //10.xxx.xxx.65/d/data/output /mnt/99/ mount.cifs kernel mount options: ip=10.xxx.xxx.65,unc=\\\\10.xxx.xxx.65\\d,sec=ntlmssp,vers=1.0,user=gmjjb,prefixpath=data/output,pass=******** mount error(13): Permission denied Refer to the mount.cifs(8) manual page (e.g. man mount.cifs) and kernel log messages (dmesg) 端口 445 是通的 共享路径确认过是正确的 d/data/output 用户密码，以及这个用户能否访问到？用户错了 No such file or directory\r是因为找不到共享的磁盘\n确认共享目录是什么盘，这里共享的是 d$/data/output 不是 d/data/output 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 [root@kylinV10arm162 ~]# cat /var/pwd_65 username=zgyyb password=sxzq@123 vers=1.0 [root@kylinV10arm162 ~]# mount -t cifs -v -o credentials=/var/pwd_65 //10.xxx.xxx.65/d/data/output /mnt/99/ Credential formatted incorrectly: 1.0 mount.cifs kernel mount options: ip=10.xxx.xxx.65,unc=\\\\10.xxx.xxx.65\\d,user=zgyyb,prefixpath=data/output,pass=******** mount error(2): No such file or directory Refer to the mount.cifs(8) manual page (e.g. man mount.cifs) and kernel log messages (dmesg) # 查看共享目录的盘 注意这里的盘是 d$ 不是 d [root@kylinV10arm162 ~]# smbclient -L //10.xxx.xxx.65/ -U zgyyb Enter SAMBA\\zgyyb\\\u0026#39;s password: Sharename Type Comment --------- ---- ------- ADMIN$ Disk 远程管理 C$ Disk 默认共享 D$ Disk 默认共享 E盘 Disk I$ Disk 默认共享 IPC$ IPC 远程 IPC Reconnecting with SMB1 for workgroup listing. do_connect: Connection to 10.xxx.xxx.65 failed (Error NT_STATUS_IO_TIMEOUT) Unable to connect with SMB1 -- no workgroup available # 把路径换成 d$ 就可以了 [root@kylinV10arm162 ~]# mount -t cifs -v -o credentials=/var/pwd_65 //10.xxx.xxx.65/d$/data/output /mnt/99/ Credential formatted incorrectly: 1.0 mount.cifs kernel mount options: ip=10.xxx.xxx.65,unc=\\\\10.xxx.xxx.65\\d$,user=zgyyb,prefixpath=data/output,pass=******** [root@kylinV10arm162 ~]# df -h Filesystem Size Used Avail Use% Mounted on devtmpfs 32G 0 32G 0% /dev tmpfs 32G 192K 32G 1% /dev/shm tmpfs 32G 1.8G 30G 6% /run tmpfs 32G 0 32G 0% /sys/fs/cgroup /dev/mapper/klas-root 483G 38G 446G 8% / tmpfs 32G 2.2M 32G 1% /tmp /dev/vda2 1014M 222M 793M 22% /boot /dev/vda1 599M 6.5M 593M 2% /boot/efi tmpfs 6.3G 0 6.3G 0% /run/user/993 tmpfs 6.3G 0 6.3G 0% /run/user/0 //10.xxx.xxx.195/d/data/output 500G 395G 106G 79% /mnt/B9 //10.xxx.xxx.65/d$/data/output 200G 169G 32G 85% /mnt/99 [root@kylinV10arm162 ~]# 总结\r99 挂载\n1 mount -t cifs -v -o credentials=/var/pwd_65 //10.xxx.xxx.65/d$/data/output /mnt/99/ B9 挂载\n1 mount -t cifs -v -o credentials=/var/pwd //10.xxx.xxx.195/d/data/output /mnt/B9/ 取消挂载\n1 2 umount /mnt/99 umount /mnt/B9 ","date":"2024-07-21T22:25:30+08:00","permalink":"http://localhost:1313/posts/2024/07/linux-%E6%8C%82%E8%BD%BD%E5%85%B1%E4%BA%AB%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/linux-%E6%8C%82%E8%BD%BD%E5%85%B1%E4%BA%AB%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/","title":"Linux-挂载共享文件系统"},{"content":"因为之前实施部署达梦数据库，通常是只部署开发环境、测试环境，生成环境的数据库并没有实践在项目中实践过，受限于工作项目，开发、测试环境通常只有一台数据库服务器，部署的单机版。\n对于集群版本一直没有机会实践，最近使用虚拟机搭建了达梦实时主备集群，并进行实时主备数据同步、切换主备库的验证。特此做总结，包括：集群搭建、监视器、服务名、实时同步数据验证、手动主备切换与验证。\n安装前准备说明\r1.需要 linux 里有 tar 命令包，执行下边命令验证\n1 tar --version 2.需要先将服务器同步时间，一般同步 ntp 服务器，也可以手动修改\n1 2 date -s \u0026#34;yyyy-mm-dd HH:MM:SS\u0026#34; date -s 3.关闭防火墙并禁止自启\n1 2 systemctl stop firewalld systemctl disable firewalld 4.确保主备服务器网络互通，避免同步数据失效，需要互相传 Redo 日志的\n5.达梦数据库官方是建议关闭 SWAP 分区的，内存充足也可不关\n6.调整 limit.sconf 参数\n集群规划\r需要注意的是，确认端口不会与其他服务进程冲突\n部署信息\rA机器 B机器 IP 192.168.163.9 192.168.163.10 实例名 GRP_TEST_01 GRP_TEST_02 实例端口 5236 5236 守护进程端口 5536 5536 MAL端口 5336 5336 守护组 GRP1 GPR1 安装目录 /home/dmdba/dmdbms /home/dmdba/dmdbms 实例目录 /home/dmdba/data /home/dmdba/data 归档上限 10240（生产一般不设上限，由DBA规划） 10240 切换模式\r需要考虑 ALTER_MODE_STATUS 参数是多少：0-不可修改，1-可修改\n集群搭建\r安装数据库\r步骤可参照 实施部署-达梦数据库linux版的安装（二） | WeiQi Blog (weiqifun.github.io)\n按照下边也可以，总之步骤需要到初始化实例\n搭建集群时，每台都需要初始化实例（即 192.168.163.9 和 192.168.163.10 都需要）\n注意：在使用 ./dminit 初始化实例时，请注意修改实例名：\n192.168.163.9 \u0026gt; GRP_TEST_01\n192.168.163.10 \u0026gt; GRP_TEST_02\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 [root@linux1 soft]# groupadd dinstall [root@linux1 soft]# useradd -g dinstall -m -d /home/dmdba -s /bin/bash dmdba [root@linux1 soft]# passwd dmdba 更改用户 dmdba 的密码 。 新的 密码：!@#$qwer 重新输入新的 密码：!@#$qwer passwd：所有的身份验证令牌已经成功更新。 [root@linux1 soft]# vi /etc/security/limits.conf # 在conf文件内容的最后添加 dmdba hard nofile 65536 dmdba soft nofile 65536 dmdba hard stack 32768 dmdba soft stack 16384 # :wq 保存 [root@linux1 soft]# su - dmdba [dmdba@linux1 ~]$ ulimit -a core file size (blocks, -c) 0 data seg size (kbytes, -d) unlimited scheduling priority (-e) 0 file size (blocks, -f) unlimited pending signals (-i) 14989 max locked memory (kbytes, -l) 64 max memory size (kbytes, -m) unlimited open files (-n) 65536 pipe size (512 bytes, -p) 8 POSIX message queues (bytes, -q) 819200 real-time priority (-r) 0 stack size (kbytes, -s) 16384 cpu time (seconds, -t) unlimited max user processes (-u) 4096 virtual memory (kbytes, -v) unlimited file locks (-x) unlimited [root@linux1 soft]# chmod 755 dm8_20240408_x86_rh7_64.iso [root@linux1 soft]# mount -o loop dm8_20240408_x86_rh7_64.iso /mnt/ mount: /dev/loop0 写保护，将以只读方式挂载 [root@linux1 soft]# su - dmdba 上一次登录：六 7月 20 23:55:52 CST 2024pts/0 上 [dmdba@linux1 ~]$ cd /mnt/ [dmdba@linux1 mnt]$ ll 总用量 1057031 -r-xr-xr-x. 1 root root 2587699 3月 20 14:04 DM8 Install.pdf -r-xr-xr-x. 1 root root 1079810877 4月 8 13:35 DMInstall.bin [dmdba@linux1 mnt]$ ./DMInstall.bin -i 安装语言: [1]: 简体中文 [2]: English 请选择安装语言 [1]:1 解压安装程序......... 欢迎使用达梦数据库安装程序 是否输入Key文件路径? (Y/y:是 N/n:否) [Y/y]:n 是否设置时区? (Y/y:是 N/n:否) [Y/y]:y 设置时区: [ 1]: (GTM-12:00) 日界线西 [ 2]: (GTM-11:00) 萨摩亚群岛 [ 3]: (GTM-10:00) 夏威夷 [ 4]: (GTM-09:00) 阿拉斯加 [ 5]: (GTM-08:00) 太平洋时间（美国和加拿大） [ 6]: (GTM-07:00) 亚利桑那 [ 7]: (GTM-06:00) 中部时间（美国和加拿大） [ 8]: (GTM-05:00) 东部部时间（美国和加拿大） [ 9]: (GTM-04:00) 大西洋时间（美国和加拿大） [10]: (GTM-03:00) 巴西利亚 [11]: (GTM-02:00) 中大西洋 [12]: (GTM-01:00) 亚速尔群岛 [13]: (GTM) 格林威治标准时间 [14]: (GTM+01:00) 萨拉热窝 [15]: (GTM+02:00) 开罗 [16]: (GTM+03:00) 莫斯科 [17]: (GTM+04:00) 阿布扎比 [18]: (GTM+05:00) 伊斯兰堡 [19]: (GTM+06:00) 达卡 [20]: (GTM+07:00) 曼谷，河内 [21]: (GTM+08:00) 中国标准时间 [22]: (GTM+09:00) 首尔 [23]: (GTM+10:00) 关岛 [24]: (GTM+11:00) 所罗门群岛 [25]: (GTM+12:00) 斐济 [26]: (GTM+13:00) 努库阿勒法 [27]: (GTM+14:00) 基里巴斯 请选择时区 [21]:21 安装类型: 1 典型安装 2 服务器 3 客户端 4 自定义 请选择安装类型的数字序号 [1 典型安装]:1 所需空间: 2310M 请选择安装目录 [/home/dmdba/dmdbms]: 可用空间: 29G 是否确认安装路径(/home/dmdba/dmdbms)? (Y/y:是 N/n:否) [Y/y]: 安装前小结 安装位置: /home/dmdba/dmdbms 所需空间: 2310M 可用空间: 29G 版本信息: 有效日期: 安装类型: 典型安装 是否确认安装? (Y/y:是 N/n:否):y 2024-07-21 00:02:02 [INFO] 安装达梦数据库... 2024-07-21 00:02:02 [INFO] 安装 基础 模块... 2024-07-21 00:02:13 [INFO] 安装 服务器 模块... 2024-07-21 00:02:17 [INFO] 安装 客户端 模块... 2024-07-21 00:02:23 [INFO] 安装 驱动 模块... 2024-07-21 00:02:27 [INFO] 安装 手册 模块... 2024-07-21 00:02:28 [INFO] 安装 服务 模块... 2024-07-21 00:02:28 [INFO] 移动日志文件。 2024-07-21 00:02:29 [INFO] 安装达梦数据库完成。 请以root系统用户执行命令: /home/dmdba/dmdbms/script/root/root_installer.sh 安装结束 [dmdba@linux1 mnt]$ su - root 密码： 上一次登录：六 7月 20 23:57:11 CST 2024pts/0 上 [root@linux1 ~]# /home/dmdba/dmdbms/script/root/root_installer.sh 移动 /home/dmdba/dmdbms/bin/dm_svc.conf 到/etc目录 创建DmAPService服务 Created symlink from /etc/systemd/system/multi-user.target.wants/DmAPService.service to /usr/lib/systemd/system/DmAPService.service. 创建服务(DmAPService)完成 启动DmAPService服务 [root@linux1 ~]# su - dmdba 上一次登录：日 7月 21 00:00:02 CST 2024pts/0 上 [dmdba@linux1 ~]$ cd /home/dmdba/dmdbms/bin ########################################################## # ./dminit 这个步骤要注意，实例名要有区分 # # ./dminit 参数详见 https://eco.dameng.com/document/dm/zh-cn/pm/dminit-parameters.html # 如果需要将数据文件放到其他地方，则 path 参数应为具体的路径 # 例如：path=/home/dmdba/data （提前建好） # 如果数据库名自定义，则 DM_NAME 参数应为自定义名称 # 例如：DB_NAME=TEST_DB # 这样创建好的数据文件路径，则为：/home/dmdba/data/TEST_DB ########################################################## [dmdba@linux1 bin]# ./dminit path=/home/dmdba/dmdbms PAGE_SIZE=32 EXTENT_SIZE=32 CASE_SENSITIVE=y CHARSET=0 DB_NAME=DMDB INSTANCE_NAME=GRP_TEST_01 PORT_NUM=5236 initdb V8 db version: 0x7000c file dm.key not found, use default license! License will expire on 2025-03-21 Normal of FAST Normal of DEFAULT Normal of RECYCLE Normal of KEEP Normal of ROLL log file path: /home/dmdba/dmdbms/DMDB/DMDB01.log log file path: /home/dmdba/dmdbms/DMDB/DMDB02.log write to dir [/home/dmdba/dmdbms/DMDB]. create dm database success. 2024-07-21 00:06:03 到这里，初始化实例完成！\n配置 A 机器\r把 192.168.163.9 作为主库，即所谓的 A 机器\n以下步骤非必要说明，均使用数据库用户 dmdba 操作\n先把 A 机器的数据库服务启动\n1）启动实例服务\r1 2 3 # 前台启动服务 [dmdba@linux1 ~]$ cd /home/dmdba/dmdbms/bin [dmdba@linux1 bin]$ ./dmserver /home/dmdba/dmdbms/DMDB/dm.ini 因为还没有在 ../script/root 执行创建服务的命令，所以现在是没有后台启动服务的命令的\n2）开启归档\rSPACE_LIMIT 是归档空间的最大限制，空间不足时，会将之前旧的归档文件删掉\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 [dmdba@linux1 bin]$ ./disql SYSDBA/SYSDBA 服务器[LOCALHOST:5236]:处于普通打开状态 登录使用时间 : 17.680(ms) disql V8 SQL\u0026gt; ALTER DATABASE MOUNT; 操作已执行 已用时间: 3.546(毫秒). 执行号:0. SQL\u0026gt; ALTER DATABASE ARCHIVELOG; 操作已执行 已用时间: 17.101(毫秒). 执行号:0. SQL\u0026gt; ALTER DATABASE ADD ARCHIVELOG \u0026#39;DEST=/home/dmdba/dmdbms/DMDB/arch, TYPE=LOCAL, FILE_SIZE=1024, SPACE_LIMIT=10240\u0026#39;; 操作已执行 已用时间: 4.701(毫秒). 执行号:0. SQL\u0026gt; ALTER DATABASE OPEN; 操作已执行 已用时间: 16.531(毫秒). 执行号:0. 3）备份数据\r1 2 3 SQL\u0026gt; BACKUP DATABASE BACKUPSET \u0026#39;/home/dmdba/dmdbms/DMDB/bak/BACKUP_FILE\u0026#39;; 操作已执行 已用时间: 00:00:08.767. 执行号:501. 4）修改 dm.ini\r1 2 3 4 5 6 SQL\u0026gt; SP_SET_PARA_VALUE (2,\u0026#39;PORT_NUM\u0026#39;,5236); #数据库实例监听端口 SQL\u0026gt; SP_SET_PARA_VALUE (2,\u0026#39;DW_INACTIVE_INTERVAL\u0026#39;,60); #接收守护进程消息超时时间 SQL\u0026gt; SP_SET_PARA_VALUE (2,\u0026#39;ALTER_MODE_STATUS\u0026#39;,0); #不允许手工方式修改实例模式/状态/OGUID SQL\u0026gt; SP_SET_PARA_VALUE (2,\u0026#39;ENABLE_OFFLINE_TS\u0026#39;,2); #不允许备库 OFFLINE 表空间 SQL\u0026gt; SP_SET_PARA_VALUE (2,\u0026#39;MAL_INI\u0026#39;,1); #打开 MAL 系统 SQL\u0026gt; SP_SET_PARA_VALUE (2,\u0026#39;RLOG_SEND_APPLY_MON\u0026#39;,64); #统计最近 64 次的日志重演信息 5）退出并关闭数据库服务\r1 2 3 SQL\u0026gt; exit; # 到开启服务的linux窗口，终止前台服务 6）修改 dmarch.ini\r1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 [dmdba@linux1~]$ vi /home/dmdba/dmdbms/DMDB/dmarch.ini ARCH_WAIT_APPLY = 0 #0：高性能 1：事务一致 [ARCHIVE_LOCAL] ARCH_TYPE = LOCAL #本地归档类型 ARCH_DEST = /home/dmdba/dmdbms/DMDB/arch/ #本地归档存放路径 ARCH_FILE_SIZE = 1024 #单个归档大小，单位 MB ARCH_SPACE_LIMIT = 10240 #归档上限，单位 MB ARCH_FLUSH_BUF_SIZE = 0 ARCH_HANG_FLAG = 1 [ARCHIVE_REALTIME1] ARCH_TYPE = REALTIME #实时归档类型 ARCH_DEST = GRP_TEST_02 #实时归档目标实例名(备库实例名) 7）创建 dmmal.ini\r在 dm.ini 相同目录下，创建 dmmal.ini\n是两个机器传 Redo 日志、响应消息的配置文件\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 vi /home/dmdba/dmdbms/DMDB/dmmal.ini MAL_CHECK_INTERVAL = 10 #MAL 链路检测时间间隔 MAL_CONN_FAIL_INTERVAL = 10 #判定 MAL 链路断开的时间 MAL_TEMP_PATH = /home/dmdba/dmdbms/DMDB/malpath/ #临时文件目录 MAL_BUF_SIZE = 512 #单个 MAL 缓存大小，单位 MB MAL_SYS_BUF_SIZE = 2048 #MAL 总大小限制，单位 MB MAL_COMPRESS_LEVEL = 0 #MAL 消息压缩等级，0 表示不压缩 [MAL_INST1] MAL_INST_NAME = GRP_TEST_01 #实例名，和 dm.ini 的 INSTANCE_NAME 一致 MAL_HOST = 192.168.163.9 #MAL 系统监听 TCP 连接的 IP 地址 MAL_PORT = 5336 #MAL 系统监听 TCP 连接的端口 MAL_INST_HOST = 192.168.163.9 #实例的对外服务 IP 地址 MAL_INST_PORT = 5236 #实例对外服务端口，和 dm.ini 的 PORT_NUM 一致 MAL_DW_PORT = 5436 #实例对应的守护进程监听 TCP 连接的端口 MAL_INST_DW_PORT = 5536 #实例监听守护进程 TCP 连接的端口 [MAL_INST2] MAL_INST_NAME = GRP_TEST_02 MAL_HOST = 192.168.163.10 MAL_PORT = 5336 MAL_INST_HOST = 192.168.163.10 MAL_INST_PORT = 5236 MAL_DW_PORT = 5436 MAL_INST_DW_PORT = 5536 8）创建 dmwatcher.ini\r在 dm.ini 相同目录下，创建 dmwatcher.ini\n1 2 3 4 5 6 7 8 9 10 11 12 [GRP1] DW_TYPE = GLOBAL #全局守护类型 DW_MODE = AUTO #MANUAL：故障手切 AUTO：故障自切 DW_ERROR_TIME = 20 #远程守护进程故障认定时间 INST_ERROR_TIME = 20 #本地实例故障认定时间 INST_RECOVER_TIME = 60 #主库守护进程启动恢复的间隔时间 INST_OGUID = 45331 #守护系统唯一 OGUID 值 INST_INI = /home/dmdba/dmdbms/DMDB/dm.ini #dm.ini 文件路径 INST_AUTO_RESTART = 1 #打开实例的自动启动功能 INST_STARTUP_CMD = /home/dmdba/dmdbms/bin/dmserver #命令行方式启动 RLOG_SEND_THRESHOLD = 0 #指定主库发送日志到备库的时间阈值，默认关闭 RLOG_APPLY_THRESHOLD = 0 #指定备库重演日志的时间阈值，默认关闭 9）拷贝备份文件到备库\r1 2 3 4 5 6 7 8 9 [dmdba@linux1 DMDB]$ scp -r /home/dmdba/dmdbms/DMDB/bak/BACKUP_FILE dmdba@192.168.163.10:/home/dmdba/dmdbms/DMDB/bak/ The authenticity of host \u0026#39;192.168.163.10 (192.168.163.10)\u0026#39; can\u0026#39;t be established. ECDSA key fingerprint is SHA256:xU91rJPNr+WlgJJ3xkHHHdDAo/vxPcgYj7U+VH4zLYg. ECDSA key fingerprint is MD5:1c:b2:a6:11:d1:b8:20:e7:c4:6d:a1:0b:df:2a:d0:1c. Are you sure you want to continue connecting (yes/no)? yes Warning: Permanently added \u0026#39;192.168.163.10\u0026#39; (ECDSA) to the list of known hosts. dmdba@192.168.163.10\u0026#39;s password: BACKUP_FILE.bak 100% 27MB 20.5MB/s 00:01 BACKUP_FILE.meta 10）注册服务\r使用 root 用户操作\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 [root@linux1 ~]# cd /home/dmdba/dmdbms/script/root/ [root@linux1 root]# ll 总用量 44 -rwxr-xr-x. 1 dmdba dinstall 25373 7月 21 00:02 dm_service_installer.sh -rwxr-xr-x. 1 dmdba dinstall 9214 7月 21 00:02 dm_service_uninstaller.sh -rwxr-xr-x. 1 dmdba dinstall 490 7月 21 00:02 root_installer.sh #################### # 创建数据库服务 # -p 实例名 #################### [root@linux1 root]# ./dm_service_installer.sh -t dmserver -p GRP_TEST_01 -dm_ini /home/dmdba/dmdbms/DMDB/dm.ini -m mount Created symlink from /etc/systemd/system/multi-user.target.wants/DmServiceGRP_TEST_01.service to /usr/lib/systemd/system/DmServiceGRP_TEST_01.service. 创建服务(DmServiceGRP_TEST_01)完成 #################### # 创建数据守护服务 #################### [root@linux1 root]# ./dm_service_installer.sh -t dmwatcher -p Watcher -watcher_ini /home/dmdba/dmdbms/DMDB/dmwatcher.ini Created symlink from /etc/systemd/system/multi-user.target.wants/DmWatcherServiceWatcher.service to /usr/lib/systemd/system/DmWatcherServiceWatcher.service. 创建服务(DmWatcherServiceWatcher)完成 如果需要删除服务\r1 2 [root@~]# ./dm_service_uninstaller.sh -n DmServiceGRP_TEST_01 [root@~]# ./dm_service_uninstaller.sh -n DmWatcherServiceWatcher 配置 B 机器\r192.168.163.10 为备库\n因为安装数据库的时候，已经初始化实例了\n现在需要做的就是在备库同步主库的数据，让主备保持一致的状态\n1）备库恢复数据\r执行下边两条，注意 dm.ini 的位置和备份文件的位置，备份文件是从 A 机器拷贝过来的\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 ################### # 这步是 RESTORE DATEBASE ################### [dmdba@linux2 bin]$ ./dmrman CTLSTMT=\u0026#34;RESTORE DATABASE \u0026#39;/home/dmdba/dmdbms/DMDB/dm.ini\u0026#39; FROM BACKUPSET \u0026#39;/home/dmdba/dmdbms/DMDB/bak/BACKUP_FILE\u0026#39;\u0026#34; dmrman V8 RESTORE DATABASE \u0026#39;/home/dmdba/dmdbms/DMDB/dm.ini\u0026#39; FROM BACKUPSET \u0026#39;/home/dmdba/dmdbms/DMDB/bak/BACKUP_FILE\u0026#39; file dm.key not found, use default license! Normal of FAST Normal of DEFAULT Normal of RECYCLE Normal of KEEP Normal of ROLL [Percent:100.00%][Speed:0.00M/s][Cost:00:00:03][Remaining:00:00:00] restore successfully. time used: 00:00:03.874 ################### # 这步是 RECOVER DATEBASE ################### [dmdba@linux2 bin]$ ./dmrman CTLSTMT=\u0026#34;RECOVER DATABASE \u0026#39;/home/dmdba/dmdbms/DMDB/dm.ini\u0026#39; FROM BACKUPSET \u0026#39;/home/dmdba/dmdbms/DMDB/bak/BACKUP_FILE\u0026#39;\u0026#34; ################### # 这步是 RECOVER DATEBASE UPDATE DM_MAGIC ################### [dmdba@linux2 bin]$ ./dmrman CTLSTMT=\u0026#34;RECOVER DATABASE \u0026#39;/home/dmdba/dmdbms/DMDB/dm.ini\u0026#39; UPDATE DB_MAGIC\u0026#34; dmrman V8 RECOVER DATABASE \u0026#39;/home/dmdba/dmdbms/DMDB/dm.ini\u0026#39; UPDATE DB_MAGIC file dm.key not found, use default license! Database mode = 2, oguid = 0 Normal of FAST Normal of DEFAULT Normal of RECYCLE Normal of KEEP Normal of ROLL EP[0]\u0026#39;s cur_lsn[42972], file_lsn[42972] recover successfully! time used: 00:00:01.421 2）创建 dmarch.ini\rA 机器开启了归档，B 机器是还没有开启归档的，所以没有归档配置文件 dmarch.ini 的，在 B 机器创建它\n注意 ARCH_DEST 参数，主库的 dmarch.ini 文件填备库的实例名，备库的 dmarch.ini 文件填主库的实例名\n1 2 3 4 5 6 7 8 9 10 11 12 13 ARCH_WAIT_APPLY = 0 #0：高性能 1：事务一致 [ARCHIVE_LOCAL] ARCH_TYPE = LOCAL #本地归档类型 ARCH_DEST = /home/dmdba/dmdbms/DMDB/arch/ #本地归档存放路径 ARCH_FILE_SIZE = 1024 #单个归档大小，单位 MB ARCH_SPACE_LIMIT = 10240 #归档上限，单位 MB ARCH_FLUSH_BUF_SIZE = 0 ARCH_HANG_FLAG = 1 [ARCHIVE_REALTIME1] ARCH_TYPE = REALTIME #实时归档类型 ARCH_DEST = GRP_TEST_01 #实时归档目标实例名，这里则填主库的实例 3）修改 dm.ini\r在 B 机器上修改 dm.ini ，它比 A 机器上多了一个参数修改 ARCH_INI = 1 打开归档配置\n因为 A 机器是通过 SQL 的方式打开归档的，B 机器这里并没有启动服务，所以通过修改参数文件的方式开启\n并且确保文件里的实例名为：GRP_TEST_02\n1 2 3 4 5 6 7 8 9 10 [dmdba@linux2 DMDB]$ vi /home/dmdba/dmdbms/DMDB/dm.ini INSTANCE_NAME = GRP_TEST_02 PORT_NUM = 5236 #数据库实例监听端口 DW_INACTIVE_INTERVAL = 60 #接收守护进程消息超时时间 ALTER_MODE_STATUS = 0 #不允许手工方式修改实例模式/状态/OGUID ENABLE_OFFLINE_TS = 2 #不允许备库 OFFLINE 表空间 MAL_INI = 1 #打开 MAL 系统 ARCH_INI = 1 #打开归档配置 RLOG_SEND_APPLY_MON = 64 #统计最近 64 次的日志重演信息 4）创建 dmmal.ini\r配置它与 A 机器的参数相同（即保持与主库一致），用 A 机器的 dmmal.ini 配置即可\n5）创建 dmwatcher.ini\r配置它与 A 机器的参数相同（即保持与主库一致），用 A 机器的 dmwatcher.ini 配置即可\n6）注册服务\r使用 root 用户执行，跟 A 机器的注册服务类似，创建一个 GRP_TEST_02 实例服务，创建一个数据守护服务\n1 2 3 4 5 6 7 [root@linux2 root]# ./dm_service_installer.sh -t dmserver -p GRP_TEST_02 -dm_ini /home/dmdba/dmdbms/DMDB/dm.ini -m mount Created symlink from /etc/systemd/system/multi-user.target.wants/DmServiceGRP_TEST_02.service to /usr/lib/systemd/system/DmServiceGRP_TEST_02.service. 创建服务(DmServiceGRP_TEST_02)完成 [root@linux2 root]# ./dm_service_installer.sh -t dmwatcher -p Watcher -watcher_ini /home/dmdba/dmdbms/DMDB/dmwatcher.ini Created symlink from /etc/systemd/system/multi-user.target.wants/DmWatcherServiceWatcher.service to /usr/lib/systemd/system/DmWatcherServiceWatcher.service. 创建服务(DmWatcherServiceWatcher)完成 【注意】\r一般生产上通常的配置，是两台，一主一备，并没有给配置监视器的机器，所以。到这里，其实我们的实时主备就搭建完成了，剩下的就是做启动集群服务，和验证是否真的实时同步数据。\n监视器\r需要监视器的说明\r如果需要监视器，则应该再使用一台服务器，单独部署监视器，用来监控集群服务，以及实现自动切换主备。现有接触到的项目，监视器直接部署到了主库服务器上了。\n需要监视器，则按照此步骤继续部署监视器，否则请跳过该步骤，往下接【3.5 启动服务】步骤\n为了更贴近实际项目，所以我在 A 机器（192.168.163.9）上安装（反正随便装在一台上）监视器\n1）创建 dmmonitor.ini\r这个是确认监视器，就是MON_DW_CONFIRE=1\n1 2 3 4 5 6 7 8 9 10 11 12 [dmdba@linux1 DMDB]# vi dmmonitor.ini MON_DW_CONFIRM = 1 #0：非确认（故障手切） 1：确认（故障自切） MON_LOG_PATH = ../log_monitor #监视器日志文件存放路径 MON_LOG_INTERVAL = 60 #每隔 60s 定时记录系统信息到日志文件 MON_LOG_FILE_SIZE = 32 #单个日志大小，单位 MB MON_LOG_SPACE_LIMIT = 1024 #日志上限，单位 MB [GRP1] MON_INST_OGUID = 45331 #组 GRP1 的唯一 OGUID 值 MON_DW_IP = 192.168.163.9:5436 #IP 对应 MAL_HOST，PORT 对应 MAL_DW_PORT MON_DW_IP = 192.168.163.10:5436 2）创建 dmmonitor_manual.ini\r再配置一个非监视器，就是 MON_DW_CONFIRE=0\n它可以在手动切换的时候，直接通过这个非监视器命令去手动切换，就不需要这么麻烦的切换主备数据库模式了\n1 2 3 4 5 6 7 8 9 10 11 12 [dmdba@linux1 DMDB]# vi dmmonitor_manaul.ini MON_DW_CONFIRM = 0 #0：非确认（故障手切） 1：确认（故障自切） MON_LOG_PATH = ../log_monitor #监视器日志文件存放路径 MON_LOG_INTERVAL = 60 #每隔 60s 定时记录系统信息到日志文件 MON_LOG_FILE_SIZE = 32 #单个日志大小，单位 MB MON_LOG_SPACE_LIMIT = 1024 #日志上限，单位 MB [GRP1] MON_INST_OGUID = 45331 #组 GRP1 的唯一 OGUID 值 MON_DW_IP = 192.168.163.9:5436 #IP 对应 MAL_HOST，PORT 对应 MAL_DW_PORT MON_DW_IP = 192.168.163.10:5436 3）注册监视器服务\r【注意】确认监视器需要注册服务，非确认监视器不需要注册服务\n1 2 3 [root@linux1 root]# ./dm_service_installer.sh -t dmmonitor -p Monitor -monitor_ini /home/dmdba/dmdbms/DMDB/dmmonitor.ini Created symlink from /etc/systemd/system/multi-user.target.wants/DmMonitorServiceMonitor.service to /usr/lib/systemd/system/DmMonitorServiceMonitor.service. 创建服务(DmMonitorServiceMonitor)完成 附：删除监视器服务\r1 [root@linux1 root]# ./dm_service_uninstaller.sh -n DmMonitorServiceMonitor 4）监视器启动\r1 2 [dmdba@linux1 bin]# ./DmMonitorServiceMonitor start Starting DmMonitorServiceMonitor: 上一次登录：日 7月 21 11:07:16 CST 2024pts/1 上\t[OK] 监视器的启动，需要在达梦数据库服务启动才能启\n5）非确认监视器的使用\r确认监视器为自动切换，所以不需要使用它\n只有需要手动切换主备的时候，使用非确认监视器就行\n5.1）进入非确认监视器\r1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 [dmdba@linux1 bin]$ ./dmmonitor ../DMDB/dmmonitor_manual.ini [monitor] 2024-07-22 21:44:14: DMMONITOR[4.0] V8 [monitor] 2024-07-22 21:44:15: DMMONITOR[4.0] IS READY. [monitor] 2024-07-22 21:44:15: #-----------------------------------------------------------------------------------------------# GET MONITOR CONNECT INFO FROM DMWATCHER(GRP_TEST_01), THE FIRST LINE IS SELF INFO. DW_CONN_TIME MON_CONFIRM MID MON_IP MON_VERSION 2024-07-22 21:44:15 FALSE 930807350 ::ffff:192.168.163.9 DMMONITOR[4.0] V8 2024-07-22 21:34:50 TRUE 826253418 ::ffff:192.168.163.9 DMMONITOR[4.0] V8 #-----------------------------------------------------------------------------------------------# [monitor] 2024-07-22 21:44:15: 收到守护进程(GRP_TEST_01)消息 WTIME WSTATUS INST_OK INAME ISTATUS IMODE RSTAT N_OPEN FLSN CLSN 2024-07-22 21:44:15 OPEN OK GRP_TEST_01 OPEN STANDBY NULL 5 43526 43526 [monitor] 2024-07-22 21:44:15: 收到守护进程(GRP_TEST_02)消息 WTIME WSTATUS INST_OK INAME ISTATUS IMODE RSTAT N_OPEN FLSN CLSN 2024-07-22 21:44:15 OPEN OK GRP_TEST_02 OPEN PRIMARY VALID 5 43526 43526 5.2）监视器命令\r命令 含义 list 查看守护进程的配置信息 show global info 查看所有实例组的信息 tip 查看系统当前允许状态 login 登录监视器，使用的具有 DBA 权限数据库用户，非服务器用户 logout 退出登录 choose switchover GRP1 主机正常时，查看可切换为主机的实例 switchover GRP1.GRP_TEST_01 主机正常时，使用指定组.实例 切换为主机 choose takeover GRP1 主机故障时，查看可切换为主机的实例 takeover GRP1.GRP_TEST_01 主机故障时，使用指定组.实例 切换为主机 choose takeover force GRP1 查看可强制切换为主机的实例 takeover force GRP1.GRP_TEST_01 使用组.实例 强制切换为主机 使用命令例子：都是进入监视器后直接输入即可\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 login 用户名:SYSDBA 密码: [monitor] 2024-07-22 21:46:33: 登录监视器成功! tip [monitor] 2024-07-22 21:49:01: [!!! 提示：本监视器不是确认监视器，在故障自动切换模式下如果发生主库故障，本监视器无法执行自动接管 !!!] [monitor] 2024-07-22 21:49:01: 实例GRP_TEST_02[PRIMARY, OPEN, ISTAT_SAME:TRUE]不可加入其他实例，守护进程状态：OPEN，Open记录状态：VALID [monitor] 2024-07-22 21:49:01: 实例GRP_TEST_02[PRIMARY, OPEN, ISTAT_SAME:TRUE]当前没有命令正在执行 [monitor] 2024-07-22 21:49:01: 实例GRP_TEST_02[PRIMARY, OPEN, ISTAT_SAME:TRUE]运行正常, 守护进程是OPEN状态，守护类型是GLOBAL [monitor] 2024-07-22 21:49:01: 实例GRP_TEST_01[STANDBY, OPEN, ISTAT_SAME:TRUE]可加入实例GRP_TEST_02[PRIMARY, OPEN, ISTAT_SAME:TRUE] [monitor] 2024-07-22 21:49:01: 实例GRP_TEST_01[STANDBY, OPEN, ISTAT_SAME:TRUE]当前没有命令正在执行 [monitor] 2024-07-22 21:49:01: 实例GRP_TEST_01[STANDBY, OPEN, ISTAT_SAME:TRUE]运行正常, 守护进程是OPEN状态，守护类型是GLOBAL [monitor] 2024-07-22 21:49:01: 组(GRP1)当前活动实例运行正常 [monitor] 2024-07-22 21:49:01: 所有组中的活动实例运行正常！ 启动服务\r启动数据库并修改参数\rA 机器，启动数据库实例服务，并修改 OGUID 为 dmwatcher.ini 里配置的 OGUID 一致，并将 A 机器的库设置为 PRIMARY 模式\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 [dmdba@linux1 bin]$ ./DmServiceGRP_TEST_01 start Starting DmServiceGRP_TEST_01: [ OK ] [dmdba@linux1 bin]$ ./disql SYSDBA/SYSDBA 服务器[LOCALHOST:5236]:处于普通配置状态 登录使用时间 : 19.397(ms) disql V8 SQL\u0026gt; SP_SET_PARA_VALUE(1,\u0026#39;ALTER_MODE_STATUS\u0026#39;,1); DMSQL 过程已成功完成 已用时间: 40.185(毫秒). 执行号:1. ################ # 修改 OGUID ################ SQL\u0026gt; SP_SET_OGUID(45331); DMSQL 过程已成功完成 已用时间: 10.529(毫秒). 执行号:2. ######################### # 修改为主库为 PRIMARY 模式 ######################### SQL\u0026gt; ALTER DATABASE PRIMARY; 操作已执行 已用时间: 34.763(毫秒). 执行号:0. SQL\u0026gt; SP_SET_PARA_VALUE(1,\u0026#39;ALTER_MODE_STATUS\u0026#39;,0); DMSQL 过程已成功完成 已用时间: 26.340(毫秒). 执行号:3. B 机器，启动数据库实例服务，并修改 OGUID 为 dmwatcher.ini 里配置的 OGUID 一致，并将 B 机器的库设置为 STANDBY 模式\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 [dmdba@linux2 bin]$ ./DmServiceGRP_TEST_02 start Starting DmServiceGRP_TEST_02: [ OK ] [dmdba@linux2 bin]$ ./disql SYSDBA/SYSDBA 服务器[LOCALHOST:5236]:处于普通配置状态 登录使用时间 : 48.562(ms) disql V8 SQL\u0026gt; SP_SET_PARA_VALUE(1,\u0026#39;ALTER_MODE_STATUS\u0026#39;,1); DMSQL 过程已成功完成 已用时间: 50.707(毫秒). 执行号:1. SQL\u0026gt; SP_SET_OGUID(45331); DMSQL 过程已成功完成 已用时间: 8.188(毫秒). 执行号:2. SQL\u0026gt; ALTER DATABASE STANDBY; 操作已执行 已用时间: 48.859(毫秒). 执行号:0. SQL\u0026gt; SP_SET_PARA_VALUE(1,\u0026#39;ALTER_MODE_STATUS\u0026#39;,0); DMSQL 过程已成功完成 已用时间: 36.601(毫秒). 执行号:3. 启动守护进程\r机器 A 和 B 都启动数据守护进程\n1 2 [dmdba@linux1 bin]$ ./DmWatcherServiceWatcher start Starting DmWatcherServiceWatcher: [ OK ] 到这里，数据库服务启动完毕！\n附：集群启停\r在刚部署时，按照 数据库 \u0026raquo; 数据守护 的顺序，如上\n如果需要重启时，则应该：数据守护停止 \u0026raquo; 数据库重启 \u0026raquo; 数据守护启动\n1 2 3 4 cd /home/dmdba/dmdbms/bin ./DmWatcherServiceWatcher stop ./DmServiceGRP_TEST_01 restart ./DmWatcherServiceWatcher start 如果需要停止时，则应该：数据守护停止 \u0026raquo; 数据库停止\n1 2 3 cd /home/dmdba/dmdbms/bin ./DmWatcherServiceWatcher stop ./DmServiceGRP_TEST_01 stop 有监视器的情况下：\n启动：数据库实例 \u0026raquo; 数据守护 \u0026raquo; 监视器\n停止：监视器 \u0026raquo; 数据守护 \u0026raquo; 数据库实例\n重启同上\n配置 dm_svc.conf\r达梦数据库在安装完成后，在 /etc 目录下生成一个 dm_svc.conf 文件，用于实现达梦集群的故障自动重连、读写分离\n并且它可以在 JDBC 中使用，连接数据库时指定连接服务名，接口会随机选择 一个 IP 进行连接，如果连接不成功或者服务器状态不正确，则顺序获取下一个 IP 进行连接， 直至连接成功或者遍历了所有 IP 。\n在 实施部署-达梦数据库linux版的安装（二） | WeiQi Blog (weiqifun.github.io) 也记录总结过\n官方文档《DM8系统管理员手册.pdf》2.1.1.4 章节介绍了这个文件里详细的参数\n实时主备服务名配置\r这个是需要数据库服务器上配置，应用服务器上也要配置，即应用如果想要通过服务名连接数据库，则也需要配置这个文件，双方才能互相通信\nlinux 在 /etc/dm_svc.conf\nwindows 在 C:\\Windows\\System32 （多数 64 位机器是这个位置，反正是在 %SystemRoot%\\system32 下）\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 vi /etc/dm_svc.conf ###################### 添加以下内容 ############################# # 全局配置 TIME_ZONE=(480) # 时区 +8:00 60一个时区 LANGUAGE=(cn) GRP1=(192.168.163.9:5236,192.168.163.10:5236) # 服务名 = (各个数据库的 IP:PORT ) 逗号分割 # 服务配置 [GRP1] TIME+ZONE=(+480) # 指定优先登录的服务器模式 0-优先PRIMARY 1-只连接主库 2-只连接备库 3-优先STANDBY 4-优先NORMAL（缺省默认） LOGIN_MODE=(1) SWITCH_TIME=(3) # 以服务名连接数据库时，发生故障时，失败重连次数 SWITCH_INTERVAL=(200) # 主备服务器切换、重连等待的时间间隔，毫秒 ###################### 以上为实时主备数据守护配置 ##################################### # 读写分离配置 RW_SEPARATE=(1) # 启用读写分离，使用此参数时，LOGIN_MODE 参数失效 RW_PERCENT=(25) # 读写分离时，读写分离的分发比例 JDBC 连接\r1 2 jdbc:dm://GRP1?schema=TEST jdbc:dm://GRP1?schema=TEST\u0026amp;columnNameUpperCase=false 达梦管理工具连接\r因为目前手上的机器为 LINUX + WINDOWS ，应用在 WINDOWS 上，所以我在 C:\\Windows\\System32 找到该文件，然后进行相同的配置。应用在 LINUX 上则同理数据库服务器上的路径。\n把客户端重启，配置才会生效\n到这里也就 OK 了，服务名配置成功\n验证-主库挂掉后是否会自动切换\r1）停止主库\r采用的方式为停止主库（即把主库的DmWatcher守护进程服务、DmService服务停止掉），看看使用服务名是否能连接到备库\n1 2 3 4 5 [dmdba@linux1 bin]$ ./DmWatcherServiceWatcher stop Stopping DmWatcherServiceWatcher: [ OK ] [dmdba@linux1 bin]$ ./DmServiceGRP_TEST_01 stop Stopping DmServiceGRP_TEST_01: [ OK ] 我把达梦客户端重启，重新连接 GRP1\n报错服务器模式不匹配，因为 dm_svc.conf 的 LOGIN_MODE = 1 只连接 PRIMARY 库，因此主库挂掉后无法连接到备库\n修改数据库服务器、应用服务器的 dm_svc.conf 配置文件，修改里边的 LOGIN_MODE=0 ，优先连接 PRIMARY\n再重启客户端，重连 GRP1\n嗯，这个连接过程会有明显的卡顿了一下，估计是在遍历 GRP1 里的数据库实例\n当前连的是备库（备库是 STANDBY 模式，因为没有监视器，所以是不会自动切换主备的，我这边没有手动切换，所以连接到备库，只提供只读服务）\n2）重启主库\r把主库重新启动，再重启客户端连接，连接正常的\n1 2 SELECT NAME, INSTANCE_NAME, STATUS$, MODE$ FROM V$INSTANCE; -- MODE$ 的值为 PRIMARY 验证实时同步\r验证一：主库操作\r1）执行创建表空间、用户、授权等操作\r打开达梦管理工具，连接到主库（192.168.163.9:5236），默认的管理员用户 SYSDBA/SYSDBA\n1 2 3 4 5 6 7 8 9 10 11 12 CREATE TABLESPACE \u0026#34;TS_TEST\u0026#34; DATAFILE \u0026#39;/home/dmdba/dmdbms/DMDB/TS_TEST.DBF\u0026#39; SIZE 500 AUTOEXTEND ON NEXT 40 MAXSIZE 2048; CREATE USER \u0026#34;TEST\u0026#34; IDENTIFIED BY \u0026#34;TEST123456\u0026#34; DEFAULT TABLESPACE \u0026#34;TS_TEST\u0026#34;; GRANT \u0026#34;DBA\u0026#34; TO \u0026#34;TEST\u0026#34;; GRANT DELETE ANY TABLE TO TEST; GRANT EXECUTE ANY PROCEDURE TO TEST; GRANT INSERT ANY TABLE TO TEST; GRANT SELECT ANY DICTIONARY TO TEST; GRANT SELECT ANY TABLE TO TEST; GRANT UNLIMITED TABLESPACE TO TEST; GRANT UPDATE ANY TABLE TO TEST; 连接备库（192.168.163.10:5236），验证是否有刚刚创建的表空间、用户\n主备实时同步正常\n2）创建表、插入数据操作\r打开达梦管理工具，连接到主库（192.168.163.9:5236），默认的管理员用户 SYSDBA/SYSDBA\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 CREATE TABLE \u0026#34;TEST\u0026#34;.\u0026#34;ST_TEST_1\u0026#34; ( \u0026#34;BUSI_DATE\u0026#34; INTEGER, \u0026#34;NAME\u0026#34; VARCHAR2(20), \u0026#34;AGE\u0026#34; VARCHAR2(2), \u0026#34;SEX\u0026#34; VARCHAR2(1)) STORAGE(ON \u0026#34;TS_TEST\u0026#34;, CLUSTERBTR) ; COMMENT ON COLUMN \u0026#34;TEST\u0026#34;.\u0026#34;ST_TEST_1\u0026#34;.\u0026#34;SEX\u0026#34; IS \u0026#39;1-男; 2-女\u0026#39;; INSERT INTO \u0026#34;TEST\u0026#34;.\u0026#34;ST_TEST_1\u0026#34; (\u0026#34;BUSI_DATE\u0026#34;, \u0026#34;NAME\u0026#34;, \u0026#34;AGE\u0026#34;, \u0026#34;SEX\u0026#34;) VALUES (20240702, \u0026#39;DY L\u0026#39;, \u0026#39;18\u0026#39;, \u0026#39;1\u0026#39;); INSERT INTO \u0026#34;TEST\u0026#34;.\u0026#34;ST_TEST_1\u0026#34; (\u0026#34;BUSI_DATE\u0026#34;, \u0026#34;NAME\u0026#34;, \u0026#34;AGE\u0026#34;, \u0026#34;SEX\u0026#34;) VALUES (20240702, \u0026#39;DO W\u0026#39;, \u0026#39;19\u0026#39;, \u0026#39;1\u0026#39;); INSERT INTO \u0026#34;TEST\u0026#34;.\u0026#34;ST_TEST_1\u0026#34; (\u0026#34;BUSI_DATE\u0026#34;, \u0026#34;NAME\u0026#34;, \u0026#34;AGE\u0026#34;, \u0026#34;SEX\u0026#34;) VALUES (20240702, \u0026#39;PE J\u0026#39;, \u0026#39;10\u0026#39;, \u0026#39;2\u0026#39;); INSERT INTO \u0026#34;TEST\u0026#34;.\u0026#34;ST_TEST_1\u0026#34; (\u0026#34;BUSI_DATE\u0026#34;, \u0026#34;NAME\u0026#34;, \u0026#34;AGE\u0026#34;, \u0026#34;SEX\u0026#34;) VALUES (20240702, \u0026#39;DER K\u0026#39;, \u0026#39;52\u0026#39;, \u0026#39;1\u0026#39;); INSERT INTO \u0026#34;TEST\u0026#34;.\u0026#34;ST_TEST_1\u0026#34; (\u0026#34;BUSI_DATE\u0026#34;, \u0026#34;NAME\u0026#34;, \u0026#34;AGE\u0026#34;, \u0026#34;SEX\u0026#34;) VALUES (20240702, \u0026#39;NC VC\u0026#39;, \u0026#39;60\u0026#39;, \u0026#39;2\u0026#39;); COMMIT; 连接备库（192.168.163.10:5236），验证是否有刚刚创建表和数据\n1 2 3 4 5 6 7 8 9 10 SELECT * FROM TEST.ST_TEST_1; BUSI_DATE NAME AGE SEX 20240702 DY L 18 1 20240702 DO W 19 1 20240702 PE J 10 2 20240702 DER K 52 1 20240702 NC VC 60 2 主备实时同步正常\n验证二：备库写操作\r因为备库是 STANDBY 模式，提供只读服务，是不能往备库操作对象的，所以看看是否模式生效\n连接备库（192.168.163.10:5236），使用 SYSDBA 管理员用户试图创建一张表\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 [执行语句1]: CREATE TABLE \u0026#34;TEST\u0026#34;.\u0026#34;ST_TEST_2\u0026#34; ( \u0026#34;BUSI_DATE\u0026#34; INTEGER, \u0026#34;NAME\u0026#34; VARCHAR2(20), \u0026#34;AGE\u0026#34; VARCHAR2(2), \u0026#34;SEX\u0026#34; VARCHAR2(1)) STORAGE(ON \u0026#34;TS_TEST\u0026#34;, CLUSTERBTR) ; 执行失败(语句1) -710: 试图在STANDBY模式下，修改用户库 1条语句执行失败 [执行语句1]: DELETE FROM TEST.ST_TEST_1; 执行失败(语句1) -710: 试图在STANDBY模式下，修改用户库 主备模式正常\n无监视器进行主备切换\r当异常发生时，没有配置监视器的实时主备，如何进行切换主备库？\n直接使用 SQL 进行切换，切换之前，先使用 VMware 的快照功能备份一下当前的服务器状态，增加主备切换的容错，让自己能够使用快照快速恢复到刚刚搭建好集群的状态。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 -- 先将数据库切换为 Mount 状态 [dmdba@linux1 bin]$ ./disql SYSDBA/SYSDBA 服务器[LOCALHOST:5236]:处于主库打开状态 登录使用时间 : 37.834(ms) disql V8 SQL\u0026gt; ALTER DATABASE MOUNT; ALTER DATABASE MOUNT; 第1 行附近出现错误[-720]:守护进程处于活动状态，或当前配置(ALTER_MODE_STATUS)不允许该操作. 已用时间: 1.582(毫秒). 执行号:0. ################################################## # 需要先关闭数据守护 和 修改 ALTER_MODE_STATUS 参数 ################################################## 需要将守护进程关掉和模式的参数修改为可修改，才能切换，关掉守护进程的顺序：\n备库的守护进程 \u0026raquo; 主库的守护进程（其实无所谓）\n【注意】\r需要确保数据库中没有活动事务，手动切换需要将数据库调整为 mount 状态，它会回滚所以处于活动中的事务，已提交的事务不影响。\n所以确保一下当下数据库事务的状态，如果有正在执行增删改操作的，强行调整的话，后续切换成功后，需要手动重新执行增删改的事务。\nA 机器操作（主库操作）\r主库切换为 PRIMARY 模式\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 [dmdba@linux1 bin]$ ./DmWatcherServiceWatcher stop Stopping DmWatcherServiceWatcher: [ OK ] [dmdba@linux1 bin]$ ./disql SYSDBA/SYSDBA 服务器[LOCALHOST:5236]:处于主库打开状态 登录使用时间 : 20.108(ms) disql V8 SQL\u0026gt; SP_SET_PARA_VALUE(1,\u0026#39;ALTER_MODE_STATUS\u0026#39;,1); DMSQL 过程已成功完成 已用时间: 37.106(毫秒). 执行号:1001. SQL\u0026gt; ALTER DATABASE MOUNT; 操作已执行 已用时间: 71.860(毫秒). 执行号:0. SQL\u0026gt; ALTER DATABASE STANDBY; 操作已执行 已用时间: 73.077(毫秒). 执行号:0. ################## # 非 NORMAL 模式需要 OPEN FORCE 强制开启 ################## SQL\u0026gt; ALTER DATABASE OPEN FORCE; 操作已执行 已用时间: 33.830(毫秒). 执行号:0. SQL\u0026gt; SP_SET_PARA_VALUE(1,\u0026#39;ALTER_MODE_STATUS\u0026#39;,0); DMSQL 过程已成功完成 已用时间: 36.470(毫秒). 执行号:1002. B 机器操作（备库操作）\r备库切换为 STANDBY 模式\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 [dmdba@linux2 bin]$ ./DmWatcherServiceWatcher stop Stopping DmWatcherServiceWatcher: [ OK ] [dmdba@linux2 bin]$ ./disql SYSDBA/SYSDBA 服务器[LOCALHOST:5236]:处于备库打开状态 登录使用时间 : 21.257(ms) disql V8 SQL\u0026gt; SP_SET_PARA_VALUE(1,\u0026#39;ALTER_MODE_STATUS\u0026#39;,1); DMSQL 过程已成功完成 已用时间: 36.238(毫秒). 执行号:301. SQL\u0026gt; ALTER DATABASE MOUNT; 操作已执行 已用时间: 20.816(毫秒). 执行号:0. SQL\u0026gt; ALTER DATABASE PRIMARY; 操作已执行 已用时间: 66.994(毫秒). 执行号:0. SQL\u0026gt; ALTER DATABASE OPEN; ALTER DATABASE OPEN; 第1 行附近出现错误[-516]:非NORMAL模式需要OPEN FORCE. 已用时间: 0.959(毫秒). 执行号:0. SQL\u0026gt; ALTER DATABASE OPEN FORCE; 操作已执行 已用时间: 93.506(毫秒). 执行号:0. SQL\u0026gt; SP_SET_PARA_VALUE(1,\u0026#39;ALTER_MODE_STATUS\u0026#39;,0); DMSQL 过程已成功完成 已用时间: 32.835(毫秒). 执行号:302. 启动数据守护\rA \\ B 机器都启动\n1 2 [dmdba@linux1 bin]$ ./DmWatcherServiceWatcher start Starting DmWatcherServiceWatcher: [ OK ] 验证切换是否成功\r查看实例的模式\rA 机器查看，因为已经将 A 切换为备库了，所以 ./disql 会显示处于备库打开状态\n1 2 3 4 5 6 7 8 9 10 11 12 [dmdba@linux1 bin]$ ./disql SYSDBA/SYSDBA 服务器[LOCALHOST:5236]:处于备库打开状态 登录使用时间 : 18.106(ms) disql V8 SQL\u0026gt; SELECT NAME, INSTANCE_NAME, STATUS$, MODE$ FROM V$INSTANCE; 行号 NAME INSTANCE_NAME STATUS$ MODE$ ---------- ----------- ------------- ------- ------- 1 GRP_TEST_01 GRP_TEST_01 OPEN STANDBY B 机器查看，\n1 2 3 4 5 6 7 8 9 10 11 12 [dmdba@linux2 bin]$ ./disql SYSDBA/SYSDBA 服务器[LOCALHOST:5236]:处于主库打开状态 登录使用时间 : 31.640(ms) disql V8 SQL\u0026gt; SELECT NAME, INSTANCE_NAME, STATUS$, MODE$ FROM V$INSTANCE; 行号 NAME INSTANCE_NAME STATUS$ MODE$ ---------- ----------- ------------- ------- ------- 1 GRP_TEST_02 GRP_TEST_02 OPEN PRIMARY 在主库操作\r主库执行 SQL\n1 2 3 CREATE TABLE \u0026#34;TEST\u0026#34;.\u0026#34;T_LISTAGG_TEST\u0026#34; ( \u0026#34;ID\u0026#34; INTEGER, \u0026#34;C1\u0026#34; VARCHAR(4000)) STORAGE(ON \u0026#34;TS_TEST\u0026#34;, CLUSTERBTR) ; 在备库中查看是否同步，已同步证明没问题\n确认监视器自动切换验证\r在【6 无监视器进行主备切换】步骤中，已经把 A 机器(GRP_TEST_01)切换为备库，B 机器(GRP_TEST_02)切换为主库了。\n把主库 GRP_TEST_02 挂掉（即把主库的DmWatcher守护进程服务、DmService服务停止掉），然后使用达梦管理工具使用服务名进入数据库，查看是否连接到 GRP_TEST_01 并且将该数据库是模式切换为 PRIMARY\n1 2 3 4 [dmdba@linux2 bin]$ ./DmWatcherServiceWatcher stop Stopping DmWatcherServiceWatcher: [ OK ] [dmdba@linux2 bin]$ ./DmServiceGRP_TEST_02 stop Stopping DmServiceGRP_TEST_02: [ OK ] 确认是自动切换了 OK\n非确认监视器切换\r这里就不再详细说明了，把确认监视器失效掉（把里边的 MON_DW_CONFIRM 改为 1），然后使用非确认监视器\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 # 前台方式进入非确认监视器 cd /home/dmdba/dmdbms/bin ./dmmonitor /home/dmdba/dmdbms/DMDB/dmmonitor_manual.ini # 检查集群状态 tip # 登录非确认监视器：使用有 DBA 权限的用户，我用 SYSBDA login # 查看满足切换条件的实例 choose switchover GRP1 # 进行主备切换 switchover GRP1.GRP_TEST_01 # 切换成功，退出监视器 logout # 再次查看集群状态 tip # 正常了，退出非确认监视器即可 exit 报错问题\r主要还是步骤并没有按顺序来导致的，或者配置文件里配置错误导致\n启动数据守护报错\r1 2 3 4 5 6 [dmdba@linux1 bin]$ ./dmwatcher /home/dmdba/dmdbms/DMDB/dmwatcher.ini DMWATCHER[4.0] V8 Invalid [mal_name] or the file contains unrecognized characters in [/home/dmdba/dmdbms/DMDB/dmmal.ini]! Read ini file(/home/dmdba/dmdbms/DMDB/dmmal.ini) error in line 1, code(-104) Read dm.ini(/home/dmdba/dmdbms/DMDB/dm.ini) failed, code = -104! fail to read ini file 读两个文件报错了，第一个报错给出了明确的列\ndmmal.ini 的第一列报错，查看了一下，复制进shell的时候，缺少了 MA 两个字母，补充形成完整的\nMAL_CHECK_INTERVAL 参数\n1 MAL_CHECK_INTERVAL = 10 #MAL 链路检测时间间隔 然后重新启动就成功了\n1 2 [dmdba@linux1 bin]$ ./DmWatcherServiceWatcher start Starting DmWatcherServiceWatcher: [ OK ] 启动数据库实例报错\r1 2 [dmdba@linux1 bin]$ ./DmServiceGRP_TEST_01 start Starting DmServiceGRP_TEST_01: [ FAILED ] 查看日志 dm_实例名_年月.log\n1 2 2024-07-21 11:22:01.998 [INFO] database P0000036451 T0000000000000036513 utsk_tcp_conn_validate failed, seqno:0, from_name:, code:-9423! 2024-07-21 11:22:03.014 [INFO] database P0000036451 T0000000000000036513 Dmwatcher oguid(45331) is not match with local dmserver oguid(0), code -9423, cannot build connection! 查看数据守护的日志 dm_dmwatcher_实例名_年月.log\n1 2024-07-21 11:26:58.830 [INFO] dmwatcher P0000036411 T0000000000000036416 dw2_tcp_conn_startup, oguid(45331) configured in dmwatcher.ini not equal with local dmserver\u0026#39;s oguid(0)! 是因为没有启动数据库，并到数据库里修改 OGUID 参数导致。看上边启动服务步骤。\n","date":"2024-07-21T22:10:12+08:00","permalink":"http://localhost:1313/posts/2024/07/%E4%B8%BB%E5%A4%87%E9%9B%86%E7%BE%A4-%E8%BE%BE%E6%A2%A6%E5%AE%9E%E6%97%B6%E4%B8%BB%E5%A4%87%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA%E4%B8%8E%E4%B8%BB%E5%A4%87%E5%88%87%E6%8D%A2%E5%AE%9E%E8%B7%B5%E4%BA%8C/","title":"主备集群-达梦实时主备集群搭建与主备切换实践（二）"},{"content":"为了弄清达梦的数据守护，实操主备集群搭建实践，做概念的基本了解。\n总结一篇数据守护的概念，包括数据库模式、数据库状态、归档等概念，在搭建主备集群时，能清楚的知道自己是在做什么，为什么这么做。\n达梦数据守护概念\r达梦数据守护，为数据库容灾方案，通过数据库主备集群，进行实时主备切换，在主库出现异常时，自带切换备库对应用提供数据库服务。\n数据守护原理\rDM数据守护 DM DATA WATCH 原理：\n主库产生的 Redo 日志 \u0026raquo; 传到备库 \u0026raquo; 备库重演 Redo 日志，实现主备库数据同步\n数据守护组成\r主库\n备库\nRedo 日志\nRedo 日志传输\nRedo 日志重演\n守护进程 DmWatcher\n监视器 DmMonitor\n主库\r主库使用 Primary 模式，有完整的数据库服务\n备库\r使用 Standby 模式，提供只读服务\nRedo 日志\rRedo 日志里，记录了物理数据页内容变动的情况（在部署时，确定页大小，就是为了单页能够记录更多的内容）\nInert \\ Update \\ Delete \\ Create 等 DML 和 DDL 操作都会记录到 Redo 日志里\nRedo 日志重演\r达梦有专门的 Redo 日志重演的服务\n守护进程\rDmWatcher 用来监控数据库实例的运行状态和主备库同步情况的，它接收各种消息（数据库实例、监视器的消息）\n监视器\rDmMonitor 用来监控守护进程、数据库实例的信息，监控实例故障、自动切换主备的。\n现有的接触项目的情况，是没有这个的，监视器需要单独一台服务器，来监控数据库实例和守护进程。\n不过要是配置在数据库服务器上，应该也是可以的，就是服务器不能异常就行，这种情况只允许进程异常。\n普通的项目，通常是一主一备，并没有多余的机器部署 DmMonitor ，所以还是不能实现主备自动切换的，只能手动切换主备\n数据库与数据库实例\r数据库是一个文件集合，包括数据文件、日志文件、控制文件等，保存在磁盘中\n数据库实例，则是一个操作系统进程。通过数据库实例来操作数据库（说白了，我们只需要操作实例，实例会对数据库进行操作）\n数据守护需要了解的基本概念\r数据库模式\rNormal 模式 Primary 模式 Standby 模式 Normal 模式\r正常模式，操作没有限制\n生成本地归档\nPrimary 模式\r主库的模式\n不支持修改表空间文件名，不支持修改归档 arch_ini 参数\n生成本地归档，支持实时归档、即时归档、异步归档\n临时表空间以外的所有操作都生成 Redo 日志\nStandby 模式\r备库模式，只读模式\n数据库模式切换\r在数据库服务器上，进入 disql as SYSDBA/SYSDBA ，使用 SQL 语句切换\n1 2 3 4 5 6 7 8 9 10 11 12 -- 先将数据库切换为 Mount 状态 ALTER DATABASE MOUNT; -- 切换为 Primary 模式 ALTER DATABASE PRIMARY; -- 切换为 Standby 模式 ALTER DATABASE STANDBY; -- 切换为 Normal 模式 ALTER DATABASE NORMAL; -- 执行完毕后将数据库实例打开 ALTER DATABASE OPEN; 数据库状态\rStartup 状态\nAfter Redo 状态\nOpen 状态\nMount 状态\nSuspend 状态\nShutdown 状态\nMount 状态\r这个状态下，不能修改数据，不能访问数据库对象\n可以执行修改归档配置、控制文件、修改数据库模式\n修改为 Mount 状态时，会回滚所有活动事务，已提交事务不影响\nStartup 状态\r数据库刚启动时默认为这个状态\nOpen 状态\r这个状态，数据库才会正常提供服务\n这个状态不能归档操作\nSuspend 状态\r一般是修改归档状态之前将系统切换为 Suspend 状态，它不会像 Mount 状态那样回滚所有活动事务，而是切换后所有事务可以继续执行\nShutdown 状态\r服务退出\n数据库状态切换\r也是通过 SQL 语句切换，先进入 disql as SYSDBA/SYSDBA\n1 2 3 4 5 6 7 -- 修改为 Open 状态 ALTER DATABASE OPEN; -- 如果当前处于 Primary \\ Standby 模式，则需要加上 Force 子句 ALTER DATABASE OPEN FORCE; -- 修改为 Mount 状态 ALTER DATABASE MOUNT; Redo 日志\r就前边说的，包括了 DML 和 DDL 操作的记录\nRedo 日志包\rRLOG_PKG Redo日志包，主句发送日志到备库，就是通过日志包的形式发送的\n联机 Redo 日志文件\r达梦数据库初始化实例后，是默认有两个联机 Redo 日志文件：DAMENG01.log DAMENG02.log\n01 是 Redo 日志主文件\n归档\r本地归档 远程归档 实时归档 即时归档 异步归档 同步归档 归档模式的不同，只是在于发送 Redo 日志到备库的时机不同\n本地归档\r归档文件其实保存的就是 Redo 日志\n在本地归档情况下，Normal 、Primary 模式在 Redo 日志写入联机 Redo 日志文件后，由 Redo 日志包 RLOG_PKG\n写入本地归档日志文件中，Standby 模式则是直接写到本地归档日志中\n归档日志一般在 arch 目录，配置了归档才有\n归档日志文件是不能覆盖的，每天都会生成很多份归档日志文件，而且是不会主动删掉的，如果删掉最好配置归档日志空间上限（配置后，系统会自动删除早期的归档日志文件）\n但是在守护系统中，如果删除归档文件，需要主备都同时删，否则会发生备库接收到的日志缺失，导致主备库无法正常同步数据\n实时归档\r本地归档是写入磁盘中的日志文件（比如上方说的DAMENG01.log DAMENG02.log ）\n实时归档是将主库产生的 Redo 日志通过 MAL 系统传递到备库\n流程大致：\n主库 Redo 日志 \u0026raquo; 先传到备库并重演 \u0026raquo; 重演完成后，备库响应主库 \u0026raquo; 主库再把 Redo 日志写入联机日志文件（比如上方说的DAMENG01.log DAMENG02.log ）\n即时归档\r主库把 Redo 日志写入联机日志文件 \u0026raquo; 然后再通过 MAL 发生 Redo 日志到备库\n达梦配置文件说明\n端口配置\r在 dm.ini 中有两个参数，用来配置端口：PORT_NUM DW_PORT\nPORT_NUM\r这个参数是实例的监听端口，也就是连接数据库时，需要输入的端口\nDW_PORT\r这个是守护进程的端口，用于守护进程监听数据库\n服务名配置\r看 《DM8数据守护与读写分离集群V4.0.PDF》 5.8 章节\n数据守护的多种方案\r实时主备 MPP主备 DMDSC主备 读写分离集群 实时主备\r实时主备由一个主库、一个或多个被配了实时归档的备库组成，保障数据库的高可用和数据的安全\n主库提供完整的数据库服务，而备库提供只读服务\n在主库修改的数据，会产生 Redo 日志，通过实时归档机制，发送到备库，然后备库通过重演 Redo 日志，将修改操作在备库执行一遍，依次保持与主库的数据同步\n实时主备系统主要由：主库、备库、守护进程、监视器组成\n但是多数项目中，并没有部署监视器，都是主备库 + 守护进程的模式\n监视器是能在故障发生时自动切换主备的\n","date":"2024-07-20T22:00:31+08:00","permalink":"http://localhost:1313/posts/2024/07/%E4%B8%BB%E5%A4%87%E9%9B%86%E7%BE%A4-%E8%BE%BE%E6%A2%A6%E6%95%B0%E6%8D%AE%E5%BA%93%E6%95%B0%E6%8D%AE%E5%AE%88%E6%8A%A4%E4%B8%80/","title":"主备集群-达梦数据库数据守护（一）"},{"content":"工作中整理的命令大全\nLINUX目录结构\r1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 / - /bin\t# 存放命令，如 /bin/bash ping telnet mount 等，只要是命令，都会在这里 - /boot\t# 内核、系统启动文件 - grub - /dev\t# 硬件设备文件，比如磁盘分区、swap交换空间文件 - /etc\t# 系统配置文件 - /init.d - /sysconfig /home\t# 多为存放用户的数据 /lib | lib64\t# 必要的运行库，比如 xxx.so 文件，比如SElinux的文件 - /modules /mnt\t# 挂载盘 /opt /proc\t# 存储进程、系统信息，比如 cpuinfo、version、swaps /root /sbin /srv /sys /tmp\t# 临时文件 /usr\t# yum rpm 等 安装的应用程序的位置 - /bin - /share - /local /var - /log\t# 系统日志，内核日志 messages - /lib - /spool - /run LINUX命令大全\r1 系统信息类\r1 2 3 4 5 6 7 8 9 # 查看系统信息 uname -a # 系统架构信息 uname -r # CPU信息 cat /proc/cpuinfo # Swap 交换空间 cat /proc/swaps swapon -s 1 2 # 重启机器 reboot 1.1 空间情况\r1 2 3 4 5 6 7 8 9 10 11 12 # 实时查看系统使用情况 top # 查看磁盘使用 df -h # 查看内存使用 free -h # 查看当前目录空间大小 du -sh du -sh * | sort -n # 查看分区 fdisk -l 1.2 系统服务命令\r1 2 3 4 5 6 7 8 9 10 11 12 13 # 系统形式启动 systemctl start service.service # 停止 systemctl stop service.service # 查看状态 systemctl status service.service # 重启 systemctl restart service.service # 开启自启 systemctl enable service.service # 取消开启自启 systemctl disable service.service 1.3 查看环境变量\r1 2 3 4 # 列出环境变量 env # 查看某个环境变量 env | grep PATH 1.4 内核日志\r1 2 3 4 5 6 7 # 查看内核日志 dmesg # 查看特定的内核日志，比如挂载失败的日志 dmesg | grep mount # 或者查看 messages tail -fn 200 /var/log/messages 1.5 文件最大打开数\r为了防止失控的进程破坏系统的性能，linux 会跟踪进程使用的大部分资源，并允许用户和系统管理员使用对进程的资源限制。例如对某个用户打开系统进程数进行限制，一般限制包括软限制、硬限制。\n通常在安装数据库的时候，对这个会有要求，可优化数据库的运行性能。\n1 2 3 4 5 6 7 8 # 编辑相关文件 vi /etc/security/limits.conf # 在最后添加 # user_name user_name soft noproc 65535 user_name hard noproc 65535 user_name soft nofile 65535 user_name hard nofile 65535 1.6 时间管理\r1 2 3 4 5 # 查看时间设置 timedatectl # 手工设置时间 timedatectl set-time \u0026#34;YYYY-MM-DD HH:MM:SS\u0026#34; ntp 同步时间\r1 2 3 4 5 6 7 8 # 需要服务器里安装了 ntp # 一般的发行版自带 # 查看是否安装了 ntp rpm -qa | grep ntp # 使用 timedatectl 同步 Ntp 时间 timedatectl set-ntp true 2 分区、挂载\r1 2 3 4 5 6 7 8 9 fdisk /dev/vda m # 获取 help d # 删除分区 l # 列出现有分区 n # 添加新分区 p # 打印分区表信息 t # 更改分区的系统类型 w # 保存退出 q # 退出而不保存 2.1 更改分区\r1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 # 列出分区 fdisk -l ################################# # 删除分区 # 使用 fdisk 命令，后边接 分区名 fdisk /dev/vda # 列出当前分区信息 Command (m for help): p # 删除命令，选择第四个分区，按顺序来的 Command (m for help): d Partition number (1-4, default 4): 4 # w 是保存退出 Command (m for help): w ################################# ################################# # 新增分区 fdisk /dev/vda # m 帮助 Command (m for help): m # 新增 n ，内存取默认就行 Command (m for help): n Partition number (4-128, default 4): 4 First sector (70436864-104857566, default 70436864): Last sector, +/-sectors or +/-size{K,M,G,T,P} (70436864-104857566, default 104857566): # 也可以填 +20G 这种 # 默认 y Do you want to remove the signature? [Y]es/[N]o: y # 保存 Command (m for help): w # 让内核重新读取分区信息 partprobe -s # 格式化分区，注意这是 filesystem 类型的分区格式化 mkfs.xfs -f /dev/vda4 ################################# 2.2 调整分区类型\r1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 fdisk /dev/vda # 更改分区类型为 swap Command (m for help): t Partition number (1-4, default 4): 4 Partition type (type L to list all types): 19 # 19 是 swap 类型，具体可使用 L 查看更多类型 # 保存 Command (m for help): w # 让内核重新读取分区信息 partprobe -s # 格式化分区 mkswap /dev/vda4 # 挂载分区 swapon /dev/vda4 # 验证 swapon --show # 设置开机自启 vi /etc/fstab # 加入 UUID=9b6af8bf-5a7a-4e6b-8e2e-4afa78cf5bbc none swap defaults 0 0 # 如果不清楚 UUID 可设置为它文件的路径 /dev/vda4 none swap defaults 0 0 ### 如下查看 UUID blkid /dev/vda4 2.3 调整 Swap 空间\r1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 # 查看 swap 分区路径 cat /proc/swaps # 禁用 swapoff /dev/dm-1 # 编辑 /etc/fstab 删掉 swap 分区的信息 vi /etc/fstab # 删掉 此swap 分区的信息 # 创建分区文件 dd if=/dev/zero of=/swapfile bs=500M count=1 # /dev/zero 是 LINUX 里一个特殊块设备，在每次读取时输出零字节 # /swapfile 可以是任意路径下的文件，注意这个不用事先创建 # 授权 chmod 600 swapfile # 格式化 swap 分区 mkswap /swapfile # 激活该文件，添加到交换池中 swapon /swapfile # 验证 swapon --show 2.4 挂载\r1 2 3 4 5 6 7 # 挂载 Windows 共享目录 mount -t cifs -o username=@user, password=@password //IP/share_dir /home/aml # 挂载一个 iso 镜像文件 mount -o loop /path/to/file.iso /mnt # 卸载 umount /home/aml 3 用户相关\r说明\r3.1 用户组\r1 2 3 4 5 6 7 8 9 # 增加用户组 groupadd group_name # 新增指定用户组ID的组 groupadd -g GID group_name # 删除用户组 groupdel group_name # 重命名用户组 groupmod -n new_group_name old_group_name 3.2 用户\r1 2 3 4 5 6 7 8 9 10 11 12 13 # 创建用户 useradd -u UID -g group_name -s /bin/bash -d /home/dir_name -m user_name # -u：指定用户的 ID # -g：指定用户所属组 # -s：指定用户用的 shell # -d：指定用户的根目录路径 # -m：创建用户的根目录 # 例子,创建 test 用户，并设置用户 ID\\所属组\\指定 SHELL\\指定根目录并创建根目录： useradd -u 1001 -g dmdba -s /bin/bash -d /home/dm -m test # 删除用户 userdel -r user_name 3.3 修改用户密码\r1 2 3 4 # 修改密码 passwd user_name # 设置用户口令的失效期限 chage -E 2024-12-12 user_name 3.4 修改用户所属主、组\r1 2 3 4 # 修改用户所属主 usermod -g group_name user_name # 修改用户所属组 usermod -G group_name user_name 4 文件目录相关\r4.1 目录\r4.1 .1 进入\r1 2 3 4 5 6 7 8 9 10 11 12 # 进入目录 cd /home # 返回上一级目录 cd .. # 返回上两级目录 cd ../.. # 进入个人的主目录 cd # 进入个人的主目录 cd ~user1 # 返回上次所在的目录 cd - 4.1.2 显示当前路径\r1 pwd 4.1.3 查看目录\r1 2 3 4 5 6 7 8 9 10 11 12 13 # 查看目录中的文件 ls # 查看目录中的文件 ls -F # 显示文件和目录的详细资料 ls -l # 显示隐藏文件 ls -a # 显示包含数字的文件名和目录名 ls *[0-9]* # 按时间排序显示文件 *** ls -lrt 4.1.4 创建目录\r1 2 3 4 5 6 # 创建一个叫做 \u0026#39;dir1\u0026#39; 的目录 mkdir dir1 # 同时创建两个目录 mkdir dir1 dir2 # 递归创建 mkdir -p /tmp/dir1/dir2 4.1.5 删除目录\r1 2 3 # 删除目录 rm -rf dir_name rmdir dir_name 4.2 文件\r1 2 3 4 5 6 # 创建文件 touch file_name # 一般可以直接 vi 保存一个空文件来创建 vi file_name # 删除文件 rm -rf file_name 4.2.1 查看文件内容\r1）cat\r1 2 3 4 5 6 # 查看内容 cat file_name # 查看内容，显示行号，包括空行 cat -n file_name # 查看内容，显示行号，不包括空行 cat -b file_name cat 重定向\r1 2 3 4 # 将文件内容追加到 新文件中 cat /etc/profile \u0026gt;\u0026gt; /home/test.txt # \u0026gt;\u0026gt; 追加 # \u0026gt; 覆盖 2）分页查看 less 及操作\r1 2 3 4 5 6 7 8 9 # 分屏显示内容 less -N file_name # 操作键\t功能 # 空格键\t显示手册页的下一屏幕 # Enter 键\t一次滚动手册页的一行 # b\t回滚一屏 向上翻屏 # f\t向前一屏 向下翻屏 # q\t退出 # /word\t搜索 word 字符串\tn 向下找 N 向上找 3）查看前N行内容 head\r1 2 # 看前 n 行内容 head -n file_name 4）查看最后N行内容 tail\r1 2 # 查看后 10 行内容，并自动追加更新日志信息 tail -fn 10 file_name 4.2.2 查找文件内容\r1 2 3 # 使用 grep grep \u0026#34;09:30*\u0026#34; /var/log/messages grep -10 \u0026#34;checkpoint\u0026#34; dm_DMSERVER_202407.log 1）清空文件内容\r1 2 3 4 # 方式一 重定向覆盖 \u0026gt;/path/to/file_name # 方式二 truncate -s 0 /path/to/file_name 4.2.3 查找文件\r1）whereis \\ which\r1 2 3 4 5 6 7 8 [root@FXQ-YWYY-57-81 ~]# whereis java # 使用 which java 也行 java: /usr/bin/java /usr/lib/java /etc/java /usr/share/java /usr/java/jdk1.8.0_231/bin/java /usr/share/man/man1/java.1.gz [root@FXQ-YWYY-57-81 ~]# ls -lrt /usr/bin/java lrwxrwxrwx 1 root root 22 Jun 6 2023 /usr/bin/java -\u0026gt; /etc/alternatives/java [root@FXQ-YWYY-57-81 ~]# ls -lrt /etc/alternatives/java lrwxrwxrwx 1 root root 73 Jun 6 2023 /etc/alternatives/java -\u0026gt; /usr/lib/jvm/java-1.8.0-openjdk-1.8.0.272.b10-7.ky10.aarch64/jre/bin/java 2）find\r1 2 3 4 5 6 7 8 9 10 [root@learning /]# find / -name \u0026#34;dm.ini\u0026#34; /home/dmdba/data/DAMENG/dm.ini find /path -option file_name # -option: # -name 找名字 # -type 找类型 # -size 找大小 # 在当前路径查找 find . -name *file_name* 4.2.4 创建文件\r1 2 3 4 5 6 # 递归创建 touch -p /path/to/dir/file_name # 创建多个文件 touch file_name_1 file_name_2 file_name_3 # 使用 vi 创建空文件 vi file_name 4.2.5 删除文件\r1 rm -rf file_name 4.3 复制\r1 2 3 4 5 6 7 # 复制目录 cp /path/dir_name /path/to/new/dir_name # 复制到当前目录 cp /path/dir_name . # 复制文件 cp file_name file_new_name 4.4 移动与重命名\r1 2 3 4 # 重命名 mv dir_name dir_new_name # 移动到别处 mv /path/to/dir_name /path/to/new/dir_name 4.5 软硬链接\r1 2 3 4 # 创建一个指向文件或目录的软链接 ln -s file_name lnk_name # 创建一个指向文件或目录的物理链接 ln file_name lnk_name 4.6 权限相关\r4.6.1 更改所属组\r1 2 # 更改所属主、组； -R 递归 chown -R user_name:group_name dir_name 4.6.2 更改目录、文件权限\r1 2 3 4 5 6 7 8 9 10 # r 4 # w 2 # x 1 ## drwxrwxrwx 表示：所属主、所属组、其他用户的权限 # 给所属主读、写、执行权限，所属组给读、执行权限，其他用户给读、执行权限 chmod 755 -R /path/to/dir_name # 给执行权限 chmod +x file_name 4.7 打包、解包\r4.7.1 tar（不常用）\r1 2 3 4 5 6 7 8 9 # 创建 tar tar -cvf file_name.tar /path/to/dir_name # 指定压缩文件 tar -cvf file_name.tar file1 file2 file3 # 指定压缩 DM8_ 开头的所有文件 tar -cvf file_name.tar DM8_* # 解压 tar 到指定目录 tar -xvf file_name.tar /path/to/dir 4.7.2 tar.gz（常用）\r1 2 3 4 5 6 7 8 9 10 11 # -z 表示使用 gzip 压缩 # 将 dir_name 压缩成 tar.gz tar -czvf file_name.tar.gz /path/to/dir_name # 指定压缩文件 tar -czvf file_name.tar.gz file1 file2 file2 # 指定压缩 DM8_ 开头的所有文件 tar -czvf file_name.tar.gz DM8_* # 解压 tar.gz 到指定目录 tar -xzvf file_name.tar.gz /path/to/dir 4.7.3 tar.bz2（不常用）\r1 2 3 4 5 6 7 8 9 10 11 # -j 表示使用 bzip2 压缩 # 将 dir_name 压缩成 tar.bz2 tar -cjvf file_name.tar.bz2 /path/to/dir_name # 指定压缩文件 tar -cjvf file_name.tar.bz2 file1 file2 file2 # 指定压缩 DM8_ 开头的所有文件 tar -cjvf file_name.tar.bz2 DM8_* # 解压 tar 到指定目录 tar -xjvf file_name.tar.bz2 /path/to/dir 4.7.4 zip\r1 2 3 4 5 6 7 # 压缩成 zip 格式 zip file.zip /path/to/dir_name # 将目录一起压 zip -r file.zip /path/to/dir_name # 解压 zip unzip file.zip /path/to/dir_name 5 进程服务相关\r5.1 查看进程\r1 2 3 4 5 6 # 查看当前所有进程 ps -ef # 查看特定进程 ps -ef | grep server_name # 查看指定用户的所有进程 ps -u user_name 5.2 结束进程\r1 2 3 4 5 6 # 一般使用 kill # -9 强制结束 kill -9 server_pid # systemctl systemctl stop service.service 5.3 设置自启\r1 2 # systemctl systemctl enable server_name.service 设置之前，需要将服务在系统里进行注册，需要自己生成一个名称\n1 vi /etc/systemd/system/server_name.service 具体百度一下，还有其他不同的自启方式的\n5.4 启动 jar 包服务\r1 2 3 4 # 直接启用 java -jar jar_name.jar # 加上 JVM 参数 java -jar jar_name.jar -Xmx1024m -Xms512m 5.5 后台运行\r1 nohup server_name \u0026amp; 6 网络相关\rlinux网卡配置文件默认地址：/etc/sysconfig/network-scripts/ifcfg-eth0 ，一般ifcfg-eth0表示第一块网卡，eth1 为第二块，以此类推。\n6.1 验证网络是否通\r1 2 3 4 # ping ping ip # telnet 用于验证端口是否打通 telnet ip port 6.2 查看网络\r1 systemctl status network 查看 IP\r1 2 3 4 5 6 7 8 9 10 11 12 13 ip addr # 有的是 ipconfig # 最快的方式 [root@status shell]# hostname -I 172.16.101.182 # 可以这么查 [root@kylinV10arm162 aml_updatePatch]# hostname -i | awk {\u0026#39;print $2\u0026#39;} 10.6.7.162 # 也可以这么查 ip -f inet addr | grep -v 127.0.0.1 | grep inet | grep -o \u0026#39;inet[^/]*\u0026#39; | awk {\u0026#39;print $2\u0026#39;} 6.3 查看端口占用\r1 netstat -nltp 6.4 查看主机名\r1 hostname 修改主机名\r1 2 3 4 5 6 vi /etc/hostname # 找到主机名的那一行，修改它 # 需要重启机器生效 # 临时设置主机名 host new_hostname 6.5 设置 hosts\r1 2 3 4 5 6 7 8 vi /etc/hosts # 添加以下内容 ip 域名 # 或者 ip hostname # 可重启网络，不过一般它是立即生效的，不需要重启 systemctl restart network 6.6 设置 DNS\r1 2 3 4 5 vi /etc/resolv.conf # 添加，其中 nameserver 为固定写法 nameserver ip # 例子 nameserver 8.8.8.8 6.7 防火墙\r1 2 3 4 5 6 systemctl status firewalld\t# 状态 systemctl start firewalld\t# 启动 systemctl stop firewalld\t# 停止 systemctl restart firewalld\t# 重启 systemctl disable firewalld\t# 禁止自启 systemctl enable firewalld\t# 开机自启 可以这么检查\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 [root@learning ~]# systemctl status firewalld.service # 状态 ● firewalld.service - firewalld - dynamic firewall daemon Loaded: loaded (/usr/lib/systemd/system/firewalld.service; disabled; vendor preset: enabled) Active: inactive (dead) Docs: man:firewalld(1) [root@learning ~]# firewall-cmd --list-all FirewallD is not running # 或者 [root@learning ~]# systemctl status firewalld.service # 状态 ● firewalld.service - firewalld - dynamic firewall daemon Loaded: loaded (/usr/lib/systemd/system/firewalld.service; disabled; vendor preset: enabled) Active: inactive (dead) Docs: man:firewalld(1) 7 包管理\r7.1 rpm\r1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 # 查看已安装 rpm 包 rpm -qa # 查看特定的包 rpm -qa | grep rpm_name # 安装 rpm 包； -i 是 install 的意思，vh是显示进度详情 rpm -ivh rpm_name # 忽略依赖，强制安装； --nodeps 忽略以来 --force 强制覆盖 rpm -ivh --nodeps --force rpm_name # 更新 rpm 包 rpm -Uvh rpm_name # 卸载 rpm -e rpm_name # 删除系统自带 JDK 为例 rpm -qa | grep -i java | xargs -nl rpm -e --nodeps 7.2 yum\r1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 # 下载 yum install -y package_name # 更新 yum update package_name # 卸载 yum remove package_name # 搜索 yum search package_name # 已安装的清单 yum list installed [package_name] # 可安装的清单 yum list available [package_name] # 可更新的清单 yum list updates # 清除缓存 yum clean all # 刷新缓存 yum makecache # 验证 yum repolist 7.2.1 更换 yum 源\r阿里云 Centos 7.9 的包\nhttps://mirrors.aliyun.com/centos/7.9.2009/os/x86_64/Packages/?spm=a2c6h.25603864.0.0.23ca4ecbejPOxR\n需要使用 wget命令下载，当服务器没有这个命令的时候，到开源站下载 wget包\n1 2 3 4 5 6 # 下载 yum 源 wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repo # 清缓存 yum clean all # 重新加载 yum 缓存 yum makecache 7.3 wget\r8 三剑客 grep\\sed\\awk\r8.1 grep\rgrep是Linux里一个文本搜索工具，能够使用通配符和正则表达式搜索文本，并将匹配的行打印出来\n1 2 3 4 5 6 7 8 9 # 统计总行数 [root@status log]# cat dm_DMSERVER_202407.log | grep -c INFO 28047 # 不区分大小写查找 INFO cat dm_DMSERVER_202407.log | grep -i info # 匹配所有含有大写字母和数字的行 cat dm_DMSERVER_202407.log | grep [A-Z][0-9] 8.1.1 常用参数\r1 2 3 4 5 6 7 8 -a\t# 以文本文件方式搜搜 -c\t# 计算匹配行的数量 -i\t# 忽略大小写 -n\t# 输出行号 -v\t# 反向选择，即排除匹配的行 -h\t# 查询多文件时不显示文件名 -l\t# 查询多文件时只输出包含匹配符的文件名 -s\t# 不显示不存在或无匹配文本的错误信息 例子：\n1 2 3 4 [root@status ~]# ps -ef | grep -in dm 73:dmdba 5510 1 0 Jun24 ? 00:01:19 /home/dmdba/dmdbms/bin/dmap 79:dmdba 16636 1 0 Jun24 ? 00:23:07 /home/dmdba/dmdbms/bin/dmserver path=/home/dmdba/data/DAMENG/dm.ini -noconsole 89:root 22552 22507 0 22:28 pts/0 00:00:00 grep --color=auto -in dm 通配符和正则表达式是两个不同的概念\n8.1.2 通配符\r1 2 3 4 5 6 7 8 *\t# 表示 N 个字符（数字） ?\t# 匹配任意一个字符 # # 注释 |\t# 管道符 ;\t# 多个命令连续执行 \u0026amp;\t# 后台运行命令 []\t# 内容范围，匹配括号中的内容 {}\t# 命令块，多个命令匹配 8.1.3 正则表达式\r1 2 3 4 5 6 7 8 9 10 *\t# 匹配 n 次 .\t# 匹配除了换行符以外的任意一个字符 .*\t# 任意字符 ^\t# 匹配行的开头，即以某个字符开头 $\t# 匹配行的结尾，即以某个字符结尾 []\t# 匹配括号里的任意指定字符（只匹配一个字符） [^]\t# 匹配出了中括号以外的任意一个字符 \\\t# 转义 \\s\t# 匹配任何空白字符 \\d\t# 匹配一个数字字符 8.2 sed\r原始test.sh脚本\n1 2 3 4 5 6 7 8 9 #!/bin/bash ############## # author: wq # create_date: 20240712 # mark: test ############## echo \u0026#34;localhost: 127.0.0.1\u0026#34; 8.2.1 替换文本\r1 2 3 4 5 6 # 模板 sed -i \u0026#39;s/old/new/g\u0026#39; file # 例子 # 将文件里的 127.0.0.1替换为 192.168.0.1 sed -i \u0026#39;s/127.0.0.1/192.168.0.1/g\u0026#39; test.sh 8.2.2 添加文本\ra参数表示在其下一行添加字符串\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 sed -i \u0026#39;/text/a new_text\u0026#39; file # 例子 # 在文件里找到 localhost 所在的行，并在其下一行添加# hello, world sed -i \u0026#39;/localhost/a # hello, world\u0026#39; test.sh # 例子 # 找到的每个字符，都会在下边加新的 [root@status log]# sed -i \u0026#39;/localhost/a # hello, world\u0026#39; test.sh [root@status log]# sed -i \u0026#39;/localhost/a # hello, world\u0026#39; test.sh [root@status log]# sed -i \u0026#39;/localhost/a # hello, Gopher \u0026#39; test.sh [root@status log]# sed -i \u0026#39;/hello/a # ??? \u0026#39; test.sh [root@status log]# vi test.sh #!/bin/bash ############## # author: wq # create_date: 20240712 # mark: test ############## echo \u0026#34;localhost: 192.168.0.1\u0026#34; # hello, Gopher # ??? # hello, world # ??? # hello, world # ??? i参数表示在其上一行添加字符串\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 [root@status log]# sed -i \u0026#39;/Go/i 111\u0026#39; test.sh [root@status log]# vi test.sh #!/bin/bash ############## # author: wq # create_date: 20240712 # mark: test ############## echo \u0026#34;localhost: 192.168.0.1\u0026#34; 111 # hello, Gopher # ??? # hello, world # ??? # hello, world # ??? 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 $`表示行尾，`\u0026amp;`表示添加。在 `111` 的行尾添加 `word [root@status log]# sed \u0026#39;s/111$/\u0026amp; word/g\u0026#39; test.sh #!/bin/bash ############## # author: wq # create_date: 20240712 # mark: test ############## echo \u0026#34;localhost: 192.168.0.1\u0026#34; 111 word # hello, Gopher # ??? # hello, world # ??? # hello, world # ??? ^表示行首，\u0026amp;表示添加，在 111的行首添加 #：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 [root@status log]# sed \u0026#39;/111/s/^/\u0026amp;# /\u0026#39; test.sh #!/bin/bash ############## # author: wq # create_date: 20240712 # mark: test ############## echo \u0026#34;localhost: 192.168.0.1\u0026#34; # 111 # hello, Gopher # ??? # hello, world # ??? # hello, world # ??? 8.2.3 删除文本\r1 2 3 4 5 6 7 8 9 10 11 12 13 14 # 删除第1行 sed \u0026#39;1d\u0026#39; test.sh # 删除第3 - 8行 sed \u0026#39;3,8d\u0026#39; test.sh # 删除最后一行 sed \u0026#39;$d\u0026#39; test.sh # 删除匹配111的那一行 sed \u0026#39;/111/ d\u0026#39; test.sh # 删除匹配行到最后一行 sed \u0026#39;/111/ $d\u0026#39; test.sh 8.3 awk\r打印输出信息，并输出第一列参数\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 [root@status log]# df -h Filesystem Size Used Avail Use% Mounted on devtmpfs 868M 0 868M 0% /dev tmpfs 879M 0 879M 0% /dev/shm tmpfs 879M 556K 878M 1% /run tmpfs 879M 0 879M 0% /sys/fs/cgroup /dev/vda1 40G 8.7G 29G 24% / tmpfs 176M 0 176M 0% /run/user/0 [root@status log]# df -h | awk \u0026#39;{print $1}\u0026#39; Filesystem devtmpfs tmpfs tmpfs tmpfs /dev/vda1 tmpfs 如果是打印第一列和第二列，则是 awk '{print $1,$2}' 用逗号分隔\n9 VI 编辑器\r1 2 3 4 5 6 7 8 9 10 11 12 # vi 或者 vim # 分为3个模式：命令模式、输入模式、底行模式 # 进入 vi 的默认界面就是 命令模式 i\t# 进入输入模式，光标前一个字符开始 a # 同上，光标后一个字符开始 o # 同上，在光标的下一行开始 esc # 返回命令模式 :\t# 进入底行模式 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 # 命令模式 /find_text\t# 查找文本 n\t# 向下查找 N\t# 向上查找 # 常用操作 w\t# 跳到下一个单词的开始 b\t# 跳到上一个单词的开始 # 复制贴贴 v\t# 按 v 开始选择，选择后 y 复制， p 贴贴 # 删除 dd\t# 删除光标所在行 :n1,n2d\t# 删除 n1 - n2 行 # 例子 :3,7d # 撤销 u\t# 撤销操作，跟 windows 的 ctrl+z 一样效果 ctrl + r # 重做撤销 # 替换 :n1,n2 s/old_text/new_text/g # 例子：替换11行的localhost为hostname\t如果不加行号则为全局替换 :11 s/localhost/hostname/g 1 2 3 4 5 6 # 底行模式 :set nu\t# 显示行号 :set nonu\t# 不显示行号 :w\t# 保存 :wq\t# 保存并退出 :q!\t# 不保存并退出 10 文件传输\r1 2 3 4 scp /home/dm/dmdata/dm.ini ip:/home/dm/dmdata/ # 复制所有该目录下所有内容，递归 scp -r /home/dm/dmdata/dm.ini ip:/home/dm/dmdata/ 其他\r1 管道符 |\r|可以将一个命令的输出作为另一个命令的输入\n举例：\n1 2 3 4 5 6 7 # 查看当前目录下的文件和文件夹梳理 # 通过 ls -l 列出当前路径下所有文件、目录，让后计算它们的数量 ls -l | wc -l # 查看当前运行的dm进程 # -i 不区分大小写 ps -ef | grep -i dm 2 重定向\r2.1 重定向清空文件内容\r1 2 # 把空内容覆盖写入文件，达到清空文件内容的效果 \u0026gt;file_name 2.2 重定向介绍\r1 2 3 \u0026lt;file_name\t# 将文件内容作为标准输入传递给命令 \u0026gt;file_name\t# 将命令的输出覆盖写入文件里 \u0026gt;\u0026gt;file_name\t# 将命令的输出追加写入文件里 3 echo\r输出内容\n1 2 3 # 输入变量 echo $JAVA_HOME echo $PATH 4 配置环境变量\r环境变量通常配置在 /etc/profile``~/.bash_profile文件里\n1 2 3 4 5 6 7 8 9 10 11 vi /etc/profile # 添加 export JAVA_HOME=/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.272.b10-7.ky10.aarch64 export JRE_HOME=/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.272.b10-7.ky10.aarch64/jre export CLASSPATH=.:$JAVA_HOME/lib:$JRE_HOME/lib export PATH=$JAVA_HOME/bin:$PATH # 保存后刷新环境变量生效 source /etc/profile # 验证 echo $JAVA_HOME 5 命令别名 allas\r配置 别名 是为了方便自己，比如对命令别名、封装函数等进行配置。\n它有两个文件 /etc/bashrc ~/.bashrc，一个是全局生效，一个对当前用户生效\n1 2 3 4 5 6 7 8 9 10 11 12 13 # 进入编辑 vi /etc/bashrc # 添加 alias llt=\u0026#39;ls -lrt\u0026#39; alias nst=\u0026#39;netstat -ntlp\u0026#39; # 保存后刷新 source /etc/bashrc # 输入 llt，就会执行 ls -lrt 命令（该命令为将当前目录的内容安装时间顺序显示出来） # 输入 nst，就会执行 netstat -ntlp # 别名不能与现有命令重复，别名应当唯一 # 查看所有的别名 alias 封装函数的用法：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 # 进入编辑 vi /etc/bashrc vi /etc/bashrc # 添加 function func_name() { ps -ef | grep -i $1 } # 保存后刷新 source /etc/bashrc # 调用 func_name java # 调用函数会直接显示 ps -ef | grep -i java 命令的信息，比如下边 UID PID PPID C STIME TTY TIME CMD user1 1234 1233 0 2023-09-14 10:00:00 pts/0 00:01:23 java -jar myapp.jar ","date":"2024-07-11T22:21:07+08:00","permalink":"http://localhost:1313/posts/2024/07/linux-%E5%91%BD%E4%BB%A4%E6%95%B4%E7%90%86%E5%85%A8/","title":"Linux-命令整理（全）"},{"content":"在信创项目上，因为服务器通常是linux 操作系统，所以对linux命令也是经常需要使用。根据实际的项目里，需要经常使用到的linux 命令，做一个总结 。\nlinux基础命令\r1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 # dir 指目录 # file 指文件 # path 指路径 # 列出当前目录所有内容 ll # 移动 cd /path/dir_name # 返回上级目录 cd .. # 返回上个目录 cd - # 显示当前路径 pwd # 查看文件内容 cat cat /path/file_name # 查看文件末尾 N 行内容，并实时显示文件追加内容 tail -fn N file_name # 创建目录 mkdir -p /path/to/create_dir_name # 创建文件 touch file_name # 可以使用 vi 编辑空文件保存，也是一个新文件 vi file_name # 删除目录、文件 rm -rf dir_name rm -rf file_name # 解压 tar.gz tar -xzvf file.tar.gz # 复制 cp /path/dir_name /path/to/new_dir_name cp -r /path/dir_name /path/to/new_dir_name # 移动 mv /path/dir_name /new_path/to/dir_name # 重命名 mv /path/dir_name /path/new_dir_name # 杀掉进程 kill -9 pid 上述都是基础，当然下边也是基础。\n但是根据我在实际工作中，一个应用的部署过程来做的总结，包括前期应用的搭建，到后期应用服务运维，从一整个项目实施部署的过程，来梳理实际工作中应该掌握哪些命令。\n项目过程中常用命令\r验证网络\r先验证应用服务器与数据库服务器网络是否开通，没有开通则沟通走流程开通\n1 2 ping ip telnet ip port 配置 Hosts\r当 ping telnet 无法找到对应的主机名或服务时，可以配置 hosts\n1 2 3 4 5 6 7 8 9 # 获取 ip ip addr # 获取主机名 hostname # 编辑 vi /etc/hosts # 添加 ip hostname 配置 DNS\r在项目上，有时候客户不提供 hosts，而是提供 DNS，比如对接邮箱服务的时候提供一个邮箱服务器的 DNS。\n1 2 3 4 5 6 7 # 编辑 DNS 文件 vi /etc/resolv.con # 添加：nameserver 为固定写法 nameserver ip # 例子 nameserver 127.0.0.1 nameserver www.baidu.com 创建用户\r在项目部署时，客户的生产环境是不会提供 root 用户的，测试环境上，需要自己创建相关的中间件、数据库用户，然后使用这个用户进行操作，能够使应用服务在测试和生产环境中保持一致的运行情况。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 # 1.创建用户组 groupadd -g group_name # 例子 groupadd -g dmdba # 2.创建用户 useradd -g group_name -s /bin/bash -d /home/dir_name -m user_name # -g：指定用户所属组 # -s：指定用户用的 shell # -d：指定用户的根目录路径 # -m：创建用户的根目录 # 例子,创建 dmdba 用户，并设置用户 ID\\所属组\\指定 SHELL\\指定根目录并创建根目录： useradd -g dmdba -s /bin/bash -d /home/dm -m dmdba # 3.更改用户主、组 chown dmdba:dmdba /home/dm # 4.修改用户密码 passwd user_name 修改权限\r在创建用户后，通常会创建一些目录，用来存放应用包，或者用来安装应用服务。\n如果使用root创建了目录，是需要修改这些目录的权限的\n1 2 3 4 5 6 # 创建目录 mkdir -p /home/dm # 更改目录所属主、组 chown dmdba:dmdba -R /home/dm # 更改目录权限 chmod 755 -R /home/dm 解包\r在创建好目录后，上传应用包，一般为tar.gz 或者 zip\n1 2 3 4 5 6 7 # 解压 tar 包到当前目录 tar -xzvf file.tar.gz # 解压 tar 包到指定目录 tar -xzvf file.tar.gz /path/to/dir_name # 解压 zip 包 unzip file.zip 挂载\r因为有的安装包，是提供一个 iso 镜像文件的，在 linux 里需要先挂载 iso 文件，里边有安装 .sh 脚本\n1 2 # 挂载 iso 文件，主要挂载目录需要用户能访问，一般在应用主目录下创建一个挂载目录 mount -o loop file_name.iso /home/dm/mnt 配置环境变量\r通常的项目是个 java 构建的应用，需要使用 JDK 。如果服务器上没有安装 JDK 包就需要先安装，不过现在发行版的LINUX都是自带了openJDK ，需要根据JDK 的路径去配置环境变量。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 # 通常情况下，我们是不知道一个新服务器的java安装路径在哪里的，所以我们可以通过命令查找 # 先看是否安装 java -version # 有则找 java 路径，这么找： # whereis java 或者 which java 都可以 [root@FXQ-YWYY-57-81 ~]# whereis java java: /usr/bin/java /usr/lib/java /etc/java /usr/share/java /usr/java/jdk1.8.0_231/bin/java /usr/share/man/man1/java.1.gz [root@FXQ-YWYY-57-81 ~]# ls -lrt /usr/bin/java lrwxrwxrwx 1 root root 22 Jun 6 2023 /usr/bin/java -\u0026gt; /etc/alternatives/java [root@FXQ-YWYY-57-81 ~]# ls -lrt /etc/alternatives/java lrwxrwxrwx 1 root root 73 Jun 6 2023 /etc/alternatives/java -\u0026gt; /usr/lib/jvm/java-1.8.0-openjdk-1.8.0.272.b10-7.ky10.aarch64/jre/bin/java # 知道了 java 的路径，就可以配置环境变量 # 配置环境变量有两个文件： /etc/profile 全局环境变量； ~/.bash_profile 当前用户的环境变量 vi /etc/profile # 添加 export JAVA_HOME=/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.272.b10-7.ky10.aarch64 export JRE_HOME=/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.272.b10-7.ky10.aarch64/jre export CLASSPATH=.:$JAVA_HOME/lib:$JRE_HOME/lib export PATH=$JAVA_HOME/bin:$PATH # 保存后刷新环境变量生效 source /etc/profile # 验证 echo $JAVA_HOME 服务启停\r启动服务\r一般多是用后台命令启动\n1 nohup server_name \u0026amp; 启动 java 程序\r有的项目需要单独启动某个 jar 包\n1 java -jar file.jar 查看服务状态\r1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 ps -ef | grep app_name # 例子 ps -ef | grep java # 将 ps -ef 命令的输出结果作为 grep java 的输入 # ps -ef 会查出所有运行的进程，grep java 则在这些进程里查找有关 java 的进程 # 返回的信息解释 # user 进程归属用户 # PID 进程 ID # CPU CPU 使用率 # MEM 内存使用率 # STAT 进程状态（R 运行 S 睡眠 Z 卡死） # START 进程开始运行时间 # TIME 进程运行时间 # COMMAND 进程执行的命令 关闭防火墙\r应用服务如果起来了，但是前台地址打不开的情况，拒绝访问或者无相应。需要关闭防火墙\n1 2 3 4 # 关闭 systemctl stop firewalld # 禁止自启（可操作也可不操作，不操作的话，机器重启会自启防火墙） systemctl disable firewalld 查看端口占用情况\r项目上，可能存在端口冲突的情况，比如说某个服务关闭异常导致服务关了但是端口没释放，可排查端口由哪个pid 占用着，将它 kill 掉释放端口\n1 2 3 4 5 6 natstat -ntlp # -n 显示地址、端口号 # -t 显示 tcp 连接信息 # -l 显示监听 # -p 显示进程 追踪日志\r在排查问题过程中，经常需要看日志。\n可以直接实时查看日志，看看哪一步报错\n1 tail -fn 200 file.log 也可以使用重定向，将日志先清空，避免冗余信息过多，然后再追踪日志\n1 2 3 # \u0026gt; 其实是个重定向，这个命令就是把前边的空内容以覆盖的方式输入到文件里，达到删除效果 \u0026gt;file.log tail -fn 200 file.log 查看服务器资源占用情况\r1 2 3 4 5 6 # top 实时查看资源情况 top # 查看内存情况 free -h # 查看磁盘情况 df -h 查看历史命令\r1 2 # 显示历史执行过的命令 history 判断命令是否被拉起\r1 2 # 服务器发送请求，判断应用是否被拉起，当操作机与服务器存在网络问题时可用此判断，如果不能访问，排查操作机的网络与服务器 IP 是否通 curl URL 常见报错\rNo such file or directory\r执行 shell 脚本的是，可能会遇到这个报错，完整的报错类似下边：\n1 2 3 /bin/sh: bad interpreter: No such file or directory # 或者 /usr/bin/env: \u0026#34;sh\\r\u0026#34;: 没有那个文件或目录 是因为编写 shell 脚本时，使用的文本编辑器，它用的换行符是 dos ，在 shell 里的换行符应该需要更改为 unix ，如下设置\n1 2 3 vi file.sh :set ff=unix\t# :set ff 可以查看当前 shell 脚本的换行符是 dos 还是 unix :wq\t# 保存 Permission denied\r就是因为权限的原因。在测试环境中使用了 root 用户操作，具有系统所有权，所以操作什么都不会报错。但是到了生产环境，一般是没有 root 的权限的，所以当执行一些需要用到 root 权限的命令时，就会报错。\n通常是因为 shell 脚本中，存在授权 chmod 、创建软链 ln -s 等命令。\nEND","date":"2024-07-10T21:25:13+08:00","permalink":"http://localhost:1313/posts/2024/07/linux-%E5%B7%A5%E4%BD%9C%E4%B8%AD%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%80%BB%E7%BB%93/linux-%E5%B7%A5%E4%BD%9C%E4%B8%AD%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E6%80%BB%E7%BB%93/","title":"Linux-工作中常用命令总结与常见错误"},{"content":"一般通过修改磁盘分区来增加 swap 分区空间，只是单纯的调整swap空间会占用物理内存。\n修改磁盘分区\r1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 # 查看各分区信息 [root@FXQ-YWYY-57-81 dev]# fdisk --l Disk /dev/vda: 50 GiB, 53687091200 bytes, 104857600 sectors Units: sectors of 1 * 512 = 512 bytes Sector size (logical/physical): 512 bytes / 512 bytes I/O size (minimum/optimal): 512 bytes / 512 bytes Disklabel type: gpt Disk identifier: 55A9D713-559A-436B-BA30-299A54040073 Device Start End Sectors Size Type /dev/vda1 2048 1230847 1228800 600M EFI System /dev/vda2 1230848 3327999 2097152 1G Linux filesystem /dev/vda3 3328000 70436863 67108864 32G Linux filesystem /dev/vda4 70436864 103991295 33554432 16G Linux swap Disk /dev/vdb: 500 GiB, 536870912000 bytes, 1048576000 sectors Units: sectors of 1 * 512 = 512 bytes Sector size (logical/physical): 512 bytes / 512 bytes I/O size (minimum/optimal): 512 bytes / 512 bytes Disklabel type: dos Disk identifier: 0x93389753 Device Boot Start End Sectors Size Id Type /dev/vdb1 2048 1048575999 1048573952 500G 83 Linux Disk /dev/loop0: 3.94 GiB, 4202692608 bytes, 8208384 sectors Units: sectors of 1 * 512 = 512 bytes Sector size (logical/physical): 512 bytes / 512 bytes I/O size (minimum/optimal): 512 bytes / 512 bytes 1 删除磁盘分区\r如果删除磁盘分区，这部分空间并不会被显示，而是属于未使用的状态，不会计入 df -h 返回的结果（它返回的是已经挂载了的可用空间）。需将这部分空间重新分配到新的分区。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 # 使用 fdisk 命令，后边接 分区名 [root@FXQ-YWYY-57-81 /]# fdisk /dev/vda Welcome to fdisk (util-linux 2.35.2). Changes will remain in memory only, until you decide to write them. Be careful before using the write command. # 列出当前分区信息 Command (m for help): p Disk /dev/vda: 50 GiB, 53687091200 bytes, 104857600 sectors Units: sectors of 1 * 512 = 512 bytes Sector size (logical/physical): 512 bytes / 512 bytes I/O size (minimum/optimal): 512 bytes / 512 bytes Disklabel type: gpt Disk identifier: 55A9D713-559A-436B-BA30-299A54040073 Device Start End Sectors Size Type /dev/vda1 2048 1230847 1228800 600M EFI System /dev/vda2 1230848 3327999 2097152 1G Linux filesystem /dev/vda3 3328000 70436863 67108864 32G Linux filesystem /dev/vda4 70436864 103991295 33554432 16G Linux swap # 删除命令，选择第四个分区，按顺序来的 Command (m for help): d Partition number (1-4, default 4): 4 Partition 4 has been deleted. # w 是保存退出 Command (m for help): w The partition table has been altered. Syncing disks. 2 新增磁盘分区\r1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 # 使用 fdisk 磁盘管理命令 [root@FXQ-YWYY-57-81 ~]# fdisk /dev/vda Welcome to fdisk (util-linux 2.35.2). Changes will remain in memory only, until you decide to write them. Be careful before using the write command. Command (m for help): p Disk /dev/vda: 50 GiB, 53687091200 bytes, 104857600 sectors Units: sectors of 1 * 512 = 512 bytes Sector size (logical/physical): 512 bytes / 512 bytes I/O size (minimum/optimal): 512 bytes / 512 bytes Disklabel type: gpt Disk identifier: 55A9D713-559A-436B-BA30-299A54040073 Device Start End Sectors Size Type /dev/vda1 2048 1230847 1228800 600M EFI System /dev/vda2 1230848 3327999 2097152 1G Linux filesystem /dev/vda3 3328000 70436863 67108864 32G Linux filesystem Command (m for help): m Help: GPT M enter protective/hybrid MBR Generic d delete a partition\t# 删除 F list free unpartitioned space l list known partition types n add a new partition\t# 新增 p print the partition table t change a partition type\t# 更改分区类型 v verify the partition table i print information about a partition Misc m print this menu x extra functionality (experts only) Script I load disk layout from sfdisk script file O dump disk layout to sfdisk script file Save \u0026amp; Exit w write table to disk and exit q quit without saving changes Create a new label g create a new empty GPT partition table G create a new empty SGI (IRIX) partition table o create a new empty DOS partition table s create a new empty Sun partition table # 新增 n ，内存取默认就行 Command (m for help): n Partition number (4-128, default 4): 4 First sector (70436864-104857566, default 70436864): Last sector, +/-sectors or +/-size{K,M,G,T,P} (70436864-104857566, default 104857566): Created a new partition 4 of type \u0026#39;Linux filesystem\u0026#39; and of size 16.4 GiB. Partition #4 contains a swap signature. # 默认 y Do you want to remove the signature? [Y]es/[N]o: y The signature will be removed by a write command. # 保存 Command (m for help): w The partition table has been altered. Syncing disks. # 让内核重新读取分区信息 [root@FXQ-YWYY-57-81 ~]# partprobe -s /dev/vdb: msdos partitions 1 Warning: Unable to open /dev/sr0 read-write (Read-only file system). /dev/sr0 has been opened read-only. /dev/sr0: msdos partitions /dev/vda: gpt partitions 1 2 3 4 # 格式化分区，注意这是 filesystem 类型的分区格式化 [root@FXQ-YWYY-57-81 dev]# mkfs.xfs -f /dev/vda4 meta-data=/dev/vda4 isize=512 agcount=4, agsize=1075647 blks = sectsz=512 attr=2, projid32bit=1 = crc=1 finobt=1, sparse=1, rmapbt=0 = reflink=1 data = bsize=4096 blocks=4302587, imaxpct=25 = sunit=0 swidth=0 blks naming =version 2 bsize=4096 ascii-ci=0, ftype=1 log =internal log bsize=4096 blocks=2560, version=2 = sectsz=512 sunit=0 blks, lazy-count=1 realtime =none extsz=4096 blocks=0, rtextents=0 2.1 调整磁盘分区为 swap 分区\r1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 [root@FXQ-YWYY-57-81 ~]# fdisk /dev/vda Welcome to fdisk (util-linux 2.35.2). Changes will remain in memory only, until you decide to write them. Be careful before using the write command. Command (m for help): p Disk /dev/vda: 50 GiB, 53687091200 bytes, 104857600 sectors Units: sectors of 1 * 512 = 512 bytes Sector size (logical/physical): 512 bytes / 512 bytes I/O size (minimum/optimal): 512 bytes / 512 bytes Disklabel type: gpt Disk identifier: 55A9D713-559A-436B-BA30-299A54040073 Device Start End Sectors Size Type /dev/vda1 2048 1230847 1228800 600M EFI System /dev/vda2 1230848 3327999 2097152 1G Linux filesystem /dev/vda3 3328000 70436863 67108864 32G Linux filesystem # 更改分区类型为 swap Command (m for help): t Partition number (1-4, default 4): 4 Partition type (type L to list all types): 19 # 保存 Command (m for help): w The partition table has been altered. Syncing disks. # 让内核重新读取分区信息 [root@FXQ-YWYY-57-81 ~]# partprobe -s /dev/vdb: msdos partitions 1 Warning: Unable to open /dev/sr0 read-write (Read-only file system). /dev/sr0 has been opened read-only. /dev/sr0: msdos partitions /dev/vda: gpt partitions 1 2 3 4 # 格式化分区 [root@FXQ-YWYY-57-81 dev]# mkswap /dev/vda4 # 挂载分区 [root@FXQ-YWYY-57-81 dev]# swapon /dev/vda4 # 验证 [root@FXQ-YWYY-57-81 dev]# swapon --show NAME TYPE SIZE USED PRIO /dev/vda4 partition 16.4G 0B -2 # 设置开机自启 [root@FXQ-YWYY-57-81 dev]# vi /etc/fstab # 加入 UUID=9b6af8bf-5a7a-4e6b-8e2e-4afa78cf5bbc none swap defaults 0 0 # 如果不清楚 UUID 可设置为它文件的路径 /dev/vda4 none swap defaults 0 0 # 查看 UUID 也是可以的 [root@FXQ-YWYY-57-81 dev]# blkid /dev/vda4 /dev/vda4: UUID=\u0026#34;1be2cafb-87e7-4539-8035-76f6d6afe54b\u0026#34; TYPE=\u0026#34;swap\u0026#34; PARTUUID=\u0026#34;76bd885e-c19a-c04b-bdec-9374a1515872\u0026#34; 更改 swap 分区空间\r当服务器使用了默认的 swap 交换区，空间过大时，为了避免留给应用的物理内存太小导致应用服务器运行性能不好，可以如下进行操作，对 swap 区进行缩减。缩减还是增加，其实都是通过新增一个小（大）的新 swap 文件，把这个文件格式化为 swap 空间，然后卸掉原来的 swap 空间，启用新的 swap 空间。\n但是它本身使用的是一部分物理磁盘空间，用磁盘空间转为虚拟内存空间，这个 swap 跟 物理内存实际上没有关系。如果不需要分区，则直接把这个分区卸掉，然后把对应的分区文件删除即可。\n1 缩小 swap 分区空间\r1.1 查看 swap 分区\r1 2 3 4 5 6 7 8 9 10 # 查看 swap 具体是哪个 [root@linux1 ~]# swapon -s 文件名 类型 大小 已用 权限 /dev/dm-1 partition 4063228 0 -2 # 或者这么查 [root@linux1 ~]# cat /proc/swaps Filename Type Size Used Priority /dev/dm-1 partition 4063228 0 -2 能看出，swap 交换分区的路径是 /dev/dm-1\n1.2 禁用 swap 分区\r1 2 3 4 # 禁用 [root@linux1 ~]# swapoff /dev/dm-1 # 编辑 /etc/fstab 删掉 swap 分区的信息 vi /etc/fstab 然后可以看到 swap 分区可用为 0\n1 2 3 4 [root@linux1 ~]# free -h total used free shared buff/cache available Mem: 3.7G 284M 3.3G 11M 157M 3.2G Swap: 0B 0B 0B 1.3 重新创建 swap 分区\r创建 swap 分区文件\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 # 进入 /dev 目录 [root@linux1 ~]# dd if=/dev/zero of=/swapfile bs=500M count=1 记录了1+0 的读入 记录了1+0 的写出 524288000字节(524 MB)已复制，11.1731 秒，46.9 MB/秒 # /dev/zero 是 LINUX 里一个特殊块设备，在每次读取时输出零字节 # /swapfile 可以是任意路径下的文件，注意这个不用事先创建 # 授权 [root@linux1 /]# chmod 600 swapfile # 把这个文件格式化为 swap 空间 [root@linux1 /]# mkswap /swapfile 正在设置交换空间版本 1，大小 = 511996 KiB 无标签，UUID=fef44c17-e76e-4d25-8607-1546968093c0 # 激活该文件，添加到交换池中 [root@linux1 /]# swapon /swapfile # 添加该 swap 分区到配置文件里 [root@linux1 /]# vi /etc/fstab # 加入该 swap 分区信息 /swapfile swap defaults 0 0 # 验证 [root@linux1 /]# swapon --show NAME TYPE SIZE USED PRIO /swapfile file 500M 0B -3 # 删除旧的 swap 分区，不然还是会占用内存空间 rm -rf /dev/dm-1 1.3.1 当执行格式化swap空间命令时报错\r1 2 3 4 5 6 7 8 9 10 11 [root@linux2 dev]# sudo mkswap swapfile mkswap: swapfile: warning: wiping old swap signature. 正在设置交换空间版本 1，大小 = 511996 KiB 无标签，UUID=9db8a3f1-5bd5-4634-a659-94f849c0d98c mkswap: 无法将 swapfile 标签改为 unconfined_u:object_r:swapfile_t:s0: 权限不够 # 临时关闭 selinux 安全模块 setenforce 0 # 格式化完成记得把它改打开 setenforce 1 2 增加 swap 分区空间\r这部分如果不是使用的磁盘空间，会使用物理内存空间转为 swap 空间。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 [root@linux2 dev]# dd if=/dev/zero of=/dev/dm-1 bs=100M count=1 记录了1+0 的读入 记录了1+0 的写出 104857600字节(105 MB)已复制，0.20253 秒，518 MB/秒 [root@linux2 dev]# mkswap /dev/dm-1 正在设置交换空间版本 1，大小 = 102396 KiB 无标签，UUID=15a0fcd0-c122-4fd4-8ee1-c4709a3ae4a3 mkswap: 无法将 /dev/dm-1 标签改为 unconfined_u:object_r:swapfile_t:s0: 权限不够 # 关闭 sellinux [root@linux2 dev]# setenforce 0 [root@linux2 dev]# mkswap /swapfile2 正在设置交换空间版本 1，大小 = 102396 KiB 无标签，UUID=6f8da03d-85ab-4841-9508-1d5ed5937787 [root@linux2 dev]# swapon /swapfile2 swapon: /dev/dm-1：不安全的权限 0644，建议使用 0600。 [root@linux2 dev]# chmod 600 /swapfile2 [root@linux2 dev]# free -h total used free shared buff/cache available Mem: 3.7G 291M 2.6G 111M 803M 3.1G Swap: 599M 0B 599M [root@linux2 dev]# setenforce 1 # 写入 /etc/fstab vi /etc/fstab # 添加 /swapfile2 swap defaults 0 0 ","date":"2024-07-03T13:56:41+08:00","permalink":"http://localhost:1313/posts/2024/07/linux-%E6%9B%B4%E6%94%B9swap%E5%88%86%E5%8C%BA/","title":"Linux 更改swap分区"},{"content":"最近异常交易的项目中，使用到了kafka ，用来实时推送实时成交、委托流水、组合持仓、行情等等数据到自研的平台上做数据监控。那么我这边需要做的内容：将上游的数据直接推送到kafka上，给下游的应用消费kafka数据。这个过程中也遇到了一些问题，因为也是第一次接触kafka ，平且是在实际的项目中使用的，这里经验对我来说还是很宝贵的，所以在这里做一个基础知识、项目中遇到的问题、对应的解决方案的记录。在项目上主要是使用kafka 读取数据，做一个流式处理，供下游应用使用数据。\nkafka 主要组件\rbroker 服务器\rkafka集群的服务器，一台服务器就是一个 broker 。\nproducer 生产者\rproducer 主要是用于生产消息，是 kafka 当中的消息生产者，生产的消息通过 topic 进行归类，保存到 kafka 的 broker 里面去。\n项目上我们的数据平台就是作为一个生产者，通过将上游数据推送到topic里。\ntopic 主题\rkafka 将消息（数据）以 topic 为单位进行归类。在项目里边，一张表推到一个 topic ，需要推几张表就是建几个 topic 。\npartition 分区\rkafka 里，一个 topic 是可以有多个分区。比如说创建一个有 3 个分区的 topic ，那么整个 topic 的数据都存放在这 3 个分区内（就是说每个分区都存放一部分 topic 的数据）。\nconsumer 消费者\r消费者主要就是消费 kafka topic 里的数据\nconsumer group 消费者\r消费者组里可以有多个消费者，同一个组里的消费者，对于同一条数据，只能消费 1 次。\n比如：一个消费者组里有 A 和 B 两个消费者，A 消费了 topic 里的第一条数据，那么 B 就无法消费该 topic 里的第一条数据，因为已经被消费过了。\n但是不同的消费者组，还是可以共同消费某个 topic 里的数据的。\n消费者组与分区的关系\r如果 topic 只有 2 个分区，消费者组里有 4 个消费者，那么也只能供 2 个消费者消费。\n如果 topic 有 4 个分区，消费者组里的 4 个消费者都能消费数据，并发量就上来了。\n所以 topic 里的分区越多，消费的并发越高，处理速度也越快。\npartition replicas 分区副本\r每个分区的副本，用来控制数据保存在几个 broker 服务器上，通常是几台 broker 就设置几个副本。\nsegment 文件\r一个 partition 分区中由多个 segment 文件组成的。每个 segment 文件又包含了 .log 文件和.index 文件，.log 文件是存放推送的数据，.index 文件存放数据的索引值，用来加快数据的查询速度的。\n.index 文件里存的索引值，是与.log文件里的数据位置是对应的。\n1 2 3 4 # .index 是 key-value 存放方式 1,0\t# 对应 .log 的第一条数据，值是0 2,2\t# 对应 .log 的第二条数据，值是2 3,9\t# 对应 .log 的第三条数据，值是9 .log 文件里会记录offset 偏移量，用于标记消费者读取消息的位置。\nkafka 基础操作\rkafka启停\rkafka 与 zookeeper 强依赖，启动 kafka 之前必须先启动 zookeeper ，否则会报错的\n1 2 3 4 5 6 7 8 9 # zookeeper 启动，后边接配置文件 ./zookeeper-server-start.sh ../config/zookeeper.properties # zookeeper 停止 ./zookeeper-server-stop.sh # kafka 启动，后边接配置文件 ./kafka-server-start.sh ../config/server.properties # kafka 停止 ./kafka-server-stop.sh 创建 topic\r1 2 3 4 5 # 创建语句 模板 ./kafka-topics.sh --create --bootstrap-server 10.84.0.1:9092 --replication-factor 1 --partitions 1 --topic topic_name # bootstrap-server 指定 kafka 服务器地址和端口 # replication-factor 指定分区的副本个数 # partitions 指定topic的分区个数 删除 topic\r1 ./kafka-topics.sh --bootstrap-server 10.84.0.1:2181 --delete --topic topic_name 增加 topic partition\r1 ./kafka-topics.sh --zookeeper 10.84.0.1:2181 --alter --topic topic_name --partition 2 查看 topic 数据\r1 2 3 ./kafka-console-consumer.sh --bootstrap-server 10.84.0.1:9092 --topic your_topic_name --from-beginning [--max-messages 10] # --max-messages 查看几条消息 # --from-beginning 查看最新的消息 查询 topic 列表\r1 ./kafka-topics.sh --list --zookeeper localhost kafka 相关问题及解决方案\r报错 Error while fetching metadata with correlation id\r这个报错是在 kafka 查看 topic 里的数据时，出现的错误。查了下资料，它是无法识别到 hostname 导致。\n解决方案：\n修改 server.properties 配置文件，增加 listeners 。默认的配置是没有这两行的，手动加上。\n报错 exiting abnormally\r这个是在启动 zookeeper 的时候出现，报错如下图所示：\n解决方案：\n在zookeeper.properties配置文件中，有个 dataDir=/path ，把 /path 路径下的version-2 文件夹删掉，然后重新启动即可。\n报错 during kafkaserver startup\r启动 kafka 的时候出现，报错如下图所示：\n注意这个：\n由于启动的 id 和 meta.properties 里边的 id 不一致导致报错。通常是因为关闭 kafka 的时候出现了异常（虽然不知道有什么异常）\n解决方案：\n1 2 3 # 找到该文件 find / -name \u0026#34;meta.properties\u0026#34; # 修改里边的 cluster.id= 一串字符串id 修改为报错里出现的那个括号里的一串id即可。\n新增消费者组时数据显示不一致\r在做迁移的时候，为了对比迁移前后的数据量是否一致。在迁移后的环境中新增一个消费者组 B，用来消费同一个 topic 数据，发现跟迁移前的消费者组 A 的数据不一致。\n消费者组A的数据是当天的数据，但是消费者组B的数据却是几天前的。为啥？\nkafka每个消费者组都是独立消费数据，只要是消费同一个 topic，那么数据肯定是一致的。由于一般 kafka 的配置是保留 7 天的数据，所以在新增的消费者组消费同一个 topic 时，它会重头开始消费，即从所以就出现了，消费者组B里是几天前的数据，这是无可避免的。\n配置流水字段\r由于当时第一次配置的时候，没有配置流水字段，导致了推送数据到 kafka topic 的任务，每次实时推送全量数据过去，导致了数据平台每次启动推送 kafka 的任务，就会迅速占满服务器内存，然后应用挂掉。\n后边加入流水字段，将任务配置为增量推送，内存占比就好了很多。\n通常是用线性递增的字段，作为流水字段。比如，实时成交表里有成交时间，委托流水表里有委托时间。\n配置主键\r通过配置主键用来去重，避免推送重复数据到 topic 里。比如：实时成交表里的成交编号，委托流水表里的委托编号，编号是唯一的，那么可以使用编号作为主键。\n","date":"2024-06-24T22:03:22+08:00","permalink":"http://localhost:1313/posts/2024/06/kafka-%E5%9F%BA%E7%A1%80%E6%93%8D%E4%BD%9C%E4%B8%8E%E9%85%8D%E7%BD%AE/","title":"kafka-基础知识与实际项目的问题"},{"content":"本文总结Nginx在项目上的实际应用，本文包含了Nginx的常用配置与在项目中遇到的问题。信创版本的负载均衡中间件其实也是类似于Nginx，以宝兰德负载均衡中间件BWS为例。\nNginx 负载均衡，在生产环境上常常会用到。简单通俗的架构如下：\n在生产环境，通常具有多台应用服务器（一般为集群），通过 Nginx 服务器配置的地址去访问同一个应用，通过 Ng 实现应用的高并发、高可用。\nNginx基础\rNginx 的配置文件，是 Nginx_home/conf/nginx.conf 文件，它里边的结构块是这样的：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 # 全局块 # user user_name; # 运行 nginx 进程的用户名 ... # 事件块 events { ... } # http 块 http { # http 全局块 ... # server 块 server { # server 全局块 ... # upstream 块 upstream name { ... } # location 块 location [PATTERN] { ... } } } 全局块\r1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 # 全局块通常是配置用户、日志、进程、pid 等 # 注意，全局块中涉及的路径，需 nginx 有权限读写。 # 运行 nginx 进程的用户名，指 Linux 用户 user user_name; # 设置 nginx 的进程数，默认为 1，一般进程数=CPU 核数即可。双核配 2，4 核配 4. worker_processes 1; # nginx 的工作目录，不配置，默认在 logs 下 working_directory nginx_path/logs; # 设置日志级别：debug\\info\\notice\\warn\\error\\crit（高到低） error_log nginx_path/logs/error.log info; # 也可以使用默认，记录 error error_log nginx_path/logs/error.log # pid，设置 nginx 进程的 pid 文件路径和名称 pid nginx_path/logs/nginx.pid; 全局块，通常配置 user worker_processes error_log pid 即可。\n解释一下 pid，这个东西就是 nginx 运行时的进程 id（Linux 每个进程都有一个进程 id，即 pid），配置 pid，就是为了将 nginx 的进程 id 写到这个文件中（例如上方的 nginx.pid 文件），可以用来判断 nginx 是否运行，防止启动多个 nginx 进程的。\n网上的说法是这样的：nginx 启动时，会去找这个设置的 pid 文件，一是看这个文件是否存在，二是看 pid 文件中记录的 pid 进程是否存在，如果 pid 文件存在并且 pid 进程也存在，则说明 nginx 已经启动了，那么启动就会报错，防止启动多个 nginx 进程。\n事件块\r1 2 3 4 5 6 7 8 9 10 # events 块，是 nginx 处理连接的配置块 events { # 配置每个工作进程的最大连接数，默认 1024 worker_connection 1024; # 鼓励接收，这个可不配 multi_accept on; # 处理连接的事件模型，默认 epoll，可不配 use epoll; # 其他可百度 } 其实只需要配置一个 worker_connection 即可\nhttp 块\r1 2 3 4 5 6 7 8 9 10 11 12 http { # http 全局块常用配置 include mime.types; # 文件扩展名与文件类型映射表 default_type application/octet-stream; # 默认文件类型 access_log logs/access.log main; # 日志路径、格式 access_log on; # 开启日志，记录客户端请求信息 sendfile on; # 开启文件传输功能 keepalive_timeout 65s; # 保持连接超时时长，超过这个时间，连接关闭 client_max_body_size 10m; # 允许文件传输的最大值，根据实际情况设置 client_header_buffer_size 4k; # 客户端请求头缓冲区大小，k(千字节) client_body_buffer_size 8m; # 客户端请求体缓存区大小，m(MB) } client_max_body_size 参数，对传输的文件大小做限制 client_header_buffer_size client_body_buffer_size 参数，为了确保请求头(体)数据不会因为缓冲区太小而被截断\nserver 块\rserver 块里包含了 upstream 块、location 块\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 # 该块在 http 块下 # 通过配置的服务名和监听端口去访问时，根据不同的权重随机跳转到应用服务端 # 这里的链路大概如下： # 访问 ng 地址：http://hello:80/app \u0026gt;\u0026gt;\u0026gt; 跳转 http://fzjh/app # \u0026gt;\u0026gt;\u0026gt; 根据 upstream 块获取 fzjh 配置的 server # \u0026gt;\u0026gt;\u0026gt; 根据权重访问 http://192.168.1.1:8080/app http://192.168.1.2:8080/app http { # http 全局块 ... # server 块 server { listen 80; # 监听端口，默认 80，需要根据实际情况更改 server_name hello; # 用来做跳转应用的服务名 # upstream 块 负载均衡关键块 upstream fzjh { server 192.168.1.1:8080 weight=1; # 服务器 1，权重 1 server 192.168.1.2:8080 weight=2; # 服务器 2，权重 2 } # location 块 反向代理关键块 location /app { # 指定访问的后缀 proxy_pass http://fzjh/app; # proxy_pass 反向代理关键字 } } } 说明：通常只是做反向代理的话，是不需要配置 upstream 块的，只需要配置 location 块。\n负载均衡策略\r负载均衡策略的问题，其实就是在 upstream 块里边去配置。比如步骤【4）server 块】中的 upstream 块用法就是一个加权轮询策略，weight=1 =2 就是服务器的权重，通过给服务器分配权重，权重大的服务器将接收更多的请求。（数值越大，权重越高）\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 # 轮询 upstream fzjh { server 192.168.1.1:8080; server 192.168.1.2:8080; server 192.168.1.3:8080; } # 加权轮询 upstream fzjh { server 192.168.1.1:8080 weight=1; server 192.168.1.2:8080 weight=3; server 192.168.1.3:8080 weight=5; # 权重越大，接收请求越多 } # ip hash upstream fzjh { ip_hash; # 没错，就是加上这个参数即可 server 192.168.1.1:8080; server 192.168.1.2:8080; server 192.168.1.3:8080; } # 最少连接 upstream fzjh { least_conn; # 没错，也是加个参数即可 server 192.168.1.1:8080; server 192.168.1.2:8080; server 192.168.1.3:8080; } Nginx启停\r1 2 3 4 5 6 # 启动 cd nginx_home/sbin \u0026amp;\u0026amp; ./nginx # 停止 pid 文件的路径为全局块中设置 kill -QUIT `cat nginx_home/logs/nginx.pid` # 重启 cd nginx_home/sbin \u0026amp;\u0026amp; ./nginx -s reload Nginx遇到的问题\r文件上传超限\r通常在使用 ng 访问应用时，在应用上传附件时，会遇到如下报错：\n1 request entity too large nginx 解决方案 此错误是由于上传文件的大小超过 nginx 配置的文件传输最大值导致。通过更改 client_max_body_size 的大小即可（没有则在 HTTP块 新增即可）。更改完需要重启 nginx 服务。\n无法显示验证码\r应用的登录页面需要输入验证码，当通过Ng跳转到应用时，不显示验证码。在upstream 里把负载均衡策略改为 IP HASH\n配置案例\r反向代理\r该配置为审计项目开发环境、测试环境的实际配置。当然，信创版本，使用的是 宝兰德 BWS 中间件（国产版的Nginx）\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 user bes; #error_log logs/error.log; #error_log logs/error.log notice; #error_log logs/error.log info; #pid logs/bws.pid; events { worker_connections 1024; } http { include mime.types; default_type application/octet-stream; log_format main \u0026#39;$remote_addr - $remote_user [$time_local] \u0026#34;$request\u0026#34; \u0026#39; \u0026#39;$status $body_bytes_sent \u0026#34;$http_referer\u0026#34; \u0026#39; \u0026#39;\u0026#34;$http_user_agent\u0026#34; \u0026#34;$http_x_forwarded_for\u0026#34;\u0026#39;; access_log logs/access.log main; access_log on; sendfile on; keepalive_timeout 65s; server { #bws_http_server_name:server-tPegV0o6 #bws_http_server_type:reverseProxy listen 8070; server_name 192.168.XXX.56; location / { #type:static #bws_http_server_location_name:location-OsbKN52L index index.html index.htm; } location /app { proxy_pass http://192.168.XXX.59:18080/app; # 此处判断，允许跨源请求、http 方法、带 cookie 信息，通用配置 -- 开始 if ($request_method = \u0026#39;OPTIONS\u0026#39;) { add_header Access-Control-Allow-Origin \u0026#39;*\u0026#39;; add_header Access-Control-Allow-Headers \u0026#39;*\u0026#39;; add_header Access-Control-Allow-Methods \u0026#39;*\u0026#39;; add_header Access-Control-Allow-Credentials \u0026#39;true\u0026#39;; return 204; } proxy_http_version 1.1; proxy_set_header X-Real-IP $remote_addr; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection \u0026#34;upgrade\u0026#34;; proxy_set_header Origin \u0026#34;\u0026#34;; proxy_set_header Cookie $http_cookie; # 通用配置 -- 结束 } location = /50x.html { #type:static #bws_http_server_location_name:location-8t7KLrfH root html; } location = /bws_status { #bws_http_server_location_name:monitor stub_status on; } error_page 500 502 503 504 /50x.html; } gzip off; gzip_comp_level 1; gzip_min_length 1k; client_max_body_size 1024m; client_header_buffer_size 4k; client_body_buffer_size 8m; } worker_processes 1; error_log logs/error.log info; 负载均衡\r审计项目生产环境的配置（已脱敏）\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 #user nobody; worker_processes auto; #error_log logs/error.log; #error_log logs/error.log notice; #error_log logs/error.log info; #pid logs/bws.pid; events { worker_connections 512; use epoll; } http { include mime.types; default_type application/octet-stream; #log_format main \u0026#39;$remote_addr - $remote_user [$time_local] \u0026#34;$request\u0026#34; \u0026#39; # \u0026#39;$status $body_bytes_sent \u0026#34;$http_referer\u0026#34; \u0026#39; # \u0026#39;\u0026#34;$http_user_agent\u0026#34; \u0026#34;$http_x_forwarded_for\u0026#34;\u0026#39;; #access_log logs/access.log main; access_log off; sendfile on; #tcp_nopush on; #keepalive_timeout 0; keepalive_timeout 75; #gzip on; server { listen 8080; server_name SJGL-JR2-JQ; #charset koi8-r; #access_log logs/host.access.log main; location /app { index index.html index.htm; proxy_cache off; concat off; sysguard off; proxy_pass http://app-8080/app; } #error_page 404 /404.html; # redirect server error pages to the static page /50x.html # error_page 500 502 503 504 /50x.html; location = /50x.html { root html; proxy_cache off; concat off; sysguard off; } } upstream app-8080 { server SJGL-YY1-JQ:8080; server SJGL-YY2-JQ:8080; server SJGL-YY3-JQ:8080; server SJGL-YY4-JQ:8080; ip_hash; check interval=30000 fall=3 rise=2 default_down=false timeout=1000 type=tcp port=8080; } } ","date":"2024-06-10T21:34:07+08:00","permalink":"http://localhost:1313/posts/2024/06/%E5%AE%9E%E6%96%BD%E9%83%A8%E7%BD%B2-nginx%E5%9C%A8%E4%BF%A1%E5%88%9B%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8/","title":"实施部署-Nginx在项目上的应用与常见问题（四）"},{"content":"本文总结在信创项目中，使用最多的中间件：东方通、宝兰德。\n在安装中间件之前，应先在服务器创建一个应用用户，这里并不是说不能用root用户安装，开发环境和测试环境可以直接安装，但是生产上是无特殊情况是不提供root用户的。为了避免因为用户差异导致的文件执行问题，这里先创建一个用户，上线时，可以保证我们的操作一致，以及后续方便排查部署过程中可能产生的报错。\n安装前准备\r创建中间件用户\r在应用服务器上使用root用户\n1 2 3 4 5 6 # 创建用户组 groupadd -g 1051 test # 创建用户 useradd -g test -m -d /home/test -s /bin/bash test # 修改密码 passwd test hosts配置\r1 2 3 4 5 6 7 8 # 查看本机名 hostname # 查看本机IP hostname -i # 配置hosts vi /etc/hosts # 添加 ip hostname 修改文件打开最大数\r说明：此步骤，安装东方通时可跳过的，宝兰德需要操作（以我接触的项目情况是这样的）\n1 2 3 4 5 6 vi /etc/security/limits.conf # 添加 * soft nofile 65535 * hard nofile 65535 * soft nproc 65535 * hard nproc 65535 保存后重新连接服务器\n1 2 # 查看是否生效 ulimit -a 配置JDK\r没有则安装，一般信创的机器是自带的。但是有时候，为了确保这个版本的JDK是中间件以及应用服务都可用，采用自己安装，多为安装 JDK1.8 版本（自己安装需要上传jdk到服务器并解压tar包）\n1 2 # 查看是否安装 java -version 已经有了，则可以直接配置环境变量，当然，得知道路径才能配置环境变量\n1 2 3 4 # 查看 JDK 的安装路径 which java ls -l /usr/bin/java ls -l /etc/alternatives/java 最下边返回的，就是 JDK 真是的安装路径\n找到JDK安装路径后，添加环境变量：\n1 2 3 4 5 6 7 8 vi ~/.bashrc # 在末尾加入 export JAVA_HOME=/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.272.b10-7.ky10.x86_64/jre export PATH=$JAVA_HOME/bin:$PATH # 保存后刷新环境变量 source ~/.bashrc # 输出配置的环境变量 echo $JAVA_HOME 配置好环境变量后，就可以进行中间件的安装了\n东方通部署应用\r东方通中间件部署应用的详细步骤，从东方通安装到管理控制台配置的过程。\n东方通的安装\r东方通在LINUX上安装，需要通过命令的方式安装。（PS：这个已经是22年的版本了，当时接触东方通的时候，安装包是一个.bin文件，但是到了23年，东方通的安装包基本都是提供一个tar包，安装只需要解压tar包即可。方便很多，但是既然是自己安装的中间件，当然要记录啦）\nbin包安装\r1 2 3 4 # 运行安装包 sh Install_TW7.*.*.*_Enterprise_Linux.bin -i console # 选择语言 中文简体 1 2 3 4 5 6 # 中间会出现 【按回车键继续安装】【PRESS \u0026lt;ENTER\u0026gt; TO CONTINUE】 按回车就行 # 然后回出现 【是否接受此许可协议条款】 y # 选择 JDK 选择系统自带的 JDK 即可，当然也可以使用自己安装的，图上是使用自己安装的（最好是适配应用的 JDK 版本） 1 2 # 选择安装位置 输入一个安装路径 1 2 # 选择链接位置 这里常链接到主文件夹中 1 2 # 出现预安装信息 回车即可 1 2 3 4 5 # 修改端口 此步骤，可修改可不改。无特殊要求可直接使用默认（回车）。有特殊要求，则更改端口，这里也可以安装好后在配置文件中修改（$TONGWEB_HOME/conf/tongweb.xml) 通常我们关注以下两个 tong-http-listener，此为访问应用端口 system-http-listener，此为东方通控制台端口 回车后就安装完成了。\ntar包安装\r提供的tar包，只需要解压到目标目录即可。当然，tar有多种压缩格式，最常碰见的就是 tar.gz\n1 tar -xzvf tongweb_version_7.x.x.x /home/tongweb 授权\r将安装后的目录，授权给中间件用户\n1 2 chown test:test -R /home/tongweb chmod 755 -R /home/tongweb 启动配置\r以下常见配置，均为在项目上能够实际遇到的\n修改端口\r根据客户要求，或者应用要求，配置我们的应用端口。（如果是使用默认端口则不需要修改）\n1 2 3 4 # 假设安装到 /home/tongweb vi /home/tongweb/conf/tongweb.xml # 修改 tong-http-listener 的 port port = 8080 关闭防火墙\r在启动东方通控制台之前，需要关闭防火墙，否则操作机器无法访问到控制台地址。（在第一次接触东方通的时候，当时服务已经启动了，但是打不开控制台，我还以为是网络没打通，结果一查是防火墙导致）\n1 2 3 4 # 关闭防火墙 systemctl stop firewalld # 禁止防火墙自启，通常情况下，不需要禁止，但是如果遇到服务器重启的情况，首先还是需要手动关闭 systemctl disable firewalld 启停服务\r1 2 3 4 5 6 7 8 9 10 # 正常启动 cd /home/tongweb/bin \u0026amp;\u0026amp; ./startserver.sh # 后台启动（常用） cd /home/tongweb/bin \u0026amp;\u0026amp; ./startservernohup.sh # 停止 cd /home/tongweb/bin \u0026amp;\u0026amp; ./stopserver.sh # 或者手动 kill kill -9 {pid} # 重启 cd /home/tongweb/bin \u0026amp;\u0026amp; ./startservernohup.sh restart 打开控制台\r1 http://ip:port/console 控制台配置\r修改服务器可选目录\r此步骤是确保在部署应用的时候，可以访问到应用所在的位置，不然找不到\nJDBC 配置\rJDBC配置就是让中间件连接到数据库，让应用能够与数据库进行交互。\n需要注意的地方：\n达梦JDBC驱动，最好使用新版，或者应用做了适配的版本。 JDBC连接名称，需要与应用中的jndiName 一致，一般的java服务会有一个xml文件配置dispatcher-servlet 的地方，否则可能会报错在应用中找不到 jndiName 。特别是在做信创迁移的时候，会出现一种情况：tomcat里使用的jndiName与东方通里使用的jndiName名称不一致，此时需要注意修改为一致。 另外，基于项目经验猜测，基于 webbuilder 的框架，都有 WEB-INF/dispatcher-servlet.xml 文件，同样的，也会有变量配置，变量配置可能是落到数据库中，也可能使用 var.json 文件进行配置。差异不大，都是会有 jndiName 的配置\n部署应用\r如果没有【3.1修改服务器可选目录】，这里是访问不到应用所在的目录的\n点击开始部署，一般这里没什么多大的问题，都取默认即可。\n访问应用\r1 http://ip:port/app_name 多种部署情况说明\r一个东方通部署多个应用\r遇到过客户为了节省开发环境或者测试环境的资源，会让我们在一个东方通部署多个应用（就是与其他应用共享资源）。对于不同的应用，是可以的。\n针对是部署相同的应用，需要\n建立新的连接池，修改jndiName ，以防应用访问错数据库 直接部署\r直接部署则按照【3.1-3.3】步骤，部署应用即可\n注意：直接部署，东方通是按顺序拉起应用的，启动会慢一些，并且公用 IP 和 PORT ，东方通服务停掉会影响所有应用。\n域部署\r通过创建域，让各个应用启动和配置不相互影响。使用 TONGWEB_HOME/bin 下的启停命令不会影响到域里边的应用，域里的应用独立启停和配置，且端口不会冲突\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 # 创建域 cd TONGWEB_HOME/bin ./domain.sh create AppName # 执行后，在东方通的根目录下会出现 domains 目录，目录里边的结构与根目录完全一致，有 /bin /conf /logs 等等 # 域的启停，与东方通完全一致，不过是在 /domains/bin 下 # 配置文件也在 /domains/conf 下 # 配置域的端口 cd TONGWEB_HOME/domains/conf vi tongweb.xml # 域的默认端口是东方通默认的端口+1 # 启停 cd TONGWEB_HOME/domains/bin ./startservernohup.sh # 启动 ./stopserver.sh # 停止 # 默认的域管理控制台： http://IP:PORT+1/console # 比如东方通默认端口 9060，域端口则为 9061 # 应用访问： http://IP:PORT+1/app_name # 比如应用默认端口 8088，域端口则为 8089 设置connection-timeout\r有些客户，在扫描整体的安全漏洞时，会检测到目标主机可能存在缓慢的 HTTP 拒绝服务攻击，这个就是中间件里配置connection-timeout即可。\n简单来说，通过发送大量的慢速或低频率的 HTTP 请求来占用目标服务器的资源，导致服务器的连接和内存资源被恶意连接占满，无法处理新的合法请求。\ntomcat 可以通过修改 server.xml 文件中的配置来设置 connectionTimeout 参数\n1 2 3 4 5 6 7 8 9 10 11 12 \u0026lt;Connector port=\u0026#34;8080\u0026#34; protocol=\u0026#34;HTTP/1.1\u0026#34; maxHttpHeaderSize=\u0026#34;8192\u0026#34; maxThreads=\u0026#34;100\u0026#34; minSpareThreads=\u0026#34;50\u0026#34; maxSpareThreads=\u0026#34;100\u0026#34; minProcessors=\u0026#34;50\u0026#34; maxProcessors=\u0026#34;100\u0026#34; enableLookups=\u0026#34;false\u0026#34; connectionTimeout=\u0026#34;8000\u0026#34; // 修改此处值 acceptCount=\u0026#34;100\u0026#34; redirectPort=\u0026#34;8443\u0026#34; URIEncoding=\u0026#34;UTF-8\u0026#34;/\u0026gt; 同样的，在信创上，东方通中间件也可通过设置对应的请求，在 tongweb/conf/tongweb.xml 配置文件中，connection-timeout 对接的前台页面就是 http 通道里的 连接超时 ，修改此处即可（默认 60000 \u0026raquo; 改为 8000）\n宝兰德部署应用\r该步骤为宝兰德集群版本的安装步骤，非单实例。集群版本，需要配置节点、实例。实例的启动依赖于节点的启动，节点停止则实例停止。\n正确的启动顺序：集群 \u0026raquo; 节点 \u0026raquo; 实例\n宝兰德的安装\r将安装介质放入服务器，并解压\n1 2 3 4 5 6 # 使用中间件用户 su - bes # 进入介质目录 cd /home/BES955 # 解压 tar -zxvf BES-AppServer-Enterprise-9.5.5.6210-KYLIN10-X64.tar.gz -C /home/BES955/AdminServer 如果有补丁，则需要升级补丁。将补丁包放到 patch 目录下，执行\n1 2 3 4 5 cd /home/BES955/AdminServer/bin # 升级补丁 ./patch -path /home/jfcz/patch # 查看是否升级完成 ./patch -list 初始化并启动\r1 2 3 4 5 6 # 在bin目录下执行，初始化中间件 ./initstore # 启动管理控制台 ./startManagement # 查看是否启动，出现6900端口为已启动 netstat -ntlp 配置中间件\r访问管理控制台\n1 http://IP:6900/console 添加主机\r进入控制台后，点击左侧主机管理，点击添加： 填写名称、主机IP、用户名、密码，信息如图\n可以点击ping，测试是否能连接。不能ping通请检查IP、用户、密码是否正确。\n添加节点\r点击左侧节点管理，新建\n填写节点名称、节点目录（默认填宝兰德的安装目录），JAVA_HOME可默认不填\n保存后，启动它。\n点击节点，进入节点的配置界面，将【启动所有实例、停止所有实例】打勾后保存（这个操作可以在启动节点的同时自动启动实例）\n创建集群\r点击左侧集群管理，点击新建：填写个集群名称即可。保存后选中该集群然后点击启动。\n创建实例\r点击左侧实例管理，点击新建：填写如图信息保存即可\n修改实例端口\r点击实例 - 系统属性 http-listener-1_port：修改为8080（这个是http协议访问） http-listener-2_port：（这个是https协议访问，如需要此访问请更改）\nOK，到这里就是宝兰德的基础配置就结束了。\n后边可以进行应用的部署了。\n部署应用注意项\rBES集群下有实例，应用是在实例中生效的，所以改动应用的时候请直接到实例目录下的application目录下去改。每部署一次应用，就会拷贝一次应用目录到它的实例node/application下。\n重启实例出现某个实例启动失败\r在应用无报错的前提下，4个实例，正常重启实例，会出现1个或者2个实例启动报错。从应用的错误日志中查看原因，会出现一些连接不上数据源的报错，导致实例的错误日志会抛出应用错误。\n由于数据源连接数量太少导致，每个实例都需要一定的连接数。此时，需要到中间件的JDBC数据源配置处，修改池的连接数。生产环境上修改为默认的两倍数据，实例均正常启动。后续如果出现此情况，可根据实际情况，扩大连接数即可。\n","date":"2024-06-07T17:51:06+08:00","permalink":"http://localhost:1313/posts/2024/06/%E5%AE%9E%E6%96%BD%E9%83%A8%E7%BD%B2-%E4%B8%9C%E6%96%B9%E9%80%9A%E4%B8%AD%E9%97%B4%E4%BB%B6%E9%83%A8%E7%BD%B2%E5%BA%94%E7%94%A8/","title":"实施部署-东方通中间件、宝兰德部署应用（三）"},{"content":"达梦数据库的安装\r*仅适用于LINUX安装\n在搭建客户的开发环境、测试环境，数据库多为实施自行安装，并没有太大的要求，只需要注意一些参数，到时候与生产环境保持一致即可。生产环境，会与客户沟通达梦数据库的参数，比如：页大小、簇大小、字符集、大小写敏感等一些需要在注册实例时就配置的参数。\n在上一文章《实施部署-信创项目环境搭建准备（一）》已经沟通过参数了，这篇总结达梦数据库的安装和初始化实例的步骤。\n先贴个达梦官网技术文档地址：（步骤都可以在这里找到的）\nhttps://eco.dameng.com/document/dm/zh-cn/start/dm-install-linux.html\n1 新建DMDBA用户\r进入Linux服务器，用root用户创建：\n1 2 3 4 5 6 # 创建用户组 groupadd dinstall # 创建用户 useradd -g dinstall -m -d /home/dmdba -s /bin/bash dmdba # 修改用户密码 passwd dmdba 2 修改文件打开最大数\r1 2 3 4 5 6 7 vi /etc/security/limits.conf # 在conf文件内容的最后添加 dmdba hard nofile 65536 dmdba soft nofile 65536 dmdba hard stack 32768 dmdba soft stack 16384 # :wq 保存 修改后切换到dmdba用户查看是否生效\n1 2 su - dmdba ulimit -a 3 创建数据库安装目录\r1 2 3 4 5 6 7 # 创建目录 cd /home mkdir dm # 修改目录所属主、所属组 chown dmdba:dinstall -R dm # 给目录授权 chmod -R 755 dm 4 挂载达梦镜像\r将达梦数据库安装包.iso 文件上传到数据库服务器上的任意位置，例如：\n1 2 3 4 5 6 # 创建挂载目录 mkdir /mnt # 给执行权限 chmod 755 达梦数据库安装包.iso # 挂载 mount -o loop /home/dmdba/dm8_20230713_FTarm_kylin10_sp1_64_include_symbols.iso /mnt 5 安装数据库\r1 2 3 4 5 6 # 切换创建好的达梦数据库用户 su - dmdba # 进入挂载目录 cd /mnt # 安装 ./DMInstall.bin -i 步骤如图：（其中安装目录选择创建的达梦数据库安装目录）\n显示安装结束后，切换到root用户\n1 2 3 su - root # 执行 /home/dm/script/root/root_install.sh 6 注册实例\r说明：\n达梦数据库页大小、簇大小、大小写敏感、字符集都为注册实例时需要配置的，这些参数一经注册后不能修改，除非重新注册实例或者重装数据库。参数在《实施部署-信创项目环境搭建准备（一）》已经做了总结。\n6.1 使用默认参数注册\r1 2 3 4 5 6 7 # 切换到dmdba用户 su - dmdba # 进入dm/bin目录 cd /home/dm/bin # 执行初始化命令 ./dminit path=/home/dm/data # 类似下图 1 2 3 4 5 6 7 8 9 10 # 切换root用户 su - root # 进入相关目录 cd /home/dm/script/root # 执行注册服务命令 ./dm_service_installer.sh -t dmserver -dm_ini /dm/data/DAMENG/dm.ini -p DMSERVER # -t dmserver 就是达梦自己的server服务 # -p DMSERVER 这个就是数据库服务的名称，执行上边命令就是生成了 DmServiceDMSERVER 的命令 # 如果 -p DMtest 就会生成 DmServiceDMtest 的命令 # 类似下图 这个操作将生成 dm.ini 配置文件，实例注册到哪个目录，配置文件就在哪个目录\n6.2 使用自定义参数注册\r步骤与 6.1 相同，不同的步骤只有一个，在执行初始化命令时，需要在后边接上需要设置的页大小、簇大小、字符集、大小写敏感等等相关参数\n1 2 3 4 5 6 7 8 9 10 11 # 参考 ./dminit path=/home/dm/data PAGE_SIZE=32 EXTENT_SIZE=32 CASE_SENSITIVE=y CHARSET=0 DB_NAME=DMDB INSTANCE_NAME=DmDBSERVER PORT_NUM=5236 # 实例的路径 path= # 页大小 PAGE_SIZE # 簇大小 EXTENT_SIZE # 大小写敏感 CASE_SENSITIVE # 字符集 CHARSET # 数据库名 DB_NAME\t也就是达梦数据文件的目录名称 # 实例名 INSTANCE_NAME # 端口 PORT_NUM 6.3 删除实例\r如果在注册实例时，已经执行了初始化命令./dminit，已经生成了实例的数据文件了，这时候想删除这个实例怎么办？\n进入到达梦的 ../script/root 目录下，执行 ./dm_service_uninstaller.sh 命令，来删除这个实例\n必须使用 root 用户，先把数据库服务先关掉\n./dm_service_uninstaller.sh -n DmServiceDMSERVER 这里的实例名，主要是看 bin 目录中是用哪个命令来启动的，这个命令通常就是这个服务的名称\n1 2 3 4 5 6 7 8 [root@learning home]# cd /home/dmdba/dmdbms/script/root/ [root@learning root]# ls dm_service_installer.sh dm_service_uninstaller.sh root_installer.sh [root@learning root]# ./dm_service_uninstaller.sh -help Usage: dm_service_uninstaller.sh [-n service_name] -n 服务名,删除指定服务 -h 帮助 [root@learning root]# ./dm_service_uninstaller.sh -n DmServiceDMSERVER 然后把对应的实例数据目录删除即可\n7 可选参数配置\r具体见《实施部署-信创项目环境搭建准备（一）》的1.4.2步骤\n8 替换dm.key\r替换为正式的dm.key，可直接上传正式的key到dm/bin目录直接替换\n或者上传任意目录，使用cp命令替换\n9 启动数据库\r开发、测试环境启动\n1 2 # 启动数据库服务 systemctl start DmServiceDMSERVER.service 生产上，一般会安装达梦的监控守护模式\n1 2 3 cd /home/dm/bin DmServiceDM start DmWatcherServiceDM start 1 2 3 4 5 6 7 8 9 10 # 开发、测试环境 # 停止 systemctl stop DmServiceDMSERVER.service # 重启 systemctl restart DmServiceDMSERVER.service # 生产环境 DmWatcherServiceDM stop # 先停监控 DmServiceDM restart DmWatcherServiceDM start 达梦集群守护\r达梦集群守护是生产上才使用的，一般由DBA操作。\n生产环境采用双活形式部署，应用服务器上使用达梦数据库连接服务名进行连接。达梦在安装完成时会在数据库服务器上生产/etc/dm_svc.conf 文件，可以在该文件中进行添加配置，同时需要在应用服务器上【/etc/dm_svc.conf】文件（此文件为新增）中配置：\n1 2 3 4 5 6 7 8 TIME_ZONE=(480) LANGUAGE=(cn) GRP1=(192.168.xxx.1:5236,192.168.xxx.2:5236) [GRP1] TIME+ZONE=(+480) LOGIN_MODE=(1) SWITCH_TIME=(3) SWITCH_INTERVAL=(200) 配置说明如下：\nLOGIN_MODE 服务名方式登录，始终会优先登录主库； LOGIN_MODE 表示是否仅登录主库或者备库，可以配置为 0、1 或 2。2表示不登录 Standby 模式的库，如果系统中只有 Standby 模式的库，登录失败并报错。 SWITCH_TIME 检测到数据库实例故障时，接口在服务器之间切换的次数；超过设置次数没有连接到有效数据库时，断开连接并报错。 SWITCH_INTERVAL 表示在服务器之间切换的时间间隔，单位为毫秒。 ","date":"2024-06-06T23:22:03+08:00","permalink":"http://localhost:1313/posts/2024/06/%E5%AE%9E%E6%96%BD%E9%83%A8%E7%BD%B2-%E8%BE%BE%E6%A2%A6%E6%95%B0%E6%8D%AE%E5%BA%93%E7%9A%84%E5%AE%89%E8%A3%85/","title":"实施部署-达梦数据库linux版的安装（二）"},{"content":"前言\r在做交付工作的时候，环境的搭建也是工作的一个重要环节。公司现在一个产品的架构：B/S架构，采用的技术路基本是低代码平台 + JAVA后端：低代码平台里使用 javascrpit 做功能页面的开发，对于JAVA类也只是调用；业务逻辑都写在数据库的存储过程中。\n那运行产品的环境的搭建就主要包括：WEB服务的部署、数据库的部署。当然也有其他的服务，但其他服务需要根据产品的需要进行部署的。我主要负责信创类项目的实施部署，都是在LINUX服务器上部署。\n一个环境搭建的思路：\n前期环境的准备 \u0026raquo; 数据库部署 \u0026raquo; 中间件与应用部署 \u0026raquo; ETL工具部署\n本文总结前期环境的准备\n信创项目知识\r信创类产品的实施部署从 0 到 1 ，实施部署前期需要了解什么，作为跟客户沟通的技术知识保障。\n信创软硬件\r数据库：达梦 中间件：东方通、宝兰德 服务器操作系统：麒麟、统信 硬件平台：飞腾、华为、龙芯、海光、鲲鹏…… 内核：AMD、ARM\n确认服务器架构信息\r信创，产品的框架与数据平台均做了适配，都需要根据内核来确认使用哪个版本。\n1 2 3 4 5 6 7 8 9 10 # 在Linux服务器上输入命令获取内核信息，通常有3种方式 # 返回信息中包含了 x86_64 表示该服务器内核为 AMD # 返回信息中包含 arrch64 或者 arm64 表示该服务器内核为 ARM # 返回内核版本、架构 uname -a # 返回内核版本 cat /proc/version # 返回系统信息（包括内核、操作系统版本） hostnamectl 确认服务器内存信息\rJAVA服务端通常需要设置服务的 JVM ，生产环境通常推荐 JVM \u0026gt; 16G\n开发环境、测试环境 JVM 减半作为参考即可\n比如：在部署中间件、宝兰德中间件的时候，默认的 JVM 都是 2G，测试服务器只有8G内存的情况下，中间件的JVM修改为4G。\n确认数据库参数\r我所遇到的信创项目种，数据库通常使用达梦数据库。达梦数据库，有几个参数是在初始化实例的时候就需要确定的，且初始化实例后无法进行修改，除非重新初始化实例：\n页大小 (page_size) 簇大小 (extent_size) 大小写敏感 (case_sensitive) 字符集 (charset) 下表为这几个参数的具体含义：\n名称 含义 可设置值 page_size 数据文件使用的页大小 4/8/16/32 extent_size 簇大小，每次分配新的段空间时连续的页面 16/32/64 case_sensitive 标识符大小写敏感。当大小写敏感时，小写的标识符要用双引号括起，否则被转换为大写；当大小写不敏感时，系统不自动转换标识符的大小写，在标识符比较时也不区分大小写。默认 Y （1）敏感 Y/N（1/0） charset 字符集选项，0：GB18030；1：UTF-8（默认0） 0/1 length_in_char VARCHAR类型长度是否以字符为单位（默认为N 0 ） Y/N（1/0） 页大小与字段长度有关，簇大小与表空间有关，但是这两个都与我们没有关系，我们需要注意的只有 2 个：\n大小写敏感 字符集编码 产品多为oracle开发，从oracle移植过来，为了更好的兼容，通常开启大小写敏感；字符集编码是GB18030还是UTF-8没关系，但是开发环境、测试环境、生产环境需要字符集编码一致。\n在实际的项目实施部署中，客户的开发环境、测试环境通常由我们厂商维护，只有生产环境是由DBA维护。所以在前期的沟通中，我们需要跟DBA确认好达梦数据库里的上述参数，确保开发环境、测试环境、生产环境保持一致。\n总结了一份模板如下，页大小和簇大小根据在生产上通常建议设置为32\n参数带来的影响\r1）编码不一致\r当开发环境或者测试环境，与生产环境的字符集编码不一致时，可能会产生字符串长度相关的报错。\n比如：\n测试环境上是 GB18030 编码，但是生产环境上是 UTF8 编码，因为 GB 编码存一个中文需要的 1 个字节少于 UTF8 存一个中文需要的 3 个字节，测试后的产品功能上了生产环境可能会报出字符串截断的错误。\n2）大小写敏感不一致\r大小写敏感：查数据内容时，查 a 就是 a，查 A 就是 A\n大小写不敏感：查数据内容时，查 a 返回 A、a\n如果不设置大小写敏感，不仅是在写查询SQL的时候会影响，在创建对象、写存储过程时，对象名称、字段名称也会受到影响。比如：\n1 2 3 create table table_A (id varchar2(8)); insert table_a values(\u0026#39;001\u0026#39;); # insert 就会报错，因为 table_a 不存在，必须与创建的表名一模一样才可以 其他可能需要修改的参数\r此处的参数指，达梦数据库 dm.ini 配置文件里的参数。在开发环境、测试环境可由自己根据实际情况更改，在生产上必须与DBA沟通后进行更改，也需要保持三个环境中参数的一致性。\ndm.ini 配置文件中，有静态参数、动态参数。静态参数需要重启数据库服务后才生效，在生产上重启数据库是一件严肃的事情，需要修改的参数需要自己做好验证是否能够解决实际的情况。\n1）COMPATIBLE_MODE\r该参数用于控制达梦数据库在部分功能处理时与其他数据库的兼容模式。常用设置：\n0 - 不兼容 1 - 兼容SQL92标准 2 - 兼容ORACLE 3 - 兼容SQL SERVER 4 - 兼容MYSQL 通常项目上，此参数设置为2，可以更好的适配基于ORACLE开发的产品代码。\n【例子】\r达梦数据库默认NULL 与空值是不等价的，NULL就是NULL，空值就是空值。某个功能查询需要同时满足它们，需要这样写：\n1 2 3 4 select col_A from table_A where col_A is null or col_A = \u0026#39;\u0026#39; ; ORACLE中默认NULL 和空值是等价的，同时满足只需要：\n1 2 3 4 select col_A from table_A where col_A = \u0026#39;\u0026#39; ; 修改COMPATIBLE_MODE参数为2即可跟在ORACLE上的查询写法一致。\n2）PK_WITH_CLUSTER\r该参数默认为1\n该参数与建表时的主键索引有关，达梦数据库在创建表时，如果创建主键，则默认主键是聚簇索引键。如果没有主键，则默认rowid 作为聚簇索引键\n【例子】\r当在达梦数据建表时，同时出现主键、字段为大字段CLOB类型的时候，就会报错：\n1 2 3 4 5 6 7 create table table_A( id varchar2(8) primary key, name varchar2(20), addr clob ); -- 该语句会报错：表[xxxxxx]中不能同时包含聚集 KEY 和大字段 此时，修改参数PK_WITH_CLUSTER=0 ，再创建有主键、字段为CLOB类型的表，就可以创建成功。\n【关于聚簇索引】\r表（列存储表和堆表除外）都是使用 B+树(以下简称 B 树)索引结构管理的，每一个普通表都有一个聚集索引，数据通过聚集索引键排序，根据聚集索引键可以快速查询任何记录。（即表是一个索引，这个索引名称叫聚集索引，可以理解为创建一个表后，将所有字段放在一起建立一个复合索引，只不过这个不需要我们来创建，系统自动给我们维护了一个）\n当建表语句未指定聚集索引键，DM 的默认聚集索引键是 ROWID，即记录默认以 ROWID 在页面中排序。ROWID 是 B 树为记录生成的逻辑递增序号，表上不同记录的 ROWID 是不一样的，并且最新插入的记录 ROWID 最大。很多情况下，以 ROWID 建的默认聚集索引并不能提高查询速度，因为实际情况下很少人根据 ROWID 来查找数据。\n原文链接： https://blog.csdn.net/sinat_32856657/article/details/125410328\n3）CALS_AS_DECIMAL\r该参数是控制 整数除法运算是否舍弃小数。\n在达梦数据库中，整数相除或者使用ROUND函数，结果如果有小数位，会被直接舍弃，返回整数。\n比如\n1 2 select 9/2 from dual; -- 会返回4 可修改CALC_AS_DECIMAL=1 让运算不舍弃小数位\n关于参数修改方式\r第一种：通过dm.ini 修改参数\n第二种：在达梦SQL窗口中，执行：\n1 2 3 4 sp_set_para_value(old_values, \u0026#39;param_name\u0026#39;, new_values); -- 例如 sp_set_para_value(1,\u0026#39;PK_WITH_CLUSTER\u0026#39;,0); 确认数据库用户权限\r产品需要的用户大部分情况下是使用了DBA角色的权限，但是在项目实施时（特别是在生产环境中），会有部分客户认为产品上 DBA 权限不合理，也会有部分客户授权 DBA 是需要走流程申请。\n所以这一点在前期就需要跟客户确认，用户权限能否授予DBA权限。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 -- 创建达梦用户脚本 -- 创建表空间 -- 默认初始大小 500MB，每次自增 40MB，最大 10G create tablespace \u0026#34;TS_TEST\u0026#34; datafile \u0026#39;/dm8/data/DAMENG/TS_TEST.DBF\u0026#39; size 500 autoextend on next 40 maxsize 10240; -- 生产上可扩展为 unlimited create user \u0026#34;test\u0026#34; identified by \u0026#34;testdata123\u0026#34; default tablespace TS_test; grant \u0026#34;DBA\u0026#34; to \u0026#34;test\u0026#34;; grant delete any table to test; grant execute any procedure to test; grant insert any table to test; grant select any dictionary to test; grant select any table to test; grant unlimited tablespace to test; grant update any table to test; 甚至有的客户（我遇到的一个），认为ANY权限也是有大隐患的，需要针对到具体表名的权限。\n1 2 3 4 GRANT DELETE ANY TABLE TO TEST; GRANT SELECT ANY TABLE TO TEST; GRANT UPDATE ANY TABLE TO TEST; GRANT INSERT ANY TABLE TO TEST; 这种情况就没办法了，很麻烦，一个成熟且功能复杂的产品，可能标准版初始的表就有上千张（还不包括后续的开发新的功能表），存储过程、自定义函数等等也有上千个。每个存储过程用到的表都不一样，要一一梳理哪些用户select，哪个用户要delete等等，后期就需要额外的花时间去进行梳理。（虽然更安全、合规，但是麻烦的是我~吐槽一下）\n达梦权限说明\r通常我们在部署时，JDBC 中的连接，我们使用 WOLF WOLFDATA 用户去连接，或者使用 WOLF 去配置两个 JDBC 连接，指向 WOLF WOLFDATA 模式（达梦中 schema 的概念，可以把它当成 oracle 的实例概念）。\n使用了 WOLF 用户去配置 JDBC 连接，那么此时，在系统进行日常操作的时候，在数据库中就是基于 WOLF 用户对对各个对象（TABLE \\ SP \\ FUNCTION \\ VIEW \\ TYPE \\ PACKAGE 等）进行增删改查操作。\n通常情况下，框架提供的默认权限脚本权限多含 DBA 或者 ANY 权限，但是在生产环境上其实是不被允许的。在用户具备 DBA \\ DROP ANY OBJECTS 的情况，能做的事情比较多，包括了对表空间（数据文件）的更改、跨用户删除表 等危险操作。\n因此在权限上，有的客户会要求梳理到具体的表需要什么权限。\n1 2 3 4 5 6 7 8 9 1.除了本身的 ROURCE 角色外，需要对系统表的查询权限，SOV\\SVI 角色 2.需要对 WOLFDATA 具有完全执行权，WOLFDATA 下一般只有表，对这些表有增删改查即可 3.对产品用户的对象：（不包含达梦自身用户的对象） 所有 TABLE 有 INSERT \\ DELETE \\ UPDATE \\ SELECT 权限 所有 VIEW 有 SELECT 权限 所有 SP 有 EXECUTE 权限 所有的 FUNC 有 EXECUTE 所有的 PACKAGE 有 EXECUTE （达梦的 TYPE 类型集合到了 PACKAGE 里） 所有的 CLASS 有 EXECUTE 1 2 3 4 5 6 7 其他的产品用户，权限则需要有自身的 RESOURCE 用户外， 还应该从自身的 SP 中逐一排查需要的 跨用户对象的某个权限 比如 RISKCONFIG 的 SP 中通常含有对中间层表的 DELETE \\ INSERT \\ SELECT \\ UPDATE 则应该为 RISKCONFIG 用户赋予中间层表的 DELETE \\ INSERT \\ SELECT \\ UPDATE 权限。 不需要 WOLF 对中间层表有权限，WOLF 只需要有执行该 SP 的权限即可。 前期将这些沟通好，等客户给服务器的相关信息，就可以开始着手准备实施部署产品了。\n","date":"2024-06-01T21:41:26+08:00","permalink":"http://localhost:1313/posts/2024/06/%E5%AE%9E%E6%96%BD%E9%83%A8%E7%BD%B2-%E4%BF%A1%E5%88%9B%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%96%BD%E5%87%86%E5%A4%87/","title":"实施部署-信创项目环境搭建准备（一）"},{"content":"问题\r实际的项目中，采集上游数据到数据集市的贴源层 \u0026raquo; 跑数据转换任务，将数据写入到我们的业务表，在跑转换任务的时候，时不时会报错主键冲突。转换里，通常写着insert update 语句，当向表执行插入和更新操作，时不时出现报错：违反表的唯一约束条件。\n因为在实际业务中，中间层或者业务层表，通常情况下，是具有主键的（可能是单一主键，可能是复合主键）。\n常见的两种情况\r1）目标表里已经有了一条数据A，但是转换任务又往目标表里写入一条数据A，导致的报错；\n2）目标表里没有数据，但是转换里，使用的关联条件产生了多条重复数据，导致的报错。\n根据这两种情况对数据进行排查，看看是哪些数据重复了。\n思路\r1.根据报错的主键名称，查找该索引名是哪张表的主键名\n1 2 3 select * from all_indexes a where a.index_name = \u0026#39;报错的主键名\u0026#39;; 2.查看该表，查看该主键由哪些字段组成\n3.对于第一种情况，根据这些字段，将目标表与转换里源表进行join，对索引字段进行count，查看是否有重复数据\n例如这张表在转换里源表（from的表）为 ct.st_xxx，那么可以如下，查到重复的数据\n1 2 3 4 5 6 7 select a.contract_no, a.stock_account, count(*) from sett.t_ref_contract a join ct.st_xxx b on a.contract_no = b.jys -- 关联字段 and a.stock_account = b.zqzh group by a.contract_no, a.stock_account having count(*) \u0026gt; 1; 然后，对比该数据，是否完全一致（因为数据可能出现只有主键字段是相同的，但是其他字段不同的情况）\n1 2 3 4 5 6 7 8 select a.* from sett.t_ref_contract a join ct.st_xxx b on a.contract_no = b.jys -- 关联字段 and a.stock_account = b.zqzh where a.contract_no = \u0026#39;查到的contract_no\u0026#39; and a.stock_account = \u0026#39;查到的stock_account\u0026#39; group by a.contract_no, a.stock_account; 3.1）若一致，则可将目标表里的数据删掉\n3.2）若不一致，应咨询业务，它们是否有区别，根据业务沟通后的方案，将数据备份后，对其更改或删除等操作\n4.对于第二种情况，则需要看转换里，它的insert 或者update 的逻辑，类似：\n1 2 3 4 5 6 7 8 9 10 11 12 insert table_a ( col_1, col_2, ... ) select col_a, col_b, ... from table_b t1 join table_c t2 on t1.col_a = t2.col_a and t1.col_b = t2.col_b; 然后对关联条件进行检查，看看是不是关联条件出现了 1:N N:N 的情况，如果是，则根据代码的逻辑，对该数据产生的原因进行定位，根据实际情况进行解决。\n","date":"2024-05-20T20:26:17+08:00","permalink":"http://localhost:1313/posts/2024/05/","title":"SQL-违反表的唯一约束条件（主键冲突）问题"}]